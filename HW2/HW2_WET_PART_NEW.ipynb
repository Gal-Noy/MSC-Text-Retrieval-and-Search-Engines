{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba969ac",
   "metadata": {},
   "source": [
    "# HW2 - WET PART\n",
    "\n",
    "## Part B: Build 2 indexes and compare retrieval effectiveness\n",
    "1. **Index 1**: WITH stopwords removal AND WITH Krovetz stemming\n",
    "2. **Index 2**: WITH stopwords removal AND WITHOUT stemming\n",
    "3. Compare MAP, P@5, P@10 for both indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d594f",
   "metadata": {},
   "source": [
    "### Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd75f59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galnoy/git-projects/MSC-Text-Retrieval-and-Search-Engines/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[0;93m2025-11-20 23:03:12.370834361 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n",
      "\u001b[0;93m2025-11-20 23:03:12.370834361 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pytrec_eval\n",
    "import warnings\n",
    "import logging\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from pyserini.analysis import get_lucene_analyzer\n",
    "from pyserini.index.lucene import IndexReader\n",
    "from pyserini.search import get_topics_with_reader\n",
    "\n",
    "# Suppress warnings and Java logging\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "\n",
    "# Part A\n",
    "PART_A_DIR = BASE_DIR / \"data\" / \"WET_PART_A\"\n",
    "PART_A_INDEX = BASE_DIR / \"indexes\" / \"part_a_index\"\n",
    "\n",
    "# Part B\n",
    "AP_COLL_PATH = BASE_DIR / \"data\" / \"AP_Coll\"\n",
    "PART_B_DIR = BASE_DIR / \"data\" / \"WET_PART_B\"\n",
    "QUERIES_PATH = PART_B_DIR / \"queries.txt\"\n",
    "STOPWORDS_PATH = PART_B_DIR / \"StopWords.txt\"\n",
    "QRELS_PATH = PART_B_DIR / \"qrels_AP\"\n",
    "\n",
    "INDEX_STEMMED = BASE_DIR / \"indexes\" / \"ap_stemmed\"\n",
    "INDEX_UNSTEMMED = BASE_DIR / \"indexes\" / \"ap_unstemmed\"\n",
    "\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "RESULTS_STEMMED = RESULTS_DIR / \"stemmed.txt\"\n",
    "RESULTS_UNSTEMMED = RESULTS_DIR / \"unstemmed.txt\"\n",
    "\n",
    "# Create directories\n",
    "for path in [PART_A_INDEX, INDEX_STEMMED, INDEX_UNSTEMMED, RESULTS_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d0a8e",
   "metadata": {},
   "source": [
    "## Part A: Index docs.txt and test queries\n",
    "Build index with `--keepStopwords --stemmer none` and test with specific queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "375e50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index at /home/galnoy/git-projects/MSC-Text-Retrieval-and-Search-Engines/HW2/indexes/part_a_index...\n",
      "Index built successfully\n",
      "Index built successfully\n"
     ]
    }
   ],
   "source": [
    "def build_index(collection_path, index_path, stemmer='none', stopwords_path=None, keep_stopwords=False):\n",
    "    \"\"\"Build a Lucene index using pyserini.\"\"\"\n",
    "    if index_path.exists() and any(index_path.iterdir()):\n",
    "        print(f\"Index already exists: {index_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Building index at {index_path}...\")\n",
    "    cmd = [\n",
    "        \"python\", \"-m\", \"pyserini.index.lucene\",\n",
    "        \"--collection\", \"TrecCollection\",\n",
    "        \"--input\", str(collection_path),\n",
    "        \"--index\", str(index_path),\n",
    "        \"--stemmer\", stemmer,\n",
    "        \"--storePositions\",\n",
    "        \"--storeDocvectors\",\n",
    "        \"--storeRaw\",\n",
    "        \"--optimize\"\n",
    "    ]\n",
    "    \n",
    "    if keep_stopwords:\n",
    "        cmd.append(\"--keepStopwords\")\n",
    "    elif stopwords_path:\n",
    "        cmd.extend([\"--stopwords\", str(stopwords_path)])\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Index built successfully\")\n",
    "    else:\n",
    "        print(f\"Build failed: {result.stderr}\")\n",
    "\n",
    "build_index(PART_A_DIR, PART_A_INDEX, stemmer='none', keep_stopwords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a6a4b2",
   "metadata": {},
   "source": [
    "### Check index statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a8aba1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IndexReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43mIndexReader\u001b[49m(\u001b[38;5;28mstr\u001b[39m(PART_A_INDEX))\n\u001b[1;32m      2\u001b[0m stats \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mstats()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPart A Index Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IndexReader' is not defined"
     ]
    }
   ],
   "source": [
    "reader = IndexReader(str(PART_A_INDEX))\n",
    "stats = reader.stats()\n",
    "\n",
    "print(\"\\nPart A Index Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key:25s}: {value:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efdf5c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74420507",
   "metadata": {},
   "source": [
    "## Part B: Build Two Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index 1: WITH Krovetz stemming + WITH stopwords removal\n",
    "build_index(AP_COLL_PATH, INDEX_STEMMED, stemmer='krovetz', stopwords_path=STOPWORDS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266ffdf",
   "metadata": {},
   "source": [
    "Build Index 1 for Part B using the AP collection WITH Krovetz stemming and WITH stopwords removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d69725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index 2: WITHOUT stemming + WITH stopwords removal\n",
    "build_index(AP_COLL_PATH, INDEX_UNSTEMMED, stemmer='none', stopwords_path=STOPWORDS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09242266",
   "metadata": {},
   "source": [
    "Build Index 2 for Part B using the AP collection WITHOUT stemming but still WITH stopwords removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70f20b",
   "metadata": {},
   "source": [
    "## Part B: Load Queries and Perform Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a938cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and format queries\n",
    "topics = get_topics_with_reader('io.anserini.search.topicreader.TsvIntTopicReader', str(QUERIES_PATH))\n",
    "\n",
    "queries = {}\n",
    "for topic_id, topic in topics.items():\n",
    "    qid = str(topic_id) if len(str(topic_id)) == 3 else f\"0{topic_id}\"\n",
    "    queries[qid] = topic['title']\n",
    "\n",
    "print(f\"Loaded {len(queries)} queries\")\n",
    "print(f\"Sample: {list(queries.items())[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382973a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_save(index_path, queries, output_path, stemmer='none', k=1000, run_name=\"run\"):\n",
    "    \"\"\"Search index and save results in TREC format.\"\"\"\n",
    "    searcher = LuceneSearcher(str(index_path))\n",
    "    analyzer = get_lucene_analyzer(stemmer=stemmer, stopwords=False)\n",
    "    searcher.set_analyzer(analyzer)\n",
    "    searcher.set_bm25(k1=0.9, b=0.4)\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        for qid in sorted(queries.keys()):\n",
    "            hits = searcher.search(queries[qid], k=k)\n",
    "            for rank, hit in enumerate(hits, start=1):\n",
    "                f.write(f\"{qid} Q0 {hit.docid} {rank} {hit.score:.4f} {run_name}\\n\")\n",
    "    \n",
    "    print(f\"Results saved to {output_path}\")\n",
    "    return len(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f86ea",
   "metadata": {},
   "source": [
    "Helper function to search an index and save results in TREC format with BM25 parameters k1=0.9 and b=0.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316c555",
   "metadata": {},
   "source": [
    "Load the 150 queries from queries.txt and format the query IDs with leading zeros where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Index 1 (stemmed)\n",
    "search_and_save(INDEX_STEMMED, queries, RESULTS_STEMMED, stemmer='krovetz', run_name='stemmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9e9a2b",
   "metadata": {},
   "source": [
    "Retrieve top 1000 documents for each query from Index 1 (stemmed) and save results in TREC format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaee70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Index 2 (unstemmed)\n",
    "search_and_save(INDEX_UNSTEMMED, queries, RESULTS_UNSTEMMED, stemmer='none', run_name='unstemmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25427081",
   "metadata": {},
   "source": [
    "Retrieve top 1000 documents for each query from Index 2 (unstemmed) and save results in TREC format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc81402",
   "metadata": {},
   "source": [
    "## Part B: Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qrels(qrels_path):\n",
    "    \"\"\"Load relevance judgments in pytrec_eval format.\"\"\"\n",
    "    qrels = {}\n",
    "    with open(qrels_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 4:\n",
    "                qid, _, docid, rel = parts[0], parts[1], parts[2], int(parts[3])\n",
    "                if qid not in qrels:\n",
    "                    qrels[qid] = {}\n",
    "                qrels[qid][docid] = rel\n",
    "    return qrels\n",
    "\n",
    "def load_results(results_path):\n",
    "    \"\"\"Load search results in pytrec_eval format.\"\"\"\n",
    "    results = {}\n",
    "    with open(results_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 6:\n",
    "                qid, _, docid, rank, score, _ = parts\n",
    "                if qid not in results:\n",
    "                    results[qid] = {}\n",
    "                results[qid][docid] = float(score)\n",
    "    return results\n",
    "\n",
    "def evaluate_with_pytrec_eval(qrels, results):\n",
    "    \"\"\"Evaluate results using pytrec_eval.\"\"\"\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'map', 'P_5', 'P_10'})\n",
    "    metrics = evaluator.evaluate(results)\n",
    "    \n",
    "    # Calculate averages\n",
    "    map_scores = [scores['map'] for scores in metrics.values()]\n",
    "    p5_scores = [scores['P_5'] for scores in metrics.values()]\n",
    "    p10_scores = [scores['P_10'] for scores in metrics.values()]\n",
    "    \n",
    "    return {\n",
    "        'MAP': sum(map_scores) / len(map_scores) if map_scores else 0.0,\n",
    "        'P@5': sum(p5_scores) / len(p5_scores) if p5_scores else 0.0,\n",
    "        'P@10': sum(p10_scores) / len(p10_scores) if p10_scores else 0.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdcccd7",
   "metadata": {},
   "source": [
    "Helper functions to load qrels and results, then evaluate using pytrec_eval to calculate MAP, P@5, and P@10 metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load qrels and results\n",
    "qrels = load_qrels(QRELS_PATH)\n",
    "results_stemmed = load_results(RESULTS_STEMMED)\n",
    "results_unstemmed = load_results(RESULTS_UNSTEMMED)\n",
    "\n",
    "print(f\"Loaded {len(qrels)} queries with relevance judgments\")\n",
    "\n",
    "# Evaluate both configurations using pytrec_eval\n",
    "print(\"\\nEvaluating stemmed index...\")\n",
    "metrics_stemmed = evaluate_with_pytrec_eval(qrels, results_stemmed)\n",
    "\n",
    "print(\"Evaluating unstemmed index...\")\n",
    "metrics_unstemmed = evaluate_with_pytrec_eval(qrels, results_unstemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186ec6b",
   "metadata": {},
   "source": [
    "Load qrels and results files, then use pytrec_eval to calculate MAP, P@5, and P@10 metrics for both index configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d97fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comparison table\n",
    "if metrics_stemmed and metrics_unstemmed:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Configuration':<30} {'MAP':>10} {'P@5':>10} {'P@10':>10}\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'WITH Krovetz + WITH Stopwords':<30} {metrics_stemmed['MAP']:>10.4f} {metrics_stemmed['P@5']:>10.4f} {metrics_stemmed['P@10']:>10.4f}\")\n",
    "    print(f\"{'WITHOUT Stemming + WITH Stopwords':<30} {metrics_unstemmed['MAP']:>10.4f} {metrics_unstemmed['P@5']:>10.4f} {metrics_unstemmed['P@10']:>10.4f}\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"Error: Could not calculate metrics. Make sure trec_eval is installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7196e0ee",
   "metadata": {},
   "source": [
    "Display a comparison table showing MAP, P@5, and P@10 for both index configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c31443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best configuration\n",
    "if metrics_stemmed and metrics_unstemmed:\n",
    "    if metrics_stemmed['MAP'] > metrics_unstemmed['MAP']:\n",
    "        winner = \"WITH Krovetz stemming\"\n",
    "        diff = metrics_stemmed['MAP'] - metrics_unstemmed['MAP']\n",
    "    else:\n",
    "        winner = \"WITHOUT stemming\"\n",
    "        diff = metrics_unstemmed['MAP'] - metrics_stemmed['MAP']\n",
    "    \n",
    "    print(f\"\\nBest configuration by MAP: {winner}\")\n",
    "    print(f\"MAP improvement: {diff:.4f}\")\n",
    "    print(\"\\nExplanation:\")\n",
    "    print(\"Krovetz stemming reduces words to their root forms, improving recall by matching\")\n",
    "    print(\"different morphological variants (e.g., 'running', 'runs', 'ran' â†’ 'run').\")\n",
    "    print(\"This typically improves retrieval effectiveness when queries and documents use\")\n",
    "    print(\"different word forms for the same concepts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04db5c7",
   "metadata": {},
   "source": [
    "Determine which configuration performed better based on MAP and provide an explanation of the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
