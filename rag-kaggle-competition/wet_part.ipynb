{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e61fc84",
      "metadata": {},
      "source": [
        "# Text Retrieval and Search Engines - Assignment 3\n",
        "**Gal Noy** · 209346486"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80249d88",
      "metadata": {},
      "source": [
        "## 1. Setup & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "660a3af5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dependencies imported\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from typing import List, Dict, Tuple, Optional, Literal\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Dependencies imported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc79df6",
      "metadata": {},
      "source": [
        "### Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "48dd5ff7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !apt-get update\n",
        "# !apt-get install -y openjdk-21-jdk\n",
        "# !update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-21-openjdk-amd64/bin/java 1\n",
        "# !update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java-21-openjdk-amd64/bin/javac 1\n",
        "# !update-alternatives --set java /usr/lib/jvm/java-21-openjdk-amd64/bin/java\n",
        "# !update-alternatives --set javac /usr/lib/jvm/java-21-openjdk-amd64/bin/javac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "8b4cf0d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "openjdk version \"21.0.9\" 2025-10-21\n",
            "OpenJDK Runtime Environment (build 21.0.9+10-Ubuntu-122.04)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.9+10-Ubuntu-122.04, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "6308b134",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install torch torchvision torchaudio\n",
        "# !pip install pyserini==0.36.0\n",
        "# !pip install accelerate\n",
        "# !pip install transformers\n",
        "# !pip install tqdm\n",
        "# !pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10ff9235",
      "metadata": {},
      "source": [
        "### Hugging Face Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "37f1afed",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Logged into Hugging Face\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "login(os.getenv('HUGGING_FACE_TOKEN'))\n",
        "print(\"✓ Logged into Hugging Face\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4a17cc",
      "metadata": {},
      "source": [
        "## 2. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "bb3486b9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set: 3778 questions\n",
            "Test set: 2032 questions\n",
            "\n",
            "Sample question: what is the name of justin bieber brother?\n",
            "Sample answers: ['Jazmyn Bieber', 'Jaxon Bieber']\n"
          ]
        }
      ],
      "source": [
        "df_train = pd.read_csv(\"./data/train.csv\", converters={\"answers\": json.loads})\n",
        "df_test = pd.read_csv(\"./data/test.csv\")\n",
        "\n",
        "print(f\"Train set: {len(df_train)} questions\")\n",
        "print(f\"Test set: {len(df_test)} questions\")\n",
        "print(f\"\\nSample question: {df_train.iloc[0]['question']}\")\n",
        "print(f\"Sample answers: {df_train.iloc[0]['answers']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d14492e1",
      "metadata": {},
      "source": [
        "## 3. Retrieval Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51843bc1",
      "metadata": {},
      "source": [
        "### Pyserini index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "8ef07078",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Pyserini index...\n",
            "SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n",
            "✓ Index loaded: 5903530 documents\n"
          ]
        }
      ],
      "source": [
        "from pyserini.search import SimpleSearcher\n",
        "from pyserini.index.lucene import IndexReader\n",
        "\n",
        "print(\"Loading Pyserini index...\")\n",
        "searcher = SimpleSearcher.from_prebuilt_index('wikipedia-kilt-doc')\n",
        "index_reader = IndexReader.from_prebuilt_index('wikipedia-kilt-doc')\n",
        "\n",
        "print(f\"✓ Index loaded: {index_reader.stats()['documents']} documents\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0286c2fc",
      "metadata": {},
      "source": [
        "### Cross-encoder reranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "0d922144",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cross-encoder reranker...\n",
            "✓ Cross-encoder loaded\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(\"Loading cross-encoder reranker...\")\n",
        "reranker = CrossEncoder(\n",
        "    \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "    model_kwargs={\"torch_dtype\": torch.float16},\n",
        "    device=device,\n",
        "    max_length=512,\n",
        ")\n",
        "print(\"✓ Cross-encoder loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2a7a1c3",
      "metadata": {},
      "source": [
        "### Retrieval manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "1d0537dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RetrievalManager(k_docs=100, k_passages=7, RRF_k=60, window=150, overlap=50)\n",
            "1. Harry Potter Harry Potter is a series of fantasy novels written by British author J. K. Rowling. The novels chronicle th...\n",
            "2. J. K. Rowling Joanne Rowling ( \"rolling\"; born 31 July 1965), better known by her pen name J. K. Rowling, is a British n...\n",
            "3. The Magical Worlds of Harry Potter The Magical Worlds of Harry Potter: A Treasury of Myths, Legends, and Fascinating Fac...\n",
            "4. English by two major publishers, Bloomsbury in the United Kingdom and Scholastic Press in the United States. A play, \"Ha...\n",
            "5. the lives of the surviving characters and the effects of Voldemort's death on the Wizarding World. In the epilogue, Harr...\n",
            "6. Fry reading the UK editions and Jim Dale voicing the series for the American editions. Section::::Adaptations.:Stage pro...\n",
            "7. Harry Potter influences and analogues Writer J. K. Rowling cites several writers as influences in her creation of her be...\n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import List, Dict\n",
        "from functools import lru_cache\n",
        "import json\n",
        "\n",
        "@lru_cache(maxsize=1000)\n",
        "def get_doc_content(docid: str) -> str:\n",
        "    \"\"\"Return cached raw document text.\"\"\"\n",
        "    try:\n",
        "        doc = searcher.doc(docid)\n",
        "        return json.loads(doc.raw()).get(\"contents\", \"\").replace(\"\\n\", \" \")\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "    \n",
        "\n",
        "@dataclass\n",
        "class RetrievalManager:\n",
        "    \"\"\"\n",
        "    Hybrid retrieval with:\n",
        "      - BM25 document retrieval\n",
        "      - QLD document retrieval\n",
        "      - RRF on documents (recall stage)\n",
        "      - Passage segmentation\n",
        "      - Cross-encoder passage reranking (precision stage)\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieval\n",
        "    k_docs: int = 100\n",
        "    k_passages: int = 7\n",
        "    rrf_k: int = 60\n",
        "\n",
        "    # BM25 / QLD\n",
        "    mu: int = 1000\n",
        "    k1: float = 0.9\n",
        "    b: float = 0.4\n",
        "\n",
        "    # Passage extraction\n",
        "    window: int = 150\n",
        "    overlap: int = 50\n",
        "    min_passage_words: int = 30\n",
        "\n",
        "    def __str__(self):\n",
        "        return (\n",
        "            f\"RetrievalManager(\"\n",
        "            f\"k_docs={self.k_docs}, k_passages={self.k_passages}, \"\n",
        "            f\"RRF_k={self.rrf_k}, \"\n",
        "            f\"window={self.window}, overlap={self.overlap})\"\n",
        "        )\n",
        "\n",
        "    def extract_passages(self, text: str) -> List[str]:\n",
        "        \"\"\"Split document text into overlapping word windows.\"\"\"\n",
        "        if not text:\n",
        "            return []\n",
        "\n",
        "        words = text.split()\n",
        "        if len(words) < self.min_passage_words:\n",
        "            return []\n",
        "\n",
        "        step = max(1, self.window - self.overlap)\n",
        "        passages = []\n",
        "\n",
        "        for i in range(0, len(words), step):\n",
        "            chunk = words[i:i + self.window]\n",
        "            if len(chunk) < self.min_passage_words:\n",
        "                break\n",
        "            passages.append(\" \".join(chunk))\n",
        "\n",
        "        return passages\n",
        "\n",
        "    def rerank_passages(self, query: str, passages: List[str]) -> List[str]:\n",
        "        \"\"\"Rerank passages using cross-encoder (ordering only).\"\"\"\n",
        "        if not passages:\n",
        "            return []\n",
        "\n",
        "        pairs = [(query, p) for p in passages]\n",
        "        \n",
        "        scores = reranker.predict(\n",
        "            pairs,\n",
        "            batch_size=16,\n",
        "            show_progress_bar=False,\n",
        "        )\n",
        "        \n",
        "        ranked = sorted(\n",
        "            zip(passages, scores),\n",
        "            key=lambda x: x[1],\n",
        "            reverse=True,\n",
        "        )\n",
        "\n",
        "        return [p for p, _ in ranked[:self.k_passages]]\n",
        "    \n",
        "    def retrieve_context(self, query: str) -> List[str]:\n",
        "        \"\"\"Return top answer-bearing passages.\"\"\"\n",
        "\n",
        "        # Lexical retrieval\n",
        "        searcher.set_bm25(self.k1, self.b)\n",
        "        bm25_docids = [h.docid for h in searcher.search(query, self.k_docs)]\n",
        "\n",
        "        searcher.set_qld(self.mu)\n",
        "        qld_docids = [h.docid for h in searcher.search(query, self.k_docs)]\n",
        "\n",
        "        # RRF on documents\n",
        "        doc_scores: Dict[str, float] = {}\n",
        "\n",
        "        for rank, docid in enumerate(bm25_docids):\n",
        "            doc_scores[docid] = doc_scores.get(docid, 0.0) + 1.0 / (self.rrf_k + rank + 1)\n",
        "\n",
        "        for rank, docid in enumerate(qld_docids):\n",
        "            doc_scores[docid] = doc_scores.get(docid, 0.0) + 1.0 / (self.rrf_k + rank + 1)\n",
        "\n",
        "        ranked_docids = sorted(\n",
        "            doc_scores,\n",
        "            key=doc_scores.get,\n",
        "            reverse=True,\n",
        "        )\n",
        "\n",
        "        # Passage extraction\n",
        "        passages: List[str] = []\n",
        "\n",
        "        for docid in ranked_docids:\n",
        "            content = get_doc_content(docid)\n",
        "            if not content:\n",
        "                continue\n",
        "\n",
        "            passages.extend(self.extract_passages(content))\n",
        "\n",
        "            # implicit cap: enough passages for reranking\n",
        "            if len(passages) >= self.k_docs * 5:\n",
        "                break\n",
        "\n",
        "        # Cross-encoder reranking\n",
        "        return self.rerank_passages(query, passages)\n",
        "    \n",
        "\n",
        "query = \"Who wrote Harry Potter?\"\n",
        "\n",
        "rm = RetrievalManager()\n",
        "print(rm)\n",
        "\n",
        "passages = rm.retrieve_context(query)\n",
        "for i, p in enumerate(passages, 1):\n",
        "    print(f\"{i}. {p[:120]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18e849f6",
      "metadata": {},
      "source": [
        "## 4. LLM Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e9df06",
      "metadata": {},
      "source": [
        "### Load LLM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "1b4b616d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading LLM model...\n",
            "✓ Model loaded on: GPU\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import logging\n",
        "\n",
        "# Suppress transformers warnings\n",
        "transformers.logging.set_verbosity_error()\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "print(\"Loading LLM model...\")\n",
        "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.float16},\n",
        "    device=0\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "# Set pad_token for batch processing\n",
        "pipeline.tokenizer.pad_token = pipeline.tokenizer.eos_token\n",
        "\n",
        "print(f\"✓ Model loaded on: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb1fa0d",
      "metadata": {},
      "source": [
        "### Prompt manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "97ae5bdb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing: temp=0.0, top_p=1.0, max_tokens=64\n",
            "✓ Generated answer: 'J. K. Rowling'\n"
          ]
        }
      ],
      "source": [
        "SYSTEM_PROMPT = (\n",
        "    \"You are a strict, grounded Question Answering system.\\n\"\n",
        "    \"You are given documents and a question.\\n\"\n",
        "    \"Answer ONLY using information that appears in the documents.\\n\"\n",
        "    \"Your answer must be ONLY the entity or value that answers the question.\\n\"\n",
        "    \"Do NOT return sentences, clauses, or descriptions.\\n\"\n",
        "    \"If the answer cannot be verified in the documents, return: unknown.\"\n",
        ")\n",
        "\n",
        "\n",
        "USER_PROMPT = (\n",
        "    \"Documents:\\n\"\n",
        "    \"{context}\\n\\n\"\n",
        "    \"Task:\\n\"\n",
        "    \"- Answer the question using only the documents.\\n\"\n",
        "    \"- Return ONE single answer only (not a list or multiple items).\\n\"\n",
        "    \"- The answer must match the question type (person, place, date, number).\\n\"\n",
        "    \"- Return the shortest complete answer that answers the question.\\n\"\n",
        "    \"- The answer must appear verbatim or as a clear entity in the documents.\\n\"\n",
        "    \"- Do NOT return explanations, relations, or full sentences.\\n\"\n",
        "    \"- If you cannot verify the answer in the documents, output: unknown.\\n\\n\"\n",
        "    \"Question: {question}\\n\"\n",
        "    \"Answer:\"\n",
        ")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PromptManager:\n",
        "    \"\"\"Manages prompt generation and LLM answer generation.\"\"\"\n",
        "    system_prompt: str = SYSTEM_PROMPT\n",
        "    user_prompt: str = USER_PROMPT\n",
        "    temperature: float = 0.0\n",
        "    top_p: float = 1.0\n",
        "    max_new_tokens: int = 64\n",
        "    do_sample: bool = False\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"temp={self.temperature}, top_p={self.top_p}, max_tokens={self.max_new_tokens}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_answer(answer: str) -> str:\n",
        "        \"\"\"Clean and standardize the generated answer.\"\"\"\n",
        "        answer = re.sub(r'^(Answer|The answer is|Based on the .*?,):?\\s*', '', answer, flags=re.I)\n",
        "        answer = answer.rstrip('.')\n",
        "        if any(phrase in answer.lower() for phrase in [\"dont know\", \"don't know\", \"do not know\", \"unknown\"]):\n",
        "            return \"unknown\"\n",
        "        return answer.strip()\n",
        "\n",
        "    def create_messages(self, question: str, contexts: List[str]) -> List[Dict]:\n",
        "        \"\"\"Create messages for the LLM based on the question and contexts.\"\"\"\n",
        "        if not contexts:\n",
        "            context_str = \"No relevant documents found.\"\n",
        "        else:\n",
        "            context_str = '\\n\\n'.join([f\"Document {i+1}: {ctx}\" for i, ctx in enumerate(contexts)])\n",
        "        \n",
        "        return [\n",
        "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "            {\"role\": \"user\", \"content\": self.user_prompt.format(context=context_str, question=question)}\n",
        "        ]\n",
        "\n",
        "    def generate_answer(self, question: str, contexts: List[str]) -> str:\n",
        "        \"\"\"Generate an answer using the LLM based on the question and contexts.\"\"\"\n",
        "        messages = self.create_messages(question, contexts)\n",
        "        \n",
        "        outputs = pipeline(\n",
        "            messages,\n",
        "            max_new_tokens=self.max_new_tokens,\n",
        "            eos_token_id=terminators,\n",
        "            do_sample=self.do_sample,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p\n",
        "        )\n",
        "        \n",
        "        answer = outputs[0][\"generated_text\"][-1].get('content', '')\n",
        "        return self.clean_answer(answer)\n",
        "\n",
        "\n",
        "test_prompt_manager = PromptManager()\n",
        "print(f\"Testing: {test_prompt_manager}\")\n",
        "test_answer = test_prompt_manager.generate_answer(query, passages)\n",
        "print(f\"✓ Generated answer: '{test_answer}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7873c1ef",
      "metadata": {},
      "source": [
        "## 5. Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "d9b4c8a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Evaluation test: F1=66.67, P=66.67, R=66.67, EM=66.67\n"
          ]
        }
      ],
      "source": [
        "def normalize_answer(s: str) -> str:\n",
        "    \"\"\"Normalize answer for comparison\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "    \n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "    \n",
        "    def remove_punc(text):\n",
        "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
        "    \n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "    \n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def compute_token_metrics(prediction: str, ground_truth: str) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Compute precision, recall, and F1 score for token-level comparison.\n",
        "    Returns: (precision, recall, f1)\n",
        "    \"\"\"\n",
        "    pred_tokens = normalize_answer(prediction).split()\n",
        "    gt_tokens = normalize_answer(ground_truth).split()\n",
        "    \n",
        "    # Handle empty cases\n",
        "    if len(pred_tokens) == 0 or len(gt_tokens) == 0:\n",
        "        match = int(pred_tokens == gt_tokens)\n",
        "        return match, match, match\n",
        "    \n",
        "    # Compute overlap\n",
        "    common = Counter(pred_tokens) & Counter(gt_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    \n",
        "    if num_same == 0:\n",
        "        return 0.0, 0.0, 0.0\n",
        "    \n",
        "    precision = num_same / len(pred_tokens)\n",
        "    recall = num_same / len(gt_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    \n",
        "    return precision, recall, f1\n",
        "\n",
        "\n",
        "def evaluate_predictions(df_gold: pd.DataFrame, predictions: Dict[int, str]) -> Dict:\n",
        "    \"\"\"Evaluate predictions against ground truth.\"\"\"\n",
        "    f1_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    exact_matches = []\n",
        "    \n",
        "    for _, row in df_gold.iterrows():\n",
        "        qid = row['id']\n",
        "        \n",
        "        # Handle missing predictions\n",
        "        if qid not in predictions:\n",
        "            f1_scores.append(0.0)\n",
        "            precision_scores.append(0.0)\n",
        "            recall_scores.append(0.0)\n",
        "            exact_matches.append(0)\n",
        "            continue\n",
        "        \n",
        "        prediction = predictions[qid]\n",
        "        ground_truths = row['answers']\n",
        "        \n",
        "        # Normalize once\n",
        "        norm_prediction = normalize_answer(prediction)\n",
        "        \n",
        "        # Find best match across all ground truths\n",
        "        best_f1 = 0.0\n",
        "        best_precision = 0.0\n",
        "        best_recall = 0.0\n",
        "        is_exact = 0\n",
        "        \n",
        "        for gt in ground_truths:\n",
        "            norm_gt = normalize_answer(gt)\n",
        "            \n",
        "            # Compute metrics\n",
        "            prec, rec, f1 = compute_token_metrics(prediction, gt)\n",
        "            \n",
        "            # Track best scores\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_precision = prec\n",
        "                best_recall = rec\n",
        "            \n",
        "            # Check exact match\n",
        "            if norm_prediction == norm_gt:\n",
        "                is_exact = 1\n",
        "        \n",
        "        f1_scores.append(best_f1)\n",
        "        precision_scores.append(best_precision)\n",
        "        recall_scores.append(best_recall)\n",
        "        exact_matches.append(is_exact)\n",
        "    \n",
        "    return {\n",
        "        'f1': 100.0 * sum(f1_scores) / len(f1_scores) if f1_scores else 0.0,\n",
        "        'precision': 100.0 * sum(precision_scores) / len(precision_scores) if precision_scores else 0.0,\n",
        "        'recall': 100.0 * sum(recall_scores) / len(recall_scores) if recall_scores else 0.0,\n",
        "        'exact_match': 100.0 * sum(exact_matches) / len(exact_matches) if exact_matches else 0.0,\n",
        "        'f1_scores': f1_scores,\n",
        "        'precision_scores': precision_scores,\n",
        "        'recall_scores': recall_scores,\n",
        "        'exact_matches': exact_matches\n",
        "    }\n",
        "\n",
        "\n",
        "# Test evaluation\n",
        "test_predictions = {1: \"J.K. Rowling\", 2: \"Paris\", 3: \"Shakespeare\"}\n",
        "test_gold = pd.DataFrame({\n",
        "    'id': [1, 2, 3],\n",
        "    'answers': [[\"J.K. Rowling\", \"Rowling\"], [\"Earth\"], [\"William Shakespeare\", \"Shakespeare\"]]\n",
        "})\n",
        "\n",
        "test_metrics = evaluate_predictions(test_gold, test_predictions)\n",
        "print(f\"✓ Evaluation test: F1={test_metrics['f1']:.2f}, P={test_metrics['precision']:.2f}, R={test_metrics['recall']:.2f}, EM={test_metrics['exact_match']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4956e446",
      "metadata": {},
      "source": [
        "## 6. Experiment Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "721292c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing experiment with:\n",
            "  Retrieval: RetrievalManager(k_docs=100, k_passages=7, RRF_k=60, window=150, overlap=50)\n",
            "  Prompt: temp=0.0, top_p=1.0, max_tokens=64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quick Test: 100%|██████████| 25/25 [01:57<00:00,  4.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quick Test\n",
            "   Retrieval: RetrievalManager(k_docs=100, k_passages=7, RRF_k=60, window=150, overlap=50)\n",
            "   Prompt: temp=0.0, top_p=1.0, max_tokens=64\n",
            "   F1=30.33 | P=36.00 | R=27.73 | EM=20.00\n",
            "   Questions: 25\n",
            "\n",
            "✓ Experiment framework ready\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def run_experiment(\n",
        "    name: str,\n",
        "    df_data: pd.DataFrame,\n",
        "    retrieval_manager: RetrievalManager,\n",
        "    prompt_manager: PromptManager,\n",
        "    max_questions: Optional[int] = None,\n",
        "    verbose: bool = True\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Run a full experiment: retrieval + prompting + evaluation.\n",
        "    Args:\n",
        "        name: Name of the experiment.\n",
        "        df_data: DataFrame with questions and answers.\n",
        "        retrieval_manager: RetrievalManager instance.\n",
        "        prompt_manager: PromptManager instance.\n",
        "        max_questions: Optional limit on number of questions to process.\n",
        "        verbose: Whether to print progress and results.\n",
        "    \"\"\"\n",
        "    if max_questions:\n",
        "        df_data = df_data.head(max_questions)\n",
        "\n",
        "    predictions = {}\n",
        "\n",
        "    iterator = tqdm(df_data.iterrows(), total=len(df_data), desc=name) if verbose else df_data.iterrows()\n",
        "\n",
        "    for _, row in iterator:\n",
        "        question = row['question']\n",
        "        qid = row['id']\n",
        "\n",
        "        contexts = retrieval_manager.retrieve_context(question)\n",
        "        answer = prompt_manager.generate_answer(question, contexts)\n",
        "\n",
        "        predictions[qid] = answer\n",
        "\n",
        "    metrics = evaluate_predictions(df_data, predictions)\n",
        "\n",
        "    result = {\n",
        "        'name': name,\n",
        "        'retrieval': retrieval_manager,\n",
        "        'prompt': prompt_manager,\n",
        "        'f1_score': metrics['f1'],\n",
        "        'precision': metrics['precision'],\n",
        "        'recall': metrics['recall'],\n",
        "        'exact_match': metrics['exact_match'],\n",
        "        'num_questions': len(df_data),\n",
        "        'predictions': predictions,\n",
        "        'f1_scores': metrics['f1_scores'],\n",
        "        'precision_scores': metrics['precision_scores'],\n",
        "        'recall_scores': metrics['recall_scores'],\n",
        "        'exact_matches': metrics['exact_matches']\n",
        "    }\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n{name}\")\n",
        "        print(f\"   Retrieval: {retrieval_manager}\")\n",
        "        print(f\"   Prompt: {prompt_manager}\")\n",
        "        print(\n",
        "            f\"   F1={metrics['f1']:.2f} | \"\n",
        "            f\"P={metrics['precision']:.2f} | \"\n",
        "            f\"R={metrics['recall']:.2f} | \"\n",
        "            f\"EM={metrics['exact_match']:.2f}\"\n",
        "        )\n",
        "        print(f\"   Questions: {len(df_data)}\\n\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "test_retrieval = RetrievalManager()\n",
        "test_prompt = PromptManager()\n",
        "print(f\"Testing experiment with:\")\n",
        "print(f\"  Retrieval: {test_retrieval}\")\n",
        "print(f\"  Prompt: {test_prompt}\")\n",
        "\n",
        "test_exp = run_experiment(\n",
        "    \"Quick Test\",\n",
        "    df_train.head(25),\n",
        "    test_retrieval,\n",
        "    test_prompt,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"✓ Experiment framework ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b78eead",
      "metadata": {},
      "source": [
        "## 7. Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c54f379",
      "metadata": {},
      "source": [
        "### Experiments global config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ac8c7605",
      "metadata": {},
      "outputs": [],
      "source": [
        "EXPERIMENT_SEED = 42\n",
        "EXPERIMENTS_NUM_QUESTIONS = 100\n",
        "DEFAULT_PROMPT_MANAGER = PromptManager()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09e9a89e",
      "metadata": {},
      "source": [
        "### Experiments utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "d4d8b47a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_experiment_log_path(num_questions: int) -> str:\n",
        "    \"\"\"Get path for experiment log CSV based on number of questions.\"\"\"\n",
        "    return f\"./results/grid_search_results_q{num_questions}.csv\"\n",
        "\n",
        "\n",
        "def generate_config_key(\n",
        "    retrieval_mgr: RetrievalManager,\n",
        "    prompt_mgr: PromptManager,\n",
        ") -> str:\n",
        "    \"\"\"Generate unique config key for RRF-based retrieval.\"\"\"\n",
        "    return (\n",
        "        f\"RRF_k{retrieval_mgr.rrf_k}_\"\n",
        "        f\"mu{retrieval_mgr.mu}_\"\n",
        "        f\"k1{retrieval_mgr.k1}_b{retrieval_mgr.b}_\"\n",
        "        f\"kdocs{retrieval_mgr.k_docs}_\"\n",
        "        f\"kpass{retrieval_mgr.k_passages}_\"\n",
        "        f\"win{retrieval_mgr.window}_ovl{retrieval_mgr.overlap}\"\n",
        "    )\n",
        "    \n",
        "    \n",
        "def build_retrieval_manager(base: dict, override: dict) -> RetrievalManager:\n",
        "    \"\"\"Build RetrievalManager safely.\"\"\"\n",
        "    return RetrievalManager(**{**base, **override})\n",
        "\n",
        "\n",
        "def save_results_to_csv(result: dict, key: str, path: str):\n",
        "    \"\"\"Save experiment results to a CSV file.\"\"\"\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "\n",
        "    row = {\n",
        "        \"config_key\": key,\n",
        "        \"f1\": result[\"f1_score\"],\n",
        "        \"precision\": result[\"precision\"],\n",
        "        \"recall\": result[\"recall\"],\n",
        "        \"exact_match\": result[\"exact_match\"],\n",
        "        \"num_questions\": result[\"num_questions\"],\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame([row])\n",
        "    if not os.path.exists(path):\n",
        "        df.to_csv(path, index=False)\n",
        "    else:\n",
        "        df.to_csv(path, mode=\"a\", header=False, index=False)\n",
        "\n",
        "\n",
        "def load_completed_configs(path: str) -> set[str]:\n",
        "    \"\"\"Load set of completed experiment config keys from CSV.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        return set()\n",
        "    return set(pd.read_csv(path)[\"config_key\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fc59d56",
      "metadata": {},
      "source": [
        "### Print utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "03274a4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_grid_results_table(grid: list[dict], *, num_questions: int):\n",
        "    \"\"\"Print results table for a given experiment grid.\"\"\"\n",
        "    pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "    path = get_experiment_log_path(num_questions)\n",
        "    if not os.path.exists(path):\n",
        "        print(\"No results file found.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    keys = [\n",
        "        generate_config_key(g[\"retrieval_mgr\"], g[\"prompt_mgr\"])\n",
        "        for g in grid\n",
        "    ]\n",
        "\n",
        "    grid_df = (\n",
        "        df[df[\"config_key\"].isin(keys)]\n",
        "        .sort_values(\"f1\", ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    if grid_df.empty:\n",
        "        print(\"No completed configs found for this grid.\")\n",
        "        return\n",
        "\n",
        "    display_cols = [\n",
        "        \"config_key\",\n",
        "        \"f1\",\n",
        "        \"precision\",\n",
        "        \"recall\",\n",
        "        \"exact_match\",\n",
        "    ]\n",
        "\n",
        "    print(\"\\nGrid results (sorted by F1):\")\n",
        "    display(grid_df[display_cols])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb074e07",
      "metadata": {},
      "source": [
        "### Best-config selector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "987015b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_top_k_configs(\n",
        "    retrieval_managers: list[RetrievalManager],\n",
        "    prompt_managers: list[PromptManager],\n",
        "    *,\n",
        "    num_questions: int,\n",
        "    top_k: int = 5,\n",
        "):\n",
        "    \"\"\"Select top-k configurations from experiment results.\"\"\"\n",
        "    path = get_experiment_log_path(num_questions)\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    scored_entries = []\n",
        "\n",
        "    for r_mgr, p_mgr in zip(retrieval_managers, prompt_managers):\n",
        "        key = generate_config_key(r_mgr, p_mgr)\n",
        "        row = df[df[\"config_key\"] == key]\n",
        "        if row.empty:\n",
        "            continue\n",
        "\n",
        "        scored_entries.append({\n",
        "            \"retrieval_mgr\": r_mgr,\n",
        "            \"prompt_mgr\": p_mgr,\n",
        "            \"f1\": float(row.iloc[0][\"f1\"]),\n",
        "            \"config_key\": key,\n",
        "        })\n",
        "\n",
        "    scored_entries.sort(\n",
        "        key=lambda x: (x[\"f1\"], x[\"config_key\"]),\n",
        "        reverse=True,\n",
        "    )\n",
        "\n",
        "    return scored_entries[:top_k]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d7f416f",
      "metadata": {},
      "source": [
        "### Phase runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "827db996",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_phase(\n",
        "    *,\n",
        "    phase_name: str,\n",
        "    grid: list[dict],\n",
        "    df_train: pd.DataFrame,\n",
        "    num_questions: int,\n",
        "    top_k: int | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Run a phase of experiments over a grid of configurations.\n",
        "    Args:\n",
        "        phase_name: Name of the experiment phase.\n",
        "        grid: List of configurations (dicts with 'retrieval_mgr' and 'prompt_mgr').\n",
        "        df_train: DataFrame with training questions and answers.\n",
        "        num_questions: Number of questions to use per configuration.\n",
        "        top_k: If specified, return only the top-k configurations after running.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(phase_name)\n",
        "    print(f\"Questions per config: {num_questions}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    path = get_experiment_log_path(num_questions)\n",
        "\n",
        "    validation_data = df_train.sample(\n",
        "        n=num_questions,\n",
        "        random_state=EXPERIMENT_SEED,\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    completed = load_completed_configs(path)\n",
        "\n",
        "    pending = [\n",
        "        g for g in grid\n",
        "        if generate_config_key(g[\"retrieval_mgr\"], g[\"prompt_mgr\"]) not in completed\n",
        "    ]\n",
        "\n",
        "    print(f\"Total configs: {len(grid)}\")\n",
        "    print(f\"Completed: {len(grid) - len(pending)}\")\n",
        "    print(f\"Pending: {len(pending)}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for i, entry in enumerate(pending, start=1):\n",
        "        r_mgr = entry[\"retrieval_mgr\"]\n",
        "        p_mgr = entry[\"prompt_mgr\"]\n",
        "        key = generate_config_key(r_mgr, p_mgr)\n",
        "\n",
        "        print(f\"[{i}/{len(pending)}] Running: {key}\")\n",
        "\n",
        "        result = run_experiment(\n",
        "            name=key,\n",
        "            df_data=validation_data,\n",
        "            retrieval_manager=r_mgr,\n",
        "            prompt_manager=p_mgr,\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "        save_results_to_csv(result, key, path)\n",
        "        print(f\"✓ F1={result['f1_score']:.4f}\")\n",
        "\n",
        "    print_grid_results_table(grid, num_questions=num_questions)\n",
        "\n",
        "    if top_k is None:\n",
        "        return grid\n",
        "\n",
        "    return select_top_k_configs(\n",
        "        [g[\"retrieval_mgr\"] for g in grid],\n",
        "        [g[\"prompt_mgr\"] for g in grid],\n",
        "        num_questions=num_questions,\n",
        "        top_k=top_k,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205277ae",
      "metadata": {},
      "source": [
        "### Phase 1 - Capacity (k_docs / k_passages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "03cdf5ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PHASE 1 — Retrieval Capacity\n",
            "Questions per config: 100\n",
            "================================================================================\n",
            "Total configs: 15\n",
            "Completed: 15\n",
            "Pending: 0\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Grid results (sorted by F1):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>config_key</th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>exact_match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>34.382749</td>\n",
              "      <td>38.434524</td>\n",
              "      <td>34.100000</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win150_ovl50</td>\n",
              "      <td>33.289076</td>\n",
              "      <td>36.833333</td>\n",
              "      <td>32.933333</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win150_ovl50</td>\n",
              "      <td>32.163701</td>\n",
              "      <td>34.758766</td>\n",
              "      <td>32.933333</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass7_win150_ovl50</td>\n",
              "      <td>31.639891</td>\n",
              "      <td>35.047727</td>\n",
              "      <td>32.600000</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs50_kpass10_win150_ovl50</td>\n",
              "      <td>30.414461</td>\n",
              "      <td>34.841782</td>\n",
              "      <td>30.433333</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass7_win150_ovl50</td>\n",
              "      <td>28.314412</td>\n",
              "      <td>32.123214</td>\n",
              "      <td>29.516667</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs100_kpass10_win150_ovl50</td>\n",
              "      <td>27.426702</td>\n",
              "      <td>31.623462</td>\n",
              "      <td>28.850000</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass10_win150_ovl50</td>\n",
              "      <td>26.462324</td>\n",
              "      <td>30.593452</td>\n",
              "      <td>26.742857</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs100_kpass7_win150_ovl50</td>\n",
              "      <td>26.452391</td>\n",
              "      <td>28.940591</td>\n",
              "      <td>28.350000</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs100_kpass5_win150_ovl50</td>\n",
              "      <td>26.335129</td>\n",
              "      <td>29.825000</td>\n",
              "      <td>26.850000</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs50_kpass5_win150_ovl50</td>\n",
              "      <td>26.032440</td>\n",
              "      <td>29.429798</td>\n",
              "      <td>27.600000</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs10_kpass5_win150_ovl50</td>\n",
              "      <td>25.007879</td>\n",
              "      <td>27.016667</td>\n",
              "      <td>26.492857</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs50_kpass7_win150_ovl50</td>\n",
              "      <td>24.125595</td>\n",
              "      <td>27.998925</td>\n",
              "      <td>25.433333</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs10_kpass7_win150_ovl50</td>\n",
              "      <td>22.550469</td>\n",
              "      <td>24.627778</td>\n",
              "      <td>24.266667</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs10_kpass10_win150_ovl50</td>\n",
              "      <td>22.338095</td>\n",
              "      <td>24.250000</td>\n",
              "      <td>22.350000</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 config_key         f1  \\\n",
              "0    RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50  34.382749   \n",
              "1   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win150_ovl50  33.289076   \n",
              "2    RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win150_ovl50  32.163701   \n",
              "3    RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass7_win150_ovl50  31.639891   \n",
              "4    RRF_k60_mu1000_k10.9_b0.4_kdocs50_kpass10_win150_ovl50  30.414461   \n",
              "5    RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass7_win150_ovl50  28.314412   \n",
              "6   RRF_k60_mu1000_k10.9_b0.4_kdocs100_kpass10_win150_ovl50  27.426702   \n",
              "7   RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass10_win150_ovl50  26.462324   \n",
              "8    RRF_k60_mu1000_k10.9_b0.4_kdocs100_kpass7_win150_ovl50  26.452391   \n",
              "9    RRF_k60_mu1000_k10.9_b0.4_kdocs100_kpass5_win150_ovl50  26.335129   \n",
              "10    RRF_k60_mu1000_k10.9_b0.4_kdocs50_kpass5_win150_ovl50  26.032440   \n",
              "11    RRF_k60_mu1000_k10.9_b0.4_kdocs10_kpass5_win150_ovl50  25.007879   \n",
              "12    RRF_k60_mu1000_k10.9_b0.4_kdocs50_kpass7_win150_ovl50  24.125595   \n",
              "13    RRF_k60_mu1000_k10.9_b0.4_kdocs10_kpass7_win150_ovl50  22.550469   \n",
              "14   RRF_k60_mu1000_k10.9_b0.4_kdocs10_kpass10_win150_ovl50  22.338095   \n",
              "\n",
              "    precision     recall  exact_match  \n",
              "0   38.434524  34.100000         22.0  \n",
              "1   36.833333  32.933333         21.0  \n",
              "2   34.758766  32.933333         20.0  \n",
              "3   35.047727  32.600000         17.0  \n",
              "4   34.841782  30.433333         17.0  \n",
              "5   32.123214  29.516667         15.0  \n",
              "6   31.623462  28.850000         14.0  \n",
              "7   30.593452  26.742857         14.0  \n",
              "8   28.940591  28.350000         14.0  \n",
              "9   29.825000  26.850000         14.0  \n",
              "10  29.429798  27.600000         13.0  \n",
              "11  27.016667  26.492857         13.0  \n",
              "12  27.998925  25.433333         11.0  \n",
              "13  24.627778  24.266667         12.0  \n",
              "14  24.250000  22.350000         14.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PHASE_1_GRID = []\n",
        "\n",
        "BASE_RETRIEVAL_PARAMS = {\n",
        "    \"window\": 150,\n",
        "    \"overlap\": 50,\n",
        "    \"mu\": 1000,\n",
        "    \"k1\": 0.9,\n",
        "    \"b\": 0.4,\n",
        "}\n",
        "\n",
        "K_DOCS = [10, 50, 100, 250, 500]\n",
        "K_PASSAGES = [5, 7, 10]\n",
        "\n",
        "CAPACITY_PAIRS = [\n",
        "    (k_docs, k_passages)\n",
        "    for k_docs in K_DOCS\n",
        "    for k_passages in K_PASSAGES\n",
        "]\n",
        "\n",
        "for k_docs, k_passages in CAPACITY_PAIRS:\n",
        "    PHASE_1_GRID.append({\n",
        "        \"retrieval_mgr\": RetrievalManager(\n",
        "            k_docs=k_docs,\n",
        "            k_passages=k_passages,\n",
        "            **BASE_RETRIEVAL_PARAMS,\n",
        "        ),\n",
        "        \"prompt_mgr\": DEFAULT_PROMPT_MANAGER,\n",
        "    })\n",
        "\n",
        "PHASE_1_TOP_CONFIGS = run_phase(\n",
        "    phase_name=\"PHASE 1 — Retrieval Capacity\",\n",
        "    grid=PHASE_1_GRID,\n",
        "    df_train=df_train,\n",
        "    num_questions=EXPERIMENTS_NUM_QUESTIONS,\n",
        "    top_k=3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30605bd4",
      "metadata": {},
      "source": [
        "### Phase 2 - Passage segmentation (window / overlap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "86e95ad9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PHASE 2 — Passage Segmentation\n",
            "Questions per config: 100\n",
            "================================================================================\n",
            "Total configs: 12\n",
            "Completed: 12\n",
            "Pending: 0\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Grid results (sorted by F1):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>config_key</th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>exact_match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>34.382749</td>\n",
              "      <td>38.434524</td>\n",
              "      <td>34.100000</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win250_ovl60</td>\n",
              "      <td>33.762698</td>\n",
              "      <td>37.403846</td>\n",
              "      <td>33.350000</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>33.656606</td>\n",
              "      <td>35.162500</td>\n",
              "      <td>34.766667</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win200_ovl50</td>\n",
              "      <td>33.610317</td>\n",
              "      <td>36.775000</td>\n",
              "      <td>33.266667</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win150_ovl50</td>\n",
              "      <td>33.289076</td>\n",
              "      <td>36.833333</td>\n",
              "      <td>32.933333</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win200_ovl50</td>\n",
              "      <td>32.956606</td>\n",
              "      <td>34.829167</td>\n",
              "      <td>33.766667</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win150_ovl50</td>\n",
              "      <td>32.163701</td>\n",
              "      <td>34.758766</td>\n",
              "      <td>32.933333</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win250_ovl60</td>\n",
              "      <td>31.002525</td>\n",
              "      <td>33.622222</td>\n",
              "      <td>31.433333</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win100_ovl30</td>\n",
              "      <td>30.872619</td>\n",
              "      <td>33.450000</td>\n",
              "      <td>32.266667</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win250_ovl60</td>\n",
              "      <td>27.988889</td>\n",
              "      <td>30.034799</td>\n",
              "      <td>28.766667</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win100_ovl30</td>\n",
              "      <td>27.645950</td>\n",
              "      <td>29.519048</td>\n",
              "      <td>29.433333</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win100_ovl30</td>\n",
              "      <td>27.326984</td>\n",
              "      <td>29.433333</td>\n",
              "      <td>28.266667</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 config_key         f1  \\\n",
              "0    RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50  34.382749   \n",
              "1    RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win250_ovl60  33.762698   \n",
              "2    RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win200_ovl50  33.656606   \n",
              "3   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win200_ovl50  33.610317   \n",
              "4   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win150_ovl50  33.289076   \n",
              "5    RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win200_ovl50  32.956606   \n",
              "6    RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win150_ovl50  32.163701   \n",
              "7   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win250_ovl60  31.002525   \n",
              "8   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win100_ovl30  30.872619   \n",
              "9    RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win250_ovl60  27.988889   \n",
              "10   RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win100_ovl30  27.645950   \n",
              "11   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win100_ovl30  27.326984   \n",
              "\n",
              "    precision     recall  exact_match  \n",
              "0   38.434524  34.100000         22.0  \n",
              "1   37.403846  33.350000         22.0  \n",
              "2   35.162500  34.766667         23.0  \n",
              "3   36.775000  33.266667         24.0  \n",
              "4   36.833333  32.933333         21.0  \n",
              "5   34.829167  33.766667         22.0  \n",
              "6   34.758766  32.933333         20.0  \n",
              "7   33.622222  31.433333         19.0  \n",
              "8   33.450000  32.266667         20.0  \n",
              "9   30.034799  28.766667         18.0  \n",
              "10  29.519048  29.433333         18.0  \n",
              "11  29.433333  28.266667         16.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PHASE_2_GRID = []\n",
        "\n",
        "WINDOW_OVERLAP_PAIRS = [\n",
        "    (100, 30),\n",
        "    (150, 50),\n",
        "    (200, 50),\n",
        "    (250, 60),\n",
        "]\n",
        "\n",
        "for entry in PHASE_1_TOP_CONFIGS:\n",
        "    base = entry[\"retrieval_mgr\"]\n",
        "    for w, o in WINDOW_OVERLAP_PAIRS:\n",
        "        PHASE_2_GRID.append({\n",
        "            \"retrieval_mgr\": RetrievalManager(\n",
        "                k_docs=base.k_docs,\n",
        "                k_passages=base.k_passages,\n",
        "                window=w,\n",
        "                overlap=o,\n",
        "                mu=base.mu,\n",
        "                k1=base.k1,\n",
        "                b=base.b,\n",
        "            ),\n",
        "            \"prompt_mgr\": DEFAULT_PROMPT_MANAGER,\n",
        "        })\n",
        "\n",
        "PHASE_2_TOP_CONFIGS = run_phase(\n",
        "    phase_name=\"PHASE 2 — Passage Segmentation\",\n",
        "    grid=PHASE_2_GRID,\n",
        "    df_train=df_train,\n",
        "    num_questions=EXPERIMENTS_NUM_QUESTIONS,\n",
        "    top_k=3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc13a845",
      "metadata": {},
      "source": [
        "### Phase 3 - BM25 / QLD parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "f47ad0b5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PHASE 3 — Lexical Hyperparameters\n",
            "Questions per config: 100\n",
            "================================================================================\n",
            "Total configs: 18\n",
            "Completed: 18\n",
            "Pending: 0\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Grid results (sorted by F1):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>config_key</th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>exact_match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RRF_k60_mu1000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>36.616082</td>\n",
              "      <td>40.791667</td>\n",
              "      <td>36.766667</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RRF_k60_mu2000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>34.949415</td>\n",
              "      <td>39.291667</td>\n",
              "      <td>34.766667</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RRF_k60_mu2000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>34.847082</td>\n",
              "      <td>37.245833</td>\n",
              "      <td>34.766667</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>34.382749</td>\n",
              "      <td>38.434524</td>\n",
              "      <td>34.100000</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>33.789940</td>\n",
              "      <td>35.829167</td>\n",
              "      <td>34.266667</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win250_ovl60</td>\n",
              "      <td>33.762698</td>\n",
              "      <td>37.403846</td>\n",
              "      <td>33.350000</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RRF_k60_mu1000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>33.680416</td>\n",
              "      <td>35.579167</td>\n",
              "      <td>34.266667</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>33.656606</td>\n",
              "      <td>35.162500</td>\n",
              "      <td>34.766667</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>33.489940</td>\n",
              "      <td>35.329167</td>\n",
              "      <td>34.100000</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RRF_k60_mu1000_k11.2_b0.6_kdocs500_kpass5_win250_ovl60</td>\n",
              "      <td>33.096032</td>\n",
              "      <td>36.103846</td>\n",
              "      <td>33.600000</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RRF_k60_mu2000_k11.2_b0.6_kdocs500_kpass5_win250_ovl60</td>\n",
              "      <td>32.929365</td>\n",
              "      <td>35.903846</td>\n",
              "      <td>32.850000</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RRF_k60_mu2000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>32.346241</td>\n",
              "      <td>35.875000</td>\n",
              "      <td>32.433333</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RRF_k60_mu2000_k10.9_b0.4_kdocs500_kpass5_win250_ovl60</td>\n",
              "      <td>30.972222</td>\n",
              "      <td>34.606227</td>\n",
              "      <td>30.683333</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RRF_k60_mu2000_k10.9_b0.4_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>30.823273</td>\n",
              "      <td>31.829167</td>\n",
              "      <td>31.766667</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win250_ovl60</td>\n",
              "      <td>30.738889</td>\n",
              "      <td>34.034799</td>\n",
              "      <td>30.766667</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RRF_k60_mu1000_k10.6_b0.3_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>30.101796</td>\n",
              "      <td>33.541667</td>\n",
              "      <td>30.100000</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RRF_k60_mu2000_k10.6_b0.3_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>28.879574</td>\n",
              "      <td>32.291667</td>\n",
              "      <td>28.850000</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win250_ovl60</td>\n",
              "      <td>28.488889</td>\n",
              "      <td>31.534799</td>\n",
              "      <td>28.600000</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                config_key         f1  \\\n",
              "0   RRF_k60_mu1000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50  36.616082   \n",
              "1   RRF_k60_mu2000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50  34.949415   \n",
              "2   RRF_k60_mu2000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50  34.847082   \n",
              "3   RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50  34.382749   \n",
              "4   RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50  33.789940   \n",
              "5   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win250_ovl60  33.762698   \n",
              "6   RRF_k60_mu1000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50  33.680416   \n",
              "7   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win200_ovl50  33.656606   \n",
              "8   RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50  33.489940   \n",
              "9   RRF_k60_mu1000_k11.2_b0.6_kdocs500_kpass5_win250_ovl60  33.096032   \n",
              "10  RRF_k60_mu2000_k11.2_b0.6_kdocs500_kpass5_win250_ovl60  32.929365   \n",
              "11  RRF_k60_mu2000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50  32.346241   \n",
              "12  RRF_k60_mu2000_k10.9_b0.4_kdocs500_kpass5_win250_ovl60  30.972222   \n",
              "13  RRF_k60_mu2000_k10.9_b0.4_kdocs500_kpass5_win200_ovl50  30.823273   \n",
              "14  RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win250_ovl60  30.738889   \n",
              "15  RRF_k60_mu1000_k10.6_b0.3_kdocs250_kpass5_win150_ovl50  30.101796   \n",
              "16  RRF_k60_mu2000_k10.6_b0.3_kdocs250_kpass5_win150_ovl50  28.879574   \n",
              "17  RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win250_ovl60  28.488889   \n",
              "\n",
              "    precision     recall  exact_match  \n",
              "0   40.791667  36.766667         22.0  \n",
              "1   39.291667  34.766667         21.0  \n",
              "2   37.245833  34.766667         24.0  \n",
              "3   38.434524  34.100000         22.0  \n",
              "4   35.829167  34.266667         23.0  \n",
              "5   37.403846  33.350000         22.0  \n",
              "6   35.579167  34.266667         23.0  \n",
              "7   35.162500  34.766667         23.0  \n",
              "8   35.329167  34.100000         24.0  \n",
              "9   36.103846  33.600000         22.0  \n",
              "10  35.903846  32.850000         23.0  \n",
              "11  35.875000  32.433333         20.0  \n",
              "12  34.606227  30.683333         20.0  \n",
              "13  31.829167  31.766667         22.0  \n",
              "14  34.034799  30.766667         19.0  \n",
              "15  33.541667  30.100000         19.0  \n",
              "16  32.291667  28.850000         18.0  \n",
              "17  31.534799  28.600000         18.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PHASE_3_GRID = []\n",
        "\n",
        "BM25_PARAMS = [\n",
        "    {\"k1\": 0.6, \"b\": 0.3},\n",
        "    {\"k1\": 0.9, \"b\": 0.4},\n",
        "    {\"k1\": 1.2, \"b\": 0.6},\n",
        "]\n",
        "\n",
        "QLD_PARAMS = [\n",
        "    {\"mu\": 1000},\n",
        "    {\"mu\": 2000},\n",
        "]\n",
        "\n",
        "for entry in PHASE_2_TOP_CONFIGS:\n",
        "    base = entry[\"retrieval_mgr\"]\n",
        "    for bm25 in BM25_PARAMS:\n",
        "        for qld in QLD_PARAMS:\n",
        "            PHASE_3_GRID.append({\n",
        "                \"retrieval_mgr\": RetrievalManager(\n",
        "                    k_docs=base.k_docs,\n",
        "                    k_passages=base.k_passages,\n",
        "                    window=base.window,\n",
        "                    overlap=base.overlap,\n",
        "                    k1=bm25[\"k1\"],\n",
        "                    b=bm25[\"b\"],\n",
        "                    mu=qld[\"mu\"],\n",
        "                ),\n",
        "                \"prompt_mgr\": DEFAULT_PROMPT_MANAGER,\n",
        "            })\n",
        "\n",
        "PHASE_3_TOP_CONFIGS = run_phase(\n",
        "    phase_name=\"PHASE 3 — Lexical Hyperparameters\",\n",
        "    grid=PHASE_3_GRID,\n",
        "    df_train=df_train,\n",
        "    num_questions=EXPERIMENTS_NUM_QUESTIONS,\n",
        "    top_k=None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4544d5ca",
      "metadata": {},
      "source": [
        "### Phase 4 - Best configs comparison over more questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "4a904e38",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1 (100q): 36.6161\n",
            "Promotion threshold: 32.9545 (90% of best)\n",
            "\n",
            "Promoted configs: 10\n",
            "1. RRF_k60_mu1000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50 | F1=36.6161\n",
            "2. RRF_k60_mu2000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50 | F1=34.9494\n",
            "3. RRF_k60_mu2000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50 | F1=34.8471\n",
            "4. RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50 | F1=34.3827\n",
            "5. RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50 | F1=33.7899\n",
            "6. RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win250_ovl60 | F1=33.7627\n",
            "7. RRF_k60_mu1000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50 | F1=33.6804\n",
            "8. RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win200_ovl50 | F1=33.6566\n",
            "9. RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win200_ovl50 | F1=33.6103\n",
            "10. RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50 | F1=33.4899\n"
          ]
        }
      ],
      "source": [
        "PHASE_4_F1_RATIO = 0.90          # promote configs within 90% of best\n",
        "PHASE_4_MAX = 10                 # safety cap\n",
        "PHASE_4_NUM_QUESTIONS = 300\n",
        "\n",
        "experiments_path = get_experiment_log_path(\n",
        "    num_questions=EXPERIMENTS_NUM_QUESTIONS\n",
        ")\n",
        "experiments_df = pd.read_csv(experiments_path)\n",
        "\n",
        "assert not experiments_df.empty, \"No results found for experiments\"\n",
        "\n",
        "# Sort globally by F1\n",
        "experiments_df = experiments_df.sort_values(\n",
        "    \"f1\", ascending=False\n",
        ").reset_index(drop=True)\n",
        "\n",
        "best_f1 = experiments_df.iloc[0][\"f1\"]\n",
        "threshold_f1 = best_f1 * PHASE_4_F1_RATIO\n",
        "\n",
        "print(f\"Best F1 ({EXPERIMENTS_NUM_QUESTIONS}q): {best_f1:.4f}\")\n",
        "print(f\"Promotion threshold: {threshold_f1:.4f} \"\n",
        "      f\"({PHASE_4_F1_RATIO:.0%} of best)\")\n",
        "\n",
        "# Promote configs close by ratio\n",
        "promoted_df = (\n",
        "    experiments_df[experiments_df[\"f1\"] >= threshold_f1]\n",
        "    .head(PHASE_4_MAX)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(f\"\\nPromoted configs: {len(promoted_df)}\")\n",
        "for i, row in promoted_df.iterrows():\n",
        "    print(\n",
        "        f\"{i+1}. {row['config_key']} | \"\n",
        "        f\"F1={row['f1']:.4f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "a3ad7b22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Phase 4 grid size: 10\n",
            "\n",
            "================================================================================\n",
            "PHASE 4 — Stabilized Comparison\n",
            "Questions per config: 300\n",
            "================================================================================\n",
            "Total configs: 10\n",
            "Completed: 10\n",
            "Pending: 0\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Grid results (sorted by F1):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>config_key</th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>exact_match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win200_ovl50</td>\n",
              "      <td>32.857235</td>\n",
              "      <td>35.653101</td>\n",
              "      <td>33.657828</td>\n",
              "      <td>21.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>30.748316</td>\n",
              "      <td>32.406665</td>\n",
              "      <td>32.057828</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>30.641472</td>\n",
              "      <td>32.831548</td>\n",
              "      <td>32.168939</td>\n",
              "      <td>19.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RRF_k60_mu2000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>30.493208</td>\n",
              "      <td>32.539998</td>\n",
              "      <td>31.653066</td>\n",
              "      <td>19.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>30.266834</td>\n",
              "      <td>32.039998</td>\n",
              "      <td>31.668939</td>\n",
              "      <td>19.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win250_ovl60</td>\n",
              "      <td>30.024503</td>\n",
              "      <td>32.795068</td>\n",
              "      <td>30.991162</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RRF_k60_mu1000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>29.979533</td>\n",
              "      <td>32.095554</td>\n",
              "      <td>31.224495</td>\n",
              "      <td>18.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RRF_k60_mu1000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>28.791060</td>\n",
              "      <td>31.315219</td>\n",
              "      <td>29.886111</td>\n",
              "      <td>17.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RRF_k60_mu2000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>28.410799</td>\n",
              "      <td>31.099875</td>\n",
              "      <td>29.497222</td>\n",
              "      <td>16.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50</td>\n",
              "      <td>26.948318</td>\n",
              "      <td>29.322684</td>\n",
              "      <td>28.163889</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                config_key         f1  \\\n",
              "0  RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win200_ovl50  32.857235   \n",
              "1   RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50  30.748316   \n",
              "2   RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50  30.641472   \n",
              "3   RRF_k60_mu2000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50  30.493208   \n",
              "4   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win200_ovl50  30.266834   \n",
              "5   RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass5_win250_ovl60  30.024503   \n",
              "6   RRF_k60_mu1000_k11.2_b0.6_kdocs500_kpass5_win200_ovl50  29.979533   \n",
              "7   RRF_k60_mu1000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50  28.791060   \n",
              "8   RRF_k60_mu2000_k11.2_b0.6_kdocs250_kpass5_win150_ovl50  28.410799   \n",
              "9   RRF_k60_mu1000_k10.9_b0.4_kdocs250_kpass5_win150_ovl50  26.948318   \n",
              "\n",
              "   precision     recall  exact_match  \n",
              "0  35.653101  33.657828    21.666667  \n",
              "1  32.406665  32.057828    20.000000  \n",
              "2  32.831548  32.168939    19.666667  \n",
              "3  32.539998  31.653066    19.333333  \n",
              "4  32.039998  31.668939    19.333333  \n",
              "5  32.795068  30.991162    19.000000  \n",
              "6  32.095554  31.224495    18.666667  \n",
              "7  31.315219  29.886111    17.666667  \n",
              "8  31.099875  29.497222    16.333333  \n",
              "9  29.322684  28.163889    16.000000  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Collect all unique configs by config_key\n",
        "ALL_CONFIGS = {}\n",
        "\n",
        "for entry in PHASE_1_GRID + PHASE_2_GRID + PHASE_3_GRID:\n",
        "    key = generate_config_key(\n",
        "        entry[\"retrieval_mgr\"],\n",
        "        entry[\"prompt_mgr\"],\n",
        "    )\n",
        "    ALL_CONFIGS[key] = entry   # dedupe by key\n",
        "\n",
        "# Build Phase 4 grid directly from promoted config_keys\n",
        "PHASE_4_GRID = [\n",
        "    {\n",
        "        \"retrieval_mgr\": ALL_CONFIGS[key][\"retrieval_mgr\"],\n",
        "        \"prompt_mgr\": DEFAULT_PROMPT_MANAGER,\n",
        "    }\n",
        "    for key in promoted_df[\"config_key\"].values\n",
        "    if key in ALL_CONFIGS\n",
        "]\n",
        "\n",
        "print(f\"\\n✓ Phase 4 grid size: {len(PHASE_4_GRID)}\")\n",
        "\n",
        "PHASE_4_RESULTS = run_phase(\n",
        "    phase_name=\"PHASE 4 — Stabilized Comparison\",\n",
        "    grid=PHASE_4_GRID,\n",
        "    df_train=df_train,\n",
        "    num_questions=PHASE_4_NUM_QUESTIONS,\n",
        "    top_k=None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd538c4b",
      "metadata": {},
      "source": [
        "### Phase 5 - Final comparison between 2 best configs, over 1000 questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "6b5075fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 3 configs from Phase 4:\n",
            "1. RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win200_ovl50 | F1=32.8572\n",
            "2. RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50 | F1=30.7483\n",
            "3. RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50 | F1=30.6415\n",
            "\n",
            "✓ Phase 5 grid size: 3\n",
            "\n",
            "================================================================================\n",
            "PHASE 5 — Final Tie-Breaker\n",
            "Questions per config: 1000\n",
            "================================================================================\n",
            "Total configs: 3\n",
            "Completed: 3\n",
            "Pending: 0\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Grid results (sorted by F1):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>config_key</th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>exact_match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win200_ovl50</td>\n",
              "      <td>32.784387</td>\n",
              "      <td>35.456917</td>\n",
              "      <td>33.412422</td>\n",
              "      <td>21.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>31.558194</td>\n",
              "      <td>33.554958</td>\n",
              "      <td>32.770563</td>\n",
              "      <td>20.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50</td>\n",
              "      <td>31.431037</td>\n",
              "      <td>33.717853</td>\n",
              "      <td>32.668896</td>\n",
              "      <td>19.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                config_key         f1  \\\n",
              "0  RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win200_ovl50  32.784387   \n",
              "1   RRF_k60_mu1000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50  31.558194   \n",
              "2   RRF_k60_mu2000_k10.6_b0.3_kdocs500_kpass5_win200_ovl50  31.431037   \n",
              "\n",
              "   precision     recall  exact_match  \n",
              "0  35.456917  33.412422         21.9  \n",
              "1  33.554958  32.770563         20.1  \n",
              "2  33.717853  32.668896         19.9  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PHASE_5_NUM_QUESTIONS = 1000\n",
        "PHASE_5_TOP_K = 3\n",
        "\n",
        "phase_4_path = get_experiment_log_path(num_questions=PHASE_4_NUM_QUESTIONS)\n",
        "df_phase_4 = pd.read_csv(phase_4_path)\n",
        "\n",
        "assert not df_phase_4.empty, \"No Phase 4 results found\"\n",
        "\n",
        "df_phase_4 = df_phase_4.sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "top_3_keys = df_phase_4.head(PHASE_5_TOP_K)[\"config_key\"].tolist()\n",
        "\n",
        "print(\"Top 3 configs from Phase 4:\")\n",
        "for i, row in df_phase_4.head(PHASE_5_TOP_K).iterrows():\n",
        "    print(f\"{i+1}. {row['config_key']} | F1={row['f1']:.4f}\")\n",
        "\n",
        "\n",
        "PHASE_5_GRID = [\n",
        "    {\n",
        "        \"retrieval_mgr\": e[\"retrieval_mgr\"],\n",
        "        \"prompt_mgr\": DEFAULT_PROMPT_MANAGER,\n",
        "    }\n",
        "    for e in PHASE_4_GRID\n",
        "    if generate_config_key(e[\"retrieval_mgr\"], e[\"prompt_mgr\"]) in top_3_keys\n",
        "]\n",
        "\n",
        "print(f\"\\n✓ Phase 5 grid size: {len(PHASE_5_GRID)}\")\n",
        "\n",
        "PHASE_5_RESULTS = run_phase(\n",
        "    phase_name=\"PHASE 5 — Final Tie-Breaker\",\n",
        "    grid=PHASE_5_GRID,\n",
        "    df_train=df_train,\n",
        "    num_questions=PHASE_5_NUM_QUESTIONS,\n",
        "    top_k=None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7efafd3a",
      "metadata": {},
      "source": [
        "## Kaggle Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a43a237",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected best config from Phase 5:\n",
            "RRF_k60_mu1000_k10.9_b0.4_kdocs500_kpass10_win200_ovl50 | F1=32.7844\n",
            "\n",
            "Generating answers for test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test Questions:   100%|██████████| 2032/2032 [2:07:40<00:00,  3.77s/it]\n",
            "================================================================================\n",
            "✓ Kaggle submission saved to: ./results/kaggle_submission.csv\n",
            "✓ Total rows: 2032\n",
            "================================================================================"
          ]
        }
      ],
      "source": [
        "phase_5_path = get_experiment_log_path(num_questions=PHASE_5_NUM_QUESTIONS)\n",
        "df_phase_5 = pd.read_csv(phase_5_path)\n",
        "\n",
        "assert not df_phase_5.empty, \"No Phase 5 results found\"\n",
        "\n",
        "df_phase_5 = df_phase_5.sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "best_row = df_phase_5.iloc[0]\n",
        "BEST_CONFIG_KEY = best_row[\"config_key\"]\n",
        "\n",
        "print(\"Selected best config from Phase 5:\")\n",
        "print(f\"{BEST_CONFIG_KEY} | F1={best_row['f1']:.4f}\")\n",
        "\n",
        "best_entry = next(\n",
        "    e for e in PHASE_5_GRID\n",
        "    if generate_config_key(e[\"retrieval_mgr\"], e[\"prompt_mgr\"]) == BEST_CONFIG_KEY\n",
        ")\n",
        "\n",
        "BEST_RETRIEVAL_MGR = best_entry[\"retrieval_mgr\"]\n",
        "BEST_PROMPT_MGR = best_entry[\"prompt_mgr\"]\n",
        "\n",
        "print(\"\\nGenerating answers for test set...\")\n",
        "\n",
        "test_questions = df_test[\"question\"].tolist()\n",
        "test_ids = df_test[\"id\"].tolist()\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for question in tqdm(test_questions, total=len(test_questions), desc=\"Test Questions\"):\n",
        "    contexts = BEST_RETRIEVAL_MGR.retrieve_context(question)\n",
        "    answer = BEST_PROMPT_MGR.generate_answer(question, contexts)\n",
        "    predictions.append(answer)\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    \"id\": test_ids,\n",
        "    \"prediction\": predictions,\n",
        "})\n",
        "\n",
        "# Required serialization for Kaggle evaluation\n",
        "submission_df[\"prediction\"] = submission_df[\"prediction\"].apply(\n",
        "    lambda x: json.dumps([x], ensure_ascii=False)\n",
        ")\n",
        "\n",
        "SUBMISSION_PATH = \"./results/kaggle_submission.csv\"\n",
        "submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"✓ Kaggle submission saved to: {SUBMISSION_PATH}\")\n",
        "print(f\"✓ Total rows: {len(submission_df)}\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
