{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4dfc41",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47500127",
   "metadata": {},
   "source": [
    "### 1.1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c34d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install pyserini\n",
    "# !pip install faiss-cpu\n",
    "# !pip install torch\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92325087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galnoy/git-projects/MSC-Text-Retrieval-and-Search-Engines/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[0;93m2026-01-09 15:43:23.520028349 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✓ Dependencies imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from pyserini.index.lucene import IndexReader\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"✓ Dependencies imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440a4ea",
   "metadata": {},
   "source": [
    "### 1.2. Load Pyserini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643713e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jan 09, 2026 3:43:24 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: robust04\n",
      "Total documents: 528,030\n",
      "Total terms: 174,540,872\n",
      "✓ Pyserini index loaded\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"robust04\"\n",
    "\n",
    "index_reader = IndexReader.from_prebuilt_index(INDEX_NAME)\n",
    "\n",
    "print(f\"Index: {INDEX_NAME}\")\n",
    "print(f\"Total documents: {index_reader.stats()['documents']:,}\")\n",
    "print(f\"Total terms: {index_reader.stats()['total_terms']:,}\")\n",
    "print(\"✓ Pyserini index loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76f243",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c651d2",
   "metadata": {},
   "source": [
    "### 2.1. Load Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba810b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries loaded: 249\n",
      "\n",
      "Sample queries:\n",
      "  301: international organized crime\n",
      "  302: poliomyelitis post polio\n",
      "  303: hubble telescope achievements\n",
      "  304: endangered species mammals\n",
      "  305: dangerous vehicles\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"./data/\"\n",
    "\n",
    "def load_queries(filepath: str) -> Dict[str, str]:\n",
    "    \"\"\"Load queries from file. Format: qid<tab>query_text\"\"\"\n",
    "    queries = {}\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) == 2:\n",
    "                qid, text = parts\n",
    "                queries[qid] = text\n",
    "    return queries\n",
    "\n",
    "all_queries = load_queries(os.path.join(DATA_DIR, \"queriesROBUST.txt\"))\n",
    "\n",
    "print(f\"Total queries loaded: {len(all_queries)}\")\n",
    "print(f\"\\nSample queries:\")\n",
    "for qid, text in list(all_queries.items())[:5]:\n",
    "    print(f\"  {qid}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bb6d6",
   "metadata": {},
   "source": [
    "### 2.2. Load Relevance Judgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e78241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries with relevance judgments: 50\n",
      "Total judgments: 61,511\n"
     ]
    }
   ],
   "source": [
    "def load_qrels(filepath: str) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"Load qrels. Format: qid 0 docid relevance\"\"\"\n",
    "    qrels = defaultdict(dict)\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 4:\n",
    "                qid, _, docid, rel = parts[:4]\n",
    "                qrels[qid][docid] = int(rel)\n",
    "    return dict(qrels)\n",
    "\n",
    "qrels = load_qrels(os.path.join(DATA_DIR, \"qrels_50_Queries\"))\n",
    "\n",
    "print(f\"Queries with relevance judgments: {len(qrels)}\")\n",
    "print(f\"Total judgments: {sum(len(v) for v in qrels.values()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb973b",
   "metadata": {},
   "source": [
    "### 2.3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838cbd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training queries: 50 (with qrels)\n",
      "Test queries: 199 (no qrels)\n"
     ]
    }
   ],
   "source": [
    "train_qids = sorted(qrels.keys())\n",
    "test_qids = [qid for qid in all_queries.keys() if qid not in train_qids]\n",
    "\n",
    "train_queries = {qid: all_queries[qid] for qid in train_qids}\n",
    "test_queries = {qid: all_queries[qid] for qid in test_qids}\n",
    "\n",
    "print(f\"Training queries: {len(train_queries)} (with qrels)\")\n",
    "print(f\"Test queries: {len(test_queries)} (no qrels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592b728",
   "metadata": {},
   "source": [
    "## 3. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff82512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation metrics defined\n"
     ]
    }
   ],
   "source": [
    "def compute_ap(ranked_docs: List[str], relevance: Dict[str, int]) -> float:\n",
    "    \"\"\"Compute Average Precision for a single query.\"\"\"\n",
    "    relevant = {d for d, r in relevance.items() if r > 0}\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    \n",
    "    hits = 0\n",
    "    precision_sum = 0.0\n",
    "    \n",
    "    for i, doc in enumerate(ranked_docs):\n",
    "        if doc in relevant:\n",
    "            hits += 1\n",
    "            precision_sum += hits / (i + 1)\n",
    "    \n",
    "    return precision_sum / len(relevant)\n",
    "\n",
    "\n",
    "def compute_map(\n",
    "    run: Dict[str, List[Tuple[str, float]]],\n",
    "    qrels: Dict[str, Dict[str, int]]\n",
    ") -> float:\n",
    "    \"\"\"Compute Mean Average Precision over all queries.\"\"\"\n",
    "    aps = []\n",
    "    for qid, results in run.items():\n",
    "        if qid in qrels:\n",
    "            ranked_docs = [doc for doc, _ in results]\n",
    "            ap = compute_ap(ranked_docs, qrels[qid])\n",
    "            aps.append(ap)\n",
    "    return np.mean(aps) if aps else 0.0\n",
    "\n",
    "\n",
    "def evaluate_run(\n",
    "    run: Dict[str, List[Tuple[str, float]]],\n",
    "    qrels: Dict[str, Dict[str, int]]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Evaluate a run and return metrics.\"\"\"\n",
    "    map_score = compute_map(run, qrels)\n",
    "    \n",
    "    per_query = {}\n",
    "    for qid in run:\n",
    "        if qid in qrels:\n",
    "            ranked = [d for d, _ in run[qid]]\n",
    "            per_query[qid] = compute_ap(ranked, qrels[qid])\n",
    "    \n",
    "    return {\n",
    "        \"map\": map_score,\n",
    "        \"num_queries\": len(per_query),\n",
    "        \"per_query_ap\": per_query\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"✓ Evaluation metrics defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af893d",
   "metadata": {},
   "source": [
    "## 4. Retrieval Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15117e17",
   "metadata": {},
   "source": [
    "### 4.1. Abstract Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5287212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BaseRetriever class defined\n"
     ]
    }
   ],
   "source": [
    "class BaseRetriever(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for all retrieval models.\n",
    "    All models must implement search.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, index_name: str = \"robust04\"):\n",
    "        self.index_name = index_name\n",
    "    \n",
    "    @abstractmethod\n",
    "    def search(\n",
    "        self,\n",
    "        queries: Dict[str, str],\n",
    "        k: int = 1000\n",
    "    ) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        \"\"\"Search for all queries and return ranked results.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_params(self) -> Dict:\n",
    "        \"\"\"Return model parameters for logging.\"\"\"\n",
    "        return {}\n",
    "\n",
    "\n",
    "print(\"✓ BaseRetriever class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfdf8d4",
   "metadata": {},
   "source": [
    "### 4.2. BM25 Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f564de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BM25Retriever class defined\n"
     ]
    }
   ],
   "source": [
    "class BM25Retriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    BM25 retrieval model.\n",
    "    \n",
    "    BM25 score = sum over terms t in q:\n",
    "        IDF(t) * (tf(t,d) * (k1 + 1)) / (tf(t,d) + k1 * (1 - b + b * |d|/avgdl))\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        k1: float = 0.9,\n",
    "        b: float = 0.4,\n",
    "        index_name: str = \"robust04\"\n",
    "    ):\n",
    "        super().__init__(index_name)\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self._searcher = None\n",
    "    \n",
    "    @property\n",
    "    def searcher(self) -> LuceneSearcher:\n",
    "        if self._searcher is None:\n",
    "            self._searcher = LuceneSearcher.from_prebuilt_index(self.index_name)\n",
    "            self._searcher.set_bm25(k1=self.k1, b=self.b)\n",
    "        return self._searcher\n",
    "    \n",
    "    def search(\n",
    "        self,\n",
    "        queries: Dict[str, str],\n",
    "        k: int = 1000\n",
    "    ) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        results = {}\n",
    "        for qid, query_text in tqdm(queries.items(), desc=\"BM25 Search\"):\n",
    "            hits = self.searcher.search(query_text, k=k)\n",
    "            results[qid] = [(hit.docid, hit.score) for hit in hits]\n",
    "        return results\n",
    "    \n",
    "    def get_params(self) -> Dict:\n",
    "        return {\"k1\": self.k1, \"b\": self.b}\n",
    "\n",
    "\n",
    "print(\"✓ BM25Retriever class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5dc9f",
   "metadata": {},
   "source": [
    "### 4.3. BM25 + RM3 Retriever (Query Expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03703408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RM3Retriever class defined\n"
     ]
    }
   ],
   "source": [
    "class RM3Retriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    BM25 + RM3 pseudo-relevance feedback.\n",
    "    \n",
    "    RM3 expands the query using terms from top-k retrieved documents.\n",
    "    Final query = original_weight * original_query + (1 - original_weight) * expansion_terms\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        k1: float = 0.9,\n",
    "        b: float = 0.4,\n",
    "        fb_terms: int = 10,\n",
    "        fb_docs: int = 10,\n",
    "        original_weight: float = 0.5,\n",
    "        index_name: str = \"robust04\"\n",
    "    ):\n",
    "        super().__init__(index_name)\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.fb_terms = fb_terms\n",
    "        self.fb_docs = fb_docs\n",
    "        self.original_weight = original_weight\n",
    "        self._searcher = None\n",
    "    \n",
    "    @property\n",
    "    def searcher(self) -> LuceneSearcher:\n",
    "        if self._searcher is None:\n",
    "            self._searcher = LuceneSearcher.from_prebuilt_index(self.index_name)\n",
    "            self._searcher.set_bm25(k1=self.k1, b=self.b)\n",
    "            self._searcher.set_rm3(\n",
    "                fb_terms=self.fb_terms,\n",
    "                fb_docs=self.fb_docs,\n",
    "                original_query_weight=self.original_weight\n",
    "            )\n",
    "        return self._searcher\n",
    "    \n",
    "    def search(\n",
    "        self,\n",
    "        queries: Dict[str, str],\n",
    "        k: int = 1000\n",
    "    ) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        results = {}\n",
    "        for qid, query_text in tqdm(queries.items(), desc=\"RM3 Search\"):\n",
    "            hits = self.searcher.search(query_text, k=k)\n",
    "            results[qid] = [(hit.docid, hit.score) for hit in hits]\n",
    "        return results\n",
    "    \n",
    "    def get_params(self) -> Dict:\n",
    "        return {\n",
    "            \"k1\": self.k1,\n",
    "            \"b\": self.b,\n",
    "            \"fb_terms\": self.fb_terms,\n",
    "            \"fb_docs\": self.fb_docs,\n",
    "            \"original_weight\": self.original_weight\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"✓ RM3Retriever class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77f11b",
   "metadata": {},
   "source": [
    "### 4.4. Hybrid Neural Retriever (Advanced)\n",
    "\n",
    "This method combines BM25 first-stage retrieval with neural cross-encoder re-ranking, then fuses the results using Reciprocal Rank Fusion (RRF):\n",
    "\n",
    "$$\n",
    "\\text{RRF}(d) = \\sum_{r \\in R} \\frac{1}{k + \\text{rank}_r(d)}\n",
    "$$\n",
    "\n",
    "where $R$ is the set of ranking systems and $k$ is a constant (typically 60)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55556642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ HybridNeuralRetriever class defined\n"
     ]
    }
   ],
   "source": [
    "class HybridNeuralRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval: BM25 -> Neural Re-ranking -> RRF Fusion.\n",
    "    \n",
    "    Uses a cross-encoder model to re-rank BM25 candidates,\n",
    "    then fuses BM25 and neural rankings using RRF.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        k1: float = 0.9,\n",
    "        b: float = 0.4,\n",
    "        rerank_depth: int = 100,\n",
    "        rrf_k: int = 60,\n",
    "        model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "        index_name: str = \"robust04\",\n",
    "        batch_size: int = 32\n",
    "    ):\n",
    "        super().__init__(index_name)\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.rerank_depth = rerank_depth\n",
    "        self.rrf_k = rrf_k\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self._searcher = None\n",
    "        self._tokenizer = None\n",
    "        self._cross_encoder = None\n",
    "    \n",
    "    @property\n",
    "    def searcher(self) -> LuceneSearcher:\n",
    "        if self._searcher is None:\n",
    "            self._searcher = LuceneSearcher.from_prebuilt_index(self.index_name)\n",
    "            self._searcher.set_bm25(k1=self.k1, b=self.b)\n",
    "        return self._searcher\n",
    "    \n",
    "    @property\n",
    "    def tokenizer(self):\n",
    "        if self._tokenizer is None:\n",
    "            self._tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        return self._tokenizer\n",
    "    \n",
    "    @property\n",
    "    def cross_encoder(self):\n",
    "        if self._cross_encoder is None:\n",
    "            self._cross_encoder = AutoModelForSequenceClassification.from_pretrained(self.model_name)\n",
    "            self._cross_encoder = self._cross_encoder.to(DEVICE)\n",
    "            self._cross_encoder.eval()\n",
    "        return self._cross_encoder\n",
    "    \n",
    "    def _get_doc_text(self, docid: str) -> str:\n",
    "        \"\"\"Retrieve document text from index.\"\"\"\n",
    "        doc = self.searcher.doc(docid)\n",
    "        if doc is None:\n",
    "            return \"\"\n",
    "        raw = doc.raw()\n",
    "        return raw[:2000] if raw else \"\"\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _rerank(self, query: str, candidates: List[Tuple[str, float]]) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Re-rank candidates using cross-encoder.\"\"\"\n",
    "        if not candidates:\n",
    "            return []\n",
    "        \n",
    "        docids = [d for d, _ in candidates]\n",
    "        docs = [self._get_doc_text(d) for d in docids]\n",
    "        \n",
    "        scores = []\n",
    "        for i in range(0, len(docs), self.batch_size):\n",
    "            batch_docs = docs[i:i+self.batch_size]\n",
    "            pairs = [[query, doc] for doc in batch_docs]\n",
    "            \n",
    "            inputs = self.tokenizer(\n",
    "                pairs,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(DEVICE)\n",
    "            \n",
    "            outputs = self.cross_encoder(**inputs)\n",
    "            batch_scores = outputs.logits.squeeze(-1).cpu().numpy()\n",
    "            scores.extend(batch_scores.tolist() if batch_scores.ndim > 0 else [batch_scores.item()])\n",
    "        \n",
    "        reranked = sorted(zip(docids, scores), key=lambda x: x[1], reverse=True)\n",
    "        return reranked\n",
    "    \n",
    "    def _rrf_fusion(self, runs: List[List[Tuple[str, float]]]) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Combine rankings using Reciprocal Rank Fusion.\"\"\"\n",
    "        rrf_scores = defaultdict(float)\n",
    "        \n",
    "        for run in runs:\n",
    "            for rank, (docid, _) in enumerate(run):\n",
    "                rrf_scores[docid] += 1.0 / (self.rrf_k + rank + 1)\n",
    "        \n",
    "        fused = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return fused\n",
    "    \n",
    "    def search(\n",
    "        self,\n",
    "        queries: Dict[str, str],\n",
    "        k: int = 1000\n",
    "    ) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        results = {}\n",
    "        \n",
    "        for qid, query_text in tqdm(queries.items(), desc=\"Hybrid Search\"):\n",
    "            # First-stage: BM25\n",
    "            bm25_hits = self.searcher.search(query_text, k=self.rerank_depth)\n",
    "            bm25_candidates = [(hit.docid, hit.score) for hit in bm25_hits]\n",
    "            \n",
    "            # Second-stage: Neural re-ranking\n",
    "            neural_reranked = self._rerank(query_text, bm25_candidates)\n",
    "            \n",
    "            # Fusion: RRF\n",
    "            fused = self._rrf_fusion([bm25_candidates, neural_reranked])\n",
    "            \n",
    "            # Pad with BM25 results if needed\n",
    "            if len(fused) < k:\n",
    "                extra_hits = self.searcher.search(query_text, k=k)\n",
    "                seen = {d for d, _ in fused}\n",
    "                for hit in extra_hits:\n",
    "                    if hit.docid not in seen:\n",
    "                        fused.append((hit.docid, 0.0))\n",
    "                        if len(fused) >= k:\n",
    "                            break\n",
    "            \n",
    "            results[qid] = fused[:k]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_params(self) -> Dict:\n",
    "        return {\n",
    "            \"k1\": self.k1,\n",
    "            \"b\": self.b,\n",
    "            \"rerank_depth\": self.rerank_depth,\n",
    "            \"rrf_k\": self.rrf_k,\n",
    "            \"model_name\": self.model_name\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"✓ HybridNeuralRetriever class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08d15b",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b1c0d",
   "metadata": {},
   "source": [
    "### 5.1. Experiment Caching Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a6e966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Caching utils ready\n",
      "  Results CSV: ./experiments.csv\n"
     ]
    }
   ],
   "source": [
    "RESULTS_CSV = \"./experiments.csv\"\n",
    "\n",
    "\n",
    "def generate_config_key(model_name: str, params: Dict) -> str:\n",
    "    \"\"\"Generate a unique config key per model + params.\"\"\"\n",
    "    parts = [model_name]\n",
    "    for k, v in sorted(params.items()):\n",
    "        if k not in [\"index_name\", \"model_name\", \"batch_size\"]:\n",
    "            parts.append(f\"{k}={v}\")\n",
    "    return \"__\".join(parts)\n",
    "\n",
    "\n",
    "def load_completed_experiments() -> pd.DataFrame:\n",
    "    if not os.path.exists(RESULTS_CSV):\n",
    "        return pd.DataFrame()\n",
    "    return pd.read_csv(RESULTS_CSV)\n",
    "\n",
    "\n",
    "def load_cached_result(config_key: str) -> Optional[Dict]:\n",
    "    df = load_completed_experiments()\n",
    "    if df.empty:\n",
    "        return None\n",
    "    row = df[df[\"config_key\"] == config_key]\n",
    "    if row.empty:\n",
    "        return None\n",
    "    return row.iloc[0].to_dict()\n",
    "\n",
    "\n",
    "def save_experiment_result(result: Dict):\n",
    "    df_row = pd.DataFrame([result])\n",
    "    if not os.path.exists(RESULTS_CSV):\n",
    "        df_row.to_csv(RESULTS_CSV, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(RESULTS_CSV, mode=\"a\", header=False, index=False)\n",
    "\n",
    "\n",
    "print(\"✓ Caching utils ready\")\n",
    "print(f\"  Results CSV: {RESULTS_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1792c",
   "metadata": {},
   "source": [
    "### 5.2. Experiment Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b6d42e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Experiment framework ready\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(\n",
    "    config_key: str,\n",
    "    model_name: str,\n",
    "    model_class: type,\n",
    "    model_params: Dict,\n",
    "    queries: Dict[str, str],\n",
    "    qrels: Dict[str, Dict[str, int]]\n",
    ") -> Dict:\n",
    "    \"\"\"Run a single experiment and return results.\"\"\"\n",
    "    model = model_class(**model_params)\n",
    "    run = model.search(queries, k=1000)\n",
    "    metrics = evaluate_run(run, qrels)\n",
    "    \n",
    "    return {\n",
    "        \"config_key\": config_key,\n",
    "        \"model\": model_name,\n",
    "        \"map\": metrics[\"map\"],\n",
    "        \"num_queries\": metrics[\"num_queries\"]\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"✓ Experiment framework ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff0aa2",
   "metadata": {},
   "source": [
    "### 5.3. Hyperparameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a1dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiments configured:\n",
      "  BM25: 25 configurations\n",
      "  RM3: 27 configurations\n",
      "  HybridNeural: 6 configurations\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENTS = [\n",
    "    {\n",
    "        \"model_name\": \"BM25\",\n",
    "        \"model_class\": BM25Retriever,\n",
    "        \"param_grid\": [\n",
    "            {\"k1\": k1, \"b\": b}\n",
    "            for k1, b in product(\n",
    "                [0.6, 0.9, 1.2, 1.5, 2.0],\n",
    "                [0.3, 0.4, 0.5, 0.6, 0.75]\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"RM3\",\n",
    "        \"model_class\": RM3Retriever,\n",
    "        \"param_grid\": [\n",
    "            {\"k1\": 0.9, \"b\": 0.4, \"fb_terms\": fb_terms, \"fb_docs\": fb_docs, \"original_weight\": orig_w}\n",
    "            for fb_terms, fb_docs, orig_w in product(\n",
    "                [10, 20, 30],\n",
    "                [5, 10, 15],\n",
    "                [0.3, 0.5, 0.7]\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"HybridNeural\",\n",
    "        \"model_class\": HybridNeuralRetriever,\n",
    "        \"param_grid\": [\n",
    "            {\"k1\": 0.9, \"b\": 0.4, \"rerank_depth\": rerank_depth, \"rrf_k\": rrf_k}\n",
    "            for rerank_depth, rrf_k in product(\n",
    "                [50, 100],\n",
    "                [30, 60, 90]\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Total experiments configured:\")\n",
    "for exp in EXPERIMENTS:\n",
    "    print(f\"  {exp['model_name']}: {len(exp['param_grid'])} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3fab848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2463\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2475\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2453\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2422\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2392\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2450\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2455\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2442\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2415\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2374\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2426\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2427\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2424\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2400\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2334\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2392\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2396\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2384\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2360\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2307\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2320\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2330\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2324\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2292\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2250\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=10__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2486\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=10__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:02<00:00, 19.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2616\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=10__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:02<00:00, 19.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2613\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:02<00:00, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2441\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:02<00:00, 19.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2559\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:02<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2587\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=10__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:02<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2499\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=10__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2583\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=10__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:04<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2605\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=20__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2562\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=20__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2719\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=20__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:04<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2630\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=20__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:07<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2600\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=20__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2670\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=20__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 15.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2588\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=20__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2612\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=20__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:04<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2684\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=20__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2624\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=30__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:05<00:00,  9.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2600\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=30__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2690\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=30__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:02<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2625\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=30__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 15.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2564\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=30__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2628\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=30__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 16.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2583\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=30__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2622\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=30__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2672\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=30__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 50/50 [00:03<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2610\n",
      "\n",
      "============================================================\n",
      "Experiment: HybridNeural__b=0.4__k1=0.9__rerank_depth=50__rrf_k=30\n",
      "Model: HybridNeural\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hybrid Search: 100%|██████████| 50/50 [00:28<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2475\n",
      "\n",
      "============================================================\n",
      "Experiment: HybridNeural__b=0.4__k1=0.9__rerank_depth=50__rrf_k=60\n",
      "Model: HybridNeural\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hybrid Search: 100%|██████████| 50/50 [00:20<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2465\n",
      "\n",
      "============================================================\n",
      "Experiment: HybridNeural__b=0.4__k1=0.9__rerank_depth=50__rrf_k=90\n",
      "Model: HybridNeural\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hybrid Search:  44%|████▍     | 22/50 [00:15<00:19,  1.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     result \u001b[38;5;241m=\u001b[39m cached\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqueries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_queries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqrels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqrels\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     save_experiment_result(result)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResults:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(config_key, model_name, model_class, model_params, queries, qrels)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run a single experiment and return results.\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_params)\n\u001b[0;32m---> 11\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluate_run(run, qrels)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: config_key,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_queries\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_queries\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m }\n",
      "Cell \u001b[0;32mIn[11], line 113\u001b[0m, in \u001b[0;36mHybridNeuralRetriever.search\u001b[0;34m(self, queries, k)\u001b[0m\n\u001b[1;32m    110\u001b[0m bm25_candidates \u001b[38;5;241m=\u001b[39m [(hit\u001b[38;5;241m.\u001b[39mdocid, hit\u001b[38;5;241m.\u001b[39mscore) \u001b[38;5;28;01mfor\u001b[39;00m hit \u001b[38;5;129;01min\u001b[39;00m bm25_hits]\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Second-stage: Neural re-ranking\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m neural_reranked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbm25_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Fusion: RRF\u001b[39;00m\n\u001b[1;32m    116\u001b[0m fused \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rrf_fusion([bm25_candidates, neural_reranked])\n",
      "File \u001b[0;32m~/git-projects/MSC-Text-Retrieval-and-Search-Engines/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 83\u001b[0m, in \u001b[0;36mHybridNeuralRetriever._rerank\u001b[0;34m(self, query, candidates)\u001b[0m\n\u001b[1;32m     74\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[1;32m     75\u001b[0m         pairs,\n\u001b[1;32m     76\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     82\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 83\u001b[0m     batch_scores \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     84\u001b[0m     scores\u001b[38;5;241m.\u001b[39mextend(batch_scores\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m batch_scores\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [batch_scores\u001b[38;5;241m.\u001b[39mitem()])\n\u001b[1;32m     86\u001b[0m reranked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mzip\u001b[39m(docids, scores), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    model_name = exp[\"model_name\"]\n",
    "    model_class = exp[\"model_class\"]\n",
    "    \n",
    "    for params in exp[\"param_grid\"]:\n",
    "        config_key = generate_config_key(model_name, params)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Experiment: {config_key}\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        cached = load_cached_result(config_key)\n",
    "        if cached is not None:\n",
    "            print(\"✓ Loaded from cache\")\n",
    "            result = cached\n",
    "        else:\n",
    "            result = run_experiment(\n",
    "                config_key=config_key,\n",
    "                model_name=model_name,\n",
    "                model_class=model_class,\n",
    "                model_params=params,\n",
    "                queries=train_queries,\n",
    "                qrels=qrels\n",
    "            )\n",
    "            save_experiment_result(result)\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  MAP: {result['map']:.4f}\")\n",
    "        \n",
    "        results.append(result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All experiments completed.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sorted = sorted(results, key=lambda x: x[\"map\"], reverse=True)\n",
    "top_k = results_sorted[:10]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Top 10 Results (sorted by MAP):\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "header = f\"{'#':<3} {'Model':<15} {'MAP':>10} {'Config':<70}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for i, r in enumerate(top_k, start=1):\n",
    "    print(\n",
    "        f\"{i:<3} \"\n",
    "        f\"{r['model']:<15} \"\n",
    "        f\"{r['map']:>10.4f} \"\n",
    "        f\"{r['config_key']:<70}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e509e",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe1916",
   "metadata": {},
   "source": [
    "### 6.1. Best Model per Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best config for each model type\n",
    "best_per_model = {}\n",
    "for r in results_sorted:\n",
    "    model = r[\"model\"]\n",
    "    if model not in best_per_model:\n",
    "        best_per_model[model] = r\n",
    "\n",
    "print(\"Best configuration per model:\")\n",
    "print(\"=\" * 80)\n",
    "for model, r in best_per_model.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"  MAP: {r['map']:.4f}\")\n",
    "    print(f\"  Config: {r['config_key']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b57ea",
   "metadata": {},
   "source": [
    "### 6.2. Training Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530cee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "for model, r in best_per_model.items():\n",
    "    summary_data.append({\n",
    "        \"Method\": model,\n",
    "        \"MAP\": r[\"map\"],\n",
    "        \"Config\": r[\"config_key\"]\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data).sort_values(\"MAP\", ascending=False)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"TRAINING PERFORMANCE SUMMARY (50 queries)\")\n",
    "print(\"=\" * 100)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "methods = summary_df[\"Method\"].tolist()\n",
    "maps = summary_df[\"MAP\"].tolist()\n",
    "colors = [\"#3498db\", \"#2ecc71\", \"#e74c3c\"]\n",
    "\n",
    "bars = ax.bar(methods, maps, color=colors[:len(methods)], edgecolor=\"black\")\n",
    "ax.set_ylabel(\"MAP\")\n",
    "ax.set_title(\"Training Performance Comparison (50 queries)\")\n",
    "ax.set_ylim(0, max(maps) * 1.15)\n",
    "\n",
    "for bar, m in zip(bars, maps):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "            f\"{m:.4f}\", ha=\"center\", va=\"bottom\", fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e5ffea",
   "metadata": {},
   "source": [
    "## 7. Final Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7390690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best overall model\n",
    "best_result = results_sorted[0]\n",
    "\n",
    "print(\"Best model from all experiments:\")\n",
    "print(f\"  Model: {best_result['model']}\")\n",
    "print(f\"  MAP: {best_result['map']:.4f}\")\n",
    "print(f\"  Config: {best_result['config_key']}\")\n",
    "\n",
    "# Find matching experiment configuration\n",
    "best_model_name = best_result[\"model\"]\n",
    "best_config_key = best_result[\"config_key\"]\n",
    "\n",
    "matched_config = None\n",
    "matched_model_class = None\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    if exp[\"model_name\"] == best_model_name:\n",
    "        matched_model_class = exp[\"model_class\"]\n",
    "        for params in exp[\"param_grid\"]:\n",
    "            config_key = generate_config_key(exp[\"model_name\"], params)\n",
    "            if config_key == best_config_key:\n",
    "                matched_config = params.copy()\n",
    "                break\n",
    "        if matched_config:\n",
    "            break\n",
    "\n",
    "if matched_config is None:\n",
    "    raise ValueError(f\"Could not find matching config for {best_config_key}\")\n",
    "\n",
    "print(f\"\\n✓ Best model identified: {best_model_name}\")\n",
    "print(f\"  Parameters: {matched_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78526c82",
   "metadata": {},
   "source": [
    "## 8. Generate Submission Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43c924",
   "metadata": {},
   "source": [
    "### 8.1. Initialize Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfbbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameters for each method\n",
    "best_bm25_params = None\n",
    "best_rm3_params = None\n",
    "best_hybrid_params = None\n",
    "\n",
    "for model_name, r in best_per_model.items():\n",
    "    for exp in EXPERIMENTS:\n",
    "        if exp[\"model_name\"] == model_name:\n",
    "            for params in exp[\"param_grid\"]:\n",
    "                if generate_config_key(model_name, params) == r[\"config_key\"]:\n",
    "                    if model_name == \"BM25\":\n",
    "                        best_bm25_params = params\n",
    "                    elif model_name == \"RM3\":\n",
    "                        best_rm3_params = params\n",
    "                    elif model_name == \"HybridNeural\":\n",
    "                        best_hybrid_params = params\n",
    "                    break\n",
    "\n",
    "print(\"Final model configurations:\")\n",
    "print(f\"  BM25: {best_bm25_params}\")\n",
    "print(f\"  RM3: {best_rm3_params}\")\n",
    "print(f\"  HybridNeural: {best_hybrid_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9f6e9",
   "metadata": {},
   "source": [
    "### 8.2. Run Inference on Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running inference on {len(test_queries)} test queries...\\n\")\n",
    "\n",
    "# Method 1: BM25\n",
    "print(\"Method 1: BM25\")\n",
    "model_1 = BM25Retriever(**best_bm25_params)\n",
    "run_1 = model_1.search(test_queries, k=1000)\n",
    "print(f\"  ✓ {len(run_1)} queries processed\")\n",
    "\n",
    "# Method 2: RM3\n",
    "print(\"\\nMethod 2: BM25 + RM3\")\n",
    "model_2 = RM3Retriever(**best_rm3_params)\n",
    "run_2 = model_2.search(test_queries, k=1000)\n",
    "print(f\"  ✓ {len(run_2)} queries processed\")\n",
    "\n",
    "# Method 3: Hybrid Neural\n",
    "print(\"\\nMethod 3: Hybrid Neural Re-ranking\")\n",
    "model_3 = HybridNeuralRetriever(**best_hybrid_params)\n",
    "run_3 = model_3.search(test_queries, k=1000)\n",
    "print(f\"  ✓ {len(run_3)} queries processed\")\n",
    "\n",
    "print(\"\\n✓ All test queries processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30683d4",
   "metadata": {},
   "source": [
    "### 8.3. Export TREC Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_trec_run(\n",
    "    run: Dict[str, List[Tuple[str, float]]],\n",
    "    filepath: str,\n",
    "    run_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Write run to TREC format.\n",
    "    Format: topic_id Q0 doc_id rank score run_name\n",
    "    \"\"\"\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for qid in sorted(run.keys(), key=lambda x: int(x)):\n",
    "            results = run[qid]\n",
    "            sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "            for rank, (docid, score) in enumerate(sorted_results[:1000], start=1):\n",
    "                f.write(f\"{qid} Q0 {docid} {rank} {score:.6f} {run_name}\\n\")\n",
    "    \n",
    "    print(f\"✓ Written: {filepath}\")\n",
    "\n",
    "\n",
    "print(\"Writing submission files...\\n\")\n",
    "\n",
    "write_trec_run(run_1, \"run_1.res\", \"run_1\")\n",
    "write_trec_run(run_2, \"run_2.res\", \"run_2\")\n",
    "write_trec_run(run_3, \"run_3.res\", \"run_3\")\n",
    "\n",
    "print(\"\\n✓ All submission files written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731a362",
   "metadata": {},
   "source": [
    "### 8.4. Validate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b4900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_run_file(filepath: str, expected_queries: int = 199, docs_per_query: int = 1000):\n",
    "    \"\"\"Validate TREC run file format and contents.\"\"\"\n",
    "    query_docs = defaultdict(list)\n",
    "    \n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            qid, _, docid, rank, score, _ = parts\n",
    "            query_docs[qid].append((int(rank), float(score)))\n",
    "    \n",
    "    assert len(query_docs) == expected_queries, f\"Expected {expected_queries} queries, got {len(query_docs)}\"\n",
    "    \n",
    "    for qid, docs in query_docs.items():\n",
    "        assert len(docs) == docs_per_query, f\"Query {qid}: expected {docs_per_query} docs, got {len(docs)}\"\n",
    "        scores = [s for _, s in sorted(docs, key=lambda x: x[0])]\n",
    "        assert scores == sorted(scores, reverse=True), f\"Query {qid}: scores not in decreasing order\"\n",
    "    \n",
    "    print(f\"✓ {filepath}: {len(query_docs)} queries × {docs_per_query} docs, scores non-increasing\")\n",
    "\n",
    "\n",
    "print(\"Validating submission files...\\n\")\n",
    "\n",
    "validate_run_file(\"run_1.res\")\n",
    "validate_run_file(\"run_2.res\")\n",
    "validate_run_file(\"run_3.res\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUBMISSION FILES READY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Files: run_1.res, run_2.res, run_3.res\")\n",
    "print(\"Format: TREC 6-column\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
