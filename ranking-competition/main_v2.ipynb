{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4dfc41",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47500127",
   "metadata": {},
   "source": [
    "### 1.1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c34d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install pyserini\n",
    "# !pip install faiss-cpu\n",
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92325087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galnoy/git-projects/MSC-Text-Retrieval-and-Search-Engines/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[0;93m2026-01-09 17:11:55.600714268 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✓ Dependencies imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from functools import lru_cache\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from pyserini.index.lucene import IndexReader\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"✓ Dependencies imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440a4ea",
   "metadata": {},
   "source": [
    "### 1.2. Load Pyserini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643713e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: robust04\n",
      "Total documents: 528,030\n",
      "Total terms: 174,540,872\n",
      "✓ Pyserini index loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jan 09, 2026 5:11:56 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"robust04\"\n",
    "\n",
    "index_reader = IndexReader.from_prebuilt_index(INDEX_NAME)\n",
    "\n",
    "print(f\"Index: {INDEX_NAME}\")\n",
    "print(f\"Total documents: {index_reader.stats()['documents']:,}\")\n",
    "print(f\"Total terms: {index_reader.stats()['total_terms']:,}\")\n",
    "print(\"✓ Pyserini index loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76f243",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c651d2",
   "metadata": {},
   "source": [
    "### 2.1. Load Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba810b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries loaded: 249\n",
      "\n",
      "Sample queries:\n",
      "  301: international organized crime\n",
      "  302: poliomyelitis post polio\n",
      "  303: hubble telescope achievements\n",
      "  304: endangered species mammals\n",
      "  305: dangerous vehicles\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"./data/\"\n",
    "\n",
    "def load_queries(filepath: str) -> Dict[str, str]:\n",
    "    \"\"\"Load queries from file. Format: qid<tab>query_text\"\"\"\n",
    "    queries = {}\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) == 2:\n",
    "                qid, text = parts\n",
    "                queries[qid] = text\n",
    "    return queries\n",
    "\n",
    "all_queries = load_queries(os.path.join(DATA_DIR, \"queriesROBUST.txt\"))\n",
    "\n",
    "print(f\"Total queries loaded: {len(all_queries)}\")\n",
    "print(f\"\\nSample queries:\")\n",
    "for qid, text in list(all_queries.items())[:5]:\n",
    "    print(f\"  {qid}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bb6d6",
   "metadata": {},
   "source": [
    "### 2.2. Load Relevance Judgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e78241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries with relevance judgments: 50\n",
      "Total judgments: 61,511\n"
     ]
    }
   ],
   "source": [
    "def load_qrels(filepath: str) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"Load qrels. Format: qid 0 docid relevance\"\"\"\n",
    "    qrels = defaultdict(dict)\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 4:\n",
    "                qid, _, docid, rel = parts[:4]\n",
    "                qrels[qid][docid] = int(rel)\n",
    "    return dict(qrels)\n",
    "\n",
    "qrels = load_qrels(os.path.join(DATA_DIR, \"qrels_50_Queries\"))\n",
    "\n",
    "print(f\"Queries with relevance judgments: {len(qrels)}\")\n",
    "print(f\"Total judgments: {sum(len(v) for v in qrels.values()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb973b",
   "metadata": {},
   "source": [
    "### 2.3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838cbd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training queries: 50 (with qrels)\n",
      "Test queries: 199 (no qrels)\n"
     ]
    }
   ],
   "source": [
    "train_qids = sorted(qrels.keys())\n",
    "test_qids = [qid for qid in all_queries.keys() if qid not in train_qids]\n",
    "\n",
    "train_queries = {qid: all_queries[qid] for qid in train_qids}\n",
    "test_queries = {qid: all_queries[qid] for qid in test_qids}\n",
    "\n",
    "print(f\"Training queries: {len(train_queries)} (with qrels)\")\n",
    "print(f\"Test queries: {len(test_queries)} (no qrels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592b728",
   "metadata": {},
   "source": [
    "## 3. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff82512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation metrics defined\n"
     ]
    }
   ],
   "source": [
    "def compute_ap(ranked_docs: List[str], relevance: Dict[str, int]) -> float:\n",
    "    \"\"\"Compute Average Precision for a single query.\"\"\"\n",
    "    relevant = {d for d, r in relevance.items() if r > 0}\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    \n",
    "    hits = 0\n",
    "    precision_sum = 0.0\n",
    "    \n",
    "    for i, doc in enumerate(ranked_docs):\n",
    "        if doc in relevant:\n",
    "            hits += 1\n",
    "            precision_sum += hits / (i + 1)\n",
    "    \n",
    "    return precision_sum / len(relevant)\n",
    "\n",
    "\n",
    "def compute_map(\n",
    "    run: Dict[str, List[Tuple[str, float]]],\n",
    "    qrels: Dict[str, Dict[str, int]]\n",
    ") -> float:\n",
    "    \"\"\"Compute Mean Average Precision over all queries.\"\"\"\n",
    "    aps = []\n",
    "    for qid, results in run.items():\n",
    "        if qid in qrels:\n",
    "            ranked_docs = [doc for doc, _ in results]\n",
    "            ap = compute_ap(ranked_docs, qrels[qid])\n",
    "            aps.append(ap)\n",
    "    return np.mean(aps) if aps else 0.0\n",
    "\n",
    "\n",
    "def evaluate_run(\n",
    "    run: Dict[str, List[Tuple[str, float]]],\n",
    "    qrels: Dict[str, Dict[str, int]]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Evaluate a run and return metrics.\"\"\"\n",
    "    map_score = compute_map(run, qrels)\n",
    "    \n",
    "    per_query = {}\n",
    "    for qid in run:\n",
    "        if qid in qrels:\n",
    "            ranked = [d for d, _ in run[qid]]\n",
    "            per_query[qid] = compute_ap(ranked, qrels[qid])\n",
    "    \n",
    "    return {\n",
    "        \"map\": map_score,\n",
    "        \"num_queries\": len(per_query),\n",
    "        \"per_query_ap\": per_query\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"✓ Evaluation metrics defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af893d",
   "metadata": {},
   "source": [
    "## 4. Retrieval Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15117e17",
   "metadata": {},
   "source": [
    "### 4.1. Abstract Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5287212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BaseRetriever class defined\n"
     ]
    }
   ],
   "source": [
    "class BaseRetriever(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for all retrieval models.\n",
    "    All models must implement search.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, index_name: str = \"robust04\"):\n",
    "        self.index_name = index_name\n",
    "    \n",
    "    @abstractmethod\n",
    "    def search(\n",
    "        self,\n",
    "        queries: Dict[str, str],\n",
    "        k: int = 1000\n",
    "    ) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        \"\"\"Search for all queries and return ranked results.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_params(self) -> Dict:\n",
    "        \"\"\"Return model parameters for logging.\"\"\"\n",
    "        return {}\n",
    "\n",
    "\n",
    "print(\"✓ BaseRetriever class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfdf8d4",
   "metadata": {},
   "source": [
    "### 4.2. BM25 Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f564de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BM25Retriever class defined\n"
     ]
    }
   ],
   "source": [
    "class BM25Retriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    BM25 retrieval model.\n",
    "    \n",
    "    BM25 score = sum over terms t in q:\n",
    "        IDF(t) * (tf(t,d) * (k1 + 1)) / (tf(t,d) + k1 * (1 - b + b * |d|/avgdl))\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        k1: float = 0.9,\n",
    "        b: float = 0.4,\n",
    "        index_name: str = \"robust04\"\n",
    "    ):\n",
    "        super().__init__(index_name)\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self._searcher = None\n",
    "    \n",
    "    @property\n",
    "    def searcher(self) -> LuceneSearcher:\n",
    "        if self._searcher is None:\n",
    "            self._searcher = LuceneSearcher.from_prebuilt_index(self.index_name)\n",
    "            self._searcher.set_bm25(k1=self.k1, b=self.b)\n",
    "        return self._searcher\n",
    "    \n",
    "    def search(\n",
    "        self,\n",
    "        queries: Dict[str, str],\n",
    "        k: int = 1000\n",
    "    ) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        results = {}\n",
    "        for qid, query_text in tqdm(queries.items(), desc=\"BM25 Search\"):\n",
    "            hits = self.searcher.search(query_text, k=k)\n",
    "            results[qid] = [(hit.docid, hit.score) for hit in hits]\n",
    "        return results\n",
    "    \n",
    "    def get_params(self) -> Dict:\n",
    "        return {\"k1\": self.k1, \"b\": self.b}\n",
    "\n",
    "\n",
    "print(\"✓ BM25Retriever class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5dc9f",
   "metadata": {},
   "source": [
    "### 4.3. BM25 + RM3 Retriever (Query Expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03703408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RM3Retriever class defined\n"
     ]
    }
   ],
   "source": [
    "class RM3Retriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    BM25 + RM3 pseudo-relevance feedback.\n",
    "    \n",
    "    RM3 expands the query using terms from top-k retrieved documents.\n",
    "    Final query = original_weight * original_query + (1 - original_weight) * expansion_terms\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        k1: float = 0.9,\n",
    "        b: float = 0.4,\n",
    "        fb_terms: int = 10,\n",
    "        fb_docs: int = 10,\n",
    "        original_weight: float = 0.5,\n",
    "        index_name: str = \"robust04\"\n",
    "    ):\n",
    "        super().__init__(index_name)\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.fb_terms = fb_terms\n",
    "        self.fb_docs = fb_docs\n",
    "        self.original_weight = original_weight\n",
    "        self._searcher = None\n",
    "    \n",
    "    @property\n",
    "    def searcher(self) -> LuceneSearcher:\n",
    "        if self._searcher is None:\n",
    "            self._searcher = LuceneSearcher.from_prebuilt_index(self.index_name)\n",
    "            self._searcher.set_bm25(k1=self.k1, b=self.b)\n",
    "            self._searcher.set_rm3(\n",
    "                fb_terms=self.fb_terms,\n",
    "                fb_docs=self.fb_docs,\n",
    "                original_query_weight=self.original_weight\n",
    "            )\n",
    "        return self._searcher\n",
    "    \n",
    "    def search(\n",
    "        self,\n",
    "        queries: Dict[str, str],\n",
    "        k: int = 1000\n",
    "    ) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        results = {}\n",
    "        for qid, query_text in tqdm(queries.items(), desc=\"RM3 Search\"):\n",
    "            hits = self.searcher.search(query_text, k=k)\n",
    "            results[qid] = [(hit.docid, hit.score) for hit in hits]\n",
    "        return results\n",
    "    \n",
    "    def get_params(self) -> Dict:\n",
    "        return {\n",
    "            \"k1\": self.k1,\n",
    "            \"b\": self.b,\n",
    "            \"fb_terms\": self.fb_terms,\n",
    "            \"fb_docs\": self.fb_docs,\n",
    "            \"original_weight\": self.original_weight\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"✓ RM3Retriever class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77f11b",
   "metadata": {},
   "source": [
    "### 4.4. Advanced Hybrid Retriever (BM25+RM3, QLD+RM3, Passages, RRF)\n",
    "\n",
    "This method combines multiple retrieval signals:\n",
    "- BM25 with RM3 query expansion\n",
    "- Query Likelihood (QLD) with RM3 query expansion\n",
    "- Document-level RRF fusion: $\\text{RRF}(d) = \\sum_{r \\in R} \\frac{1}{k + \\text{rank}_r(d)}$\n",
    "- Passage-level splitting with overlapping windows\n",
    "- Cross-encoder passage reranking\n",
    "- Passage-to-document score aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55556642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ AdvancedHybridRetriever class defined\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "TEXT_RE = re.compile(r'<TEXT>(.*?)</TEXT>', re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "@lru_cache(maxsize=2000)\n",
    "def get_doc_content(docid: str, searcher: LuceneSearcher) -> str:\n",
    "    doc = searcher.doc(docid)\n",
    "    if doc is None:\n",
    "        return \"\"\n",
    "\n",
    "    raw = doc.raw() or \"\"\n",
    "\n",
    "    # Robust04 is TREC; just parse TEXT tags\n",
    "    texts = TEXT_RE.findall(raw)\n",
    "    if texts:\n",
    "        content = \" \".join(texts)\n",
    "    else:\n",
    "        # Fallback: strip tags and return whatever text remains\n",
    "        content = re.sub(r'<[^>]+>', ' ', raw)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    content = re.sub(r'\\s+', ' ', content).strip()\n",
    "    return content\n",
    "\n",
    "\n",
    "class AdvancedHybridRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    Advanced hybrid retrieval combining:\n",
    "      1. BM25 + RM3 query expansion (first-stage)\n",
    "      2. QLD + RM3 query expansion (first-stage)\n",
    "      3. Document-level RRF fusion\n",
    "      4. Passage extraction with overlapping windows\n",
    "      5. Cross-encoder passage reranking\n",
    "      6. Passage-to-document score aggregation\n",
    "    \n",
    "    This approach balances recall (multiple retrieval models) with precision\n",
    "    (passage-level neural reranking).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        # BM25 params\n",
    "        k1: float = 0.9,\n",
    "        b: float = 0.4,\n",
    "        \n",
    "        # QLD params\n",
    "        mu: int = 1000,\n",
    "        \n",
    "        # RM3 params\n",
    "        fb_terms: int = 10,\n",
    "        fb_docs: int = 10,\n",
    "        original_weight: float = 0.5,\n",
    "        \n",
    "        # Retrieval params\n",
    "        k_docs: int = 100,\n",
    "        rrf_k: int = 60,\n",
    "        \n",
    "        # Passage params\n",
    "        window: int = 150,\n",
    "        overlap: int = 50,\n",
    "        min_passage_words: int = 30,\n",
    "        \n",
    "        # Reranking params\n",
    "        model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "        batch_size: int = 32,\n",
    "        \n",
    "        index_name: str = \"robust04\"\n",
    "    ):\n",
    "        super().__init__(index_name)\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.mu = mu\n",
    "        self.fb_terms = fb_terms\n",
    "        self.fb_docs = fb_docs\n",
    "        self.original_weight = original_weight\n",
    "        self.k_docs = k_docs\n",
    "        self.rrf_k = rrf_k\n",
    "        self.window = window\n",
    "        self.overlap = overlap\n",
    "        self.min_passage_words = min_passage_words\n",
    "        self.rerank_top_passages = k_docs * 5\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self._bm25_searcher = None\n",
    "        self._qld_searcher = None\n",
    "        self._cross_encoder = None\n",
    "    \n",
    "    @property\n",
    "    def bm25_searcher(self) -> LuceneSearcher:\n",
    "        \"\"\"BM25 + RM3 searcher.\"\"\"\n",
    "        if self._bm25_searcher is None:\n",
    "            self._bm25_searcher = LuceneSearcher.from_prebuilt_index(self.index_name)\n",
    "            self._bm25_searcher.set_bm25(k1=self.k1, b=self.b)\n",
    "            self._bm25_searcher.set_rm3(\n",
    "                fb_terms=self.fb_terms,\n",
    "                fb_docs=self.fb_docs,\n",
    "                original_query_weight=self.original_weight\n",
    "            )\n",
    "        return self._bm25_searcher\n",
    "    \n",
    "    @property\n",
    "    def qld_searcher(self) -> LuceneSearcher:\n",
    "        \"\"\"QLD + RM3 searcher.\"\"\"\n",
    "        if self._qld_searcher is None:\n",
    "            self._qld_searcher = LuceneSearcher.from_prebuilt_index(self.index_name)\n",
    "            self._qld_searcher.set_qld(mu=self.mu)\n",
    "            self._qld_searcher.set_rm3(\n",
    "                fb_terms=self.fb_terms,\n",
    "                fb_docs=self.fb_docs,\n",
    "                original_query_weight=self.original_weight\n",
    "            )\n",
    "        return self._qld_searcher\n",
    "    \n",
    "    @property\n",
    "    def cross_encoder(self):\n",
    "        \"\"\"Lazy-loaded cross-encoder model.\"\"\"\n",
    "        if self._cross_encoder is None:\n",
    "            self._cross_encoder = CrossEncoder(\n",
    "                self.model_name,\n",
    "                model_kwargs={\"dtype\": torch.float16},\n",
    "                device=DEVICE,\n",
    "                max_length=512,\n",
    "            )\n",
    "        return self._cross_encoder\n",
    "    \n",
    "    def extract_passages(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Split document into overlapping passages.\n",
    "        Uses word-level sliding window for better context preservation.\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        \n",
    "        words = text.split()\n",
    "        if len(words) < self.min_passage_words:\n",
    "            return []\n",
    "        \n",
    "        step = max(1, self.window - self.overlap)\n",
    "        passages = []\n",
    "        \n",
    "        for i in range(0, len(words), step):\n",
    "            chunk = words[i:i + self.window]\n",
    "            if len(chunk) < self.min_passage_words:\n",
    "                break\n",
    "            passages.append(\" \".join(chunk))\n",
    "        \n",
    "        return passages\n",
    "    \n",
    "    def rrf_fusion(self, rankings: List[List[Tuple[str, float]]]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Reciprocal Rank Fusion: combines multiple rankings.\n",
    "        Returns dict of {docid: rrf_score}.\n",
    "        \"\"\"\n",
    "        rrf_scores = defaultdict(float)\n",
    "        \n",
    "        for ranking in rankings:\n",
    "            for rank, (docid, _) in enumerate(ranking):\n",
    "                rrf_scores[docid] += 1.0 / (self.rrf_k + rank + 1)\n",
    "        \n",
    "        return dict(rrf_scores)\n",
    "    \n",
    "    def rerank_passages(self, query: str, docid_to_passages: Dict[str, List[str]]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Cross-encoder passage reranking.\n",
    "        Returns {docid: max_passage_score}.\n",
    "        \"\"\"\n",
    "\n",
    "        if not docid_to_passages:\n",
    "            return {}\n",
    "\n",
    "        pairs = []\n",
    "        pair_docids = []\n",
    "\n",
    "        for docid, passages in docid_to_passages.items():\n",
    "            for p in passages:\n",
    "                pairs.append([query, p])\n",
    "                pair_docids.append(docid)\n",
    "\n",
    "        if not pairs:\n",
    "            return {}\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            scores = self.cross_encoder.predict(\n",
    "                pairs,\n",
    "                batch_size=self.batch_size,\n",
    "                show_progress_bar=False,\n",
    "            )\n",
    "\n",
    "        doc_scores: Dict[str, float] = {}\n",
    "\n",
    "        for docid, score in zip(pair_docids, scores):\n",
    "            prev = doc_scores.get(docid, float(\"-inf\"))\n",
    "            if score > prev:\n",
    "                doc_scores[docid] = float(score)\n",
    "\n",
    "        return doc_scores\n",
    "        \n",
    "    def search(\n",
    "        self,\n",
    "        queries: Dict[str, str],\n",
    "        k: int = 1000\n",
    "    ) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        results: Dict[str, List[Tuple[str, float]]] = {}\n",
    "\n",
    "        for qid, query_text in tqdm(queries.items(), desc=\"Advanced Hybrid Search\"):\n",
    "            # Stage 1: First-stage lexical retrieval\n",
    "            bm25_hits = self.bm25_searcher.search(query_text, k=self.k_docs)\n",
    "            bm25_ranking = [(h.docid, h.score) for h in bm25_hits]\n",
    "\n",
    "            qld_hits = self.qld_searcher.search(query_text, k=self.k_docs)\n",
    "            qld_ranking = [(h.docid, h.score) for h in qld_hits]\n",
    "\n",
    "            # Stage 2: Document-level RRF fusion\n",
    "            doc_scores = self.rrf_fusion([bm25_ranking, qld_ranking])\n",
    "            ranked_docids = sorted(\n",
    "                doc_scores,\n",
    "                key=doc_scores.get,\n",
    "                reverse=True,\n",
    "            )\n",
    "\n",
    "            # Stage 3: Passage extraction (GLOBAL CAP = 5 * k_docs)\n",
    "            docid_to_passages: Dict[str, List[str]] = {}\n",
    "            max_passages = self.rerank_top_passages\n",
    "            total_passages = 0\n",
    "\n",
    "            for docid in ranked_docids[:self.k_docs]:\n",
    "                if total_passages >= max_passages:\n",
    "                    break\n",
    "\n",
    "                content = get_doc_content(docid, self.bm25_searcher)\n",
    "                if not content:\n",
    "                    continue\n",
    "\n",
    "                passages = self.extract_passages(content)\n",
    "                if not passages:\n",
    "                    continue\n",
    "\n",
    "                remaining = max_passages - total_passages\n",
    "                passages = passages[:remaining]\n",
    "\n",
    "                docid_to_passages[docid] = passages\n",
    "                total_passages += len(passages)\n",
    "\n",
    "            # Stage 4: Cross-encoder passage reranking\n",
    "            reranked_scores = self.rerank_passages(\n",
    "                query=query_text,\n",
    "                docid_to_passages=docid_to_passages,\n",
    "            )\n",
    "\n",
    "            # Stage 5: Final document scoring\n",
    "            final_doc_scores = reranked_scores if reranked_scores else doc_scores\n",
    "\n",
    "            ranked = sorted(\n",
    "                final_doc_scores.items(),\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True,\n",
    "            )\n",
    "\n",
    "            # Stage 6: Pad with BM25 tail to reach k documents\n",
    "            if len(ranked) < k:\n",
    "                seen = {docid for docid, _ in ranked}\n",
    "                extra_hits = self.bm25_searcher.search(query_text, k=k)\n",
    "\n",
    "                for hit in extra_hits:\n",
    "                    if hit.docid not in seen:\n",
    "                        ranked.append((hit.docid, hit.score))\n",
    "                        if len(ranked) >= k:\n",
    "                            break\n",
    "\n",
    "            results[qid] = ranked[:k]\n",
    "\n",
    "        return results\n",
    "\n",
    "    \n",
    "    def get_params(self) -> Dict:\n",
    "        return {\n",
    "            \"k1\": self.k1,\n",
    "            \"b\": self.b,\n",
    "            \"mu\": self.mu,\n",
    "            \"fb_terms\": self.fb_terms,\n",
    "            \"fb_docs\": self.fb_docs,\n",
    "            \"original_weight\": self.original_weight,\n",
    "            \"k_docs\": self.k_docs,\n",
    "            \"rrf_k\": self.rrf_k,\n",
    "            \"window\": self.window,\n",
    "            \"overlap\": self.overlap,\n",
    "            \"model_name\": self.model_name\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"✓ AdvancedHybridRetriever class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08d15b",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b1c0d",
   "metadata": {},
   "source": [
    "### 5.1. Experiment Caching Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a6e966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Caching utils ready\n",
      "  Results CSV: ./experiments.csv\n"
     ]
    }
   ],
   "source": [
    "RESULTS_CSV = \"./experiments.csv\"\n",
    "\n",
    "\n",
    "def generate_config_key(model_name: str, params: Dict) -> str:\n",
    "    \"\"\"Generate a unique config key per model + params.\"\"\"\n",
    "    parts = [model_name]\n",
    "    for k, v in sorted(params.items()):\n",
    "        if k not in [\"index_name\", \"model_name\", \"batch_size\"]:\n",
    "            parts.append(f\"{k}={v}\")\n",
    "    return \"__\".join(parts)\n",
    "\n",
    "\n",
    "def load_completed_experiments() -> pd.DataFrame:\n",
    "    if not os.path.exists(RESULTS_CSV):\n",
    "        return pd.DataFrame()\n",
    "    return pd.read_csv(RESULTS_CSV)\n",
    "\n",
    "\n",
    "def load_cached_result(config_key: str) -> Optional[Dict]:\n",
    "    df = load_completed_experiments()\n",
    "    if df.empty:\n",
    "        return None\n",
    "    row = df[df[\"config_key\"] == config_key]\n",
    "    if row.empty:\n",
    "        return None\n",
    "    return row.iloc[0].to_dict()\n",
    "\n",
    "\n",
    "def save_experiment_result(result: Dict):\n",
    "    df_row = pd.DataFrame([result])\n",
    "    if not os.path.exists(RESULTS_CSV):\n",
    "        df_row.to_csv(RESULTS_CSV, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(RESULTS_CSV, mode=\"a\", header=False, index=False)\n",
    "\n",
    "\n",
    "print(\"✓ Caching utils ready\")\n",
    "print(f\"  Results CSV: {RESULTS_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1792c",
   "metadata": {},
   "source": [
    "### 5.2. Experiment Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b6d42e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Experiment framework ready\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(\n",
    "    config_key: str,\n",
    "    model_name: str,\n",
    "    model_class: type,\n",
    "    model_params: Dict,\n",
    "    queries: Dict[str, str],\n",
    "    qrels: Dict[str, Dict[str, int]]\n",
    ") -> Dict:\n",
    "    \"\"\"Run a single experiment and return results.\"\"\"\n",
    "    model = model_class(**model_params)\n",
    "    run = model.search(queries, k=1000)\n",
    "    metrics = evaluate_run(run, qrels)\n",
    "    \n",
    "    return {\n",
    "        \"config_key\": config_key,\n",
    "        \"model\": model_name,\n",
    "        \"map\": metrics[\"map\"],\n",
    "        \"num_queries\": metrics[\"num_queries\"]\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"✓ Experiment framework ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff0aa2",
   "metadata": {},
   "source": [
    "### 5.3. Hyperparameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6a1dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiments configured:\n",
      "  BM25: 25 configurations\n",
      "  RM3: 27 configurations\n",
      "  AdvancedHybrid: 24 configurations\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "EXPERIMENTS = [\n",
    "    # --------------------------------------------------\n",
    "    # 1) BM25 — strong lexical baseline\n",
    "    # --------------------------------------------------\n",
    "    {\n",
    "        \"model_name\": \"BM25\",\n",
    "        \"model_class\": BM25Retriever,\n",
    "        \"param_grid\": [\n",
    "            {\"k1\": k1, \"b\": b}\n",
    "            for k1, b in product(\n",
    "                [0.6, 0.9, 1.2, 1.5, 2.0],\n",
    "                [0.3, 0.4, 0.5, 0.6, 0.75]\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2) BM25 + RM3 — tuned PRF\n",
    "    # --------------------------------------------------\n",
    "    {\n",
    "        \"model_name\": \"RM3\",\n",
    "        \"model_class\": RM3Retriever,\n",
    "        \"param_grid\": [\n",
    "            {\"k1\": 0.9, \"b\": 0.4, \"fb_terms\": fb_terms, \"fb_docs\": fb_docs, \"original_weight\": orig_w}\n",
    "            for fb_terms, fb_docs, orig_w in product(\n",
    "                [10, 20, 30],\n",
    "                [5, 10, 15],\n",
    "                [0.3, 0.5, 0.7]\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3) Advanced Hybrid — RRF + passage CE reranking\n",
    "    # --------------------------------------------------\n",
    "    {\n",
    "        \"model_name\": \"AdvancedHybrid\",\n",
    "        \"model_class\": AdvancedHybridRetriever,\n",
    "        \"param_grid\": [\n",
    "            {\n",
    "                \"k1\": 0.9,\n",
    "                \"b\": 0.4,\n",
    "                \"mu\": mu,\n",
    "                \"fb_terms\": 10,\n",
    "                \"fb_docs\": 10,\n",
    "                \"original_weight\": 0.5,\n",
    "                \"k_docs\": k_docs,\n",
    "                \"window\": window,\n",
    "                \"overlap\": overlap,\n",
    "            }\n",
    "            for mu, k_docs, window, overlap in product(\n",
    "                [1000, 2000],\n",
    "                [100, 250, 500],\n",
    "                [150, 250],\n",
    "                [30, 50]\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Total experiments configured:\")\n",
    "for exp in EXPERIMENTS:\n",
    "    print(f\"  {exp['model_name']}: {len(exp['param_grid'])} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3fab848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2463\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2475\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2453\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2422\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=0.6\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2392\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2450\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2455\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2442\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2415\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=0.9\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2374\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2426\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2427\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2424\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2400\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=1.2\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2334\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2392\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2396\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2384\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2360\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=1.5\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2307\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.3__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2320\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.4__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2330\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.5__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2324\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.6__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2292\n",
      "\n",
      "============================================================\n",
      "Experiment: BM25__b=0.75__k1=2.0\n",
      "Model: BM25\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2250\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=10__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2486\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=10__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2616\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=10__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2613\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2441\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2559\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2587\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=10__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2499\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=10__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2583\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=10__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2605\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=20__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2562\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=20__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2719\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=20__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2630\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=20__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2600\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=20__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2670\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=20__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2588\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=20__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2612\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=20__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2684\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=20__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2624\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=30__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2600\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=30__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2690\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=5__fb_terms=30__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2625\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=30__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2564\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=30__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2628\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=10__fb_terms=30__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2583\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=30__k1=0.9__original_weight=0.3\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2622\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=30__k1=0.9__original_weight=0.5\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2672\n",
      "\n",
      "============================================================\n",
      "Experiment: RM3__b=0.4__fb_docs=15__fb_terms=30__k1=0.9__original_weight=0.7\n",
      "Model: RM3\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2610\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=100__mu=1000__original_weight=0.5__overlap=30__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2859\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=100__mu=1000__original_weight=0.5__overlap=50__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2851\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=100__mu=1000__original_weight=0.5__overlap=30__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2812\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=100__mu=1000__original_weight=0.5__overlap=50__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2791\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=1000__original_weight=0.5__overlap=30__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2947\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=1000__original_weight=0.5__overlap=50__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2979\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=1000__original_weight=0.5__overlap=30__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n",
      "✓ Loaded from cache\n",
      "\n",
      "Results:\n",
      "  MAP: 0.2833\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=1000__original_weight=0.5__overlap=50__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [01:49<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2834\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=30__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [02:36<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2985\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=50__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [02:32<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.3018\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=30__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [03:20<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2905\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=50__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [03:27<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2834\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=100__mu=2000__original_weight=0.5__overlap=30__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [00:39<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2838\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=100__mu=2000__original_weight=0.5__overlap=50__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [00:38<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2820\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=100__mu=2000__original_weight=0.5__overlap=30__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [00:48<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2794\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=100__mu=2000__original_weight=0.5__overlap=50__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2740\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=2000__original_weight=0.5__overlap=30__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [01:26<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2941\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=2000__original_weight=0.5__overlap=50__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [01:23<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2941\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=2000__original_weight=0.5__overlap=30__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [01:48<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2829\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=2000__original_weight=0.5__overlap=50__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [01:48<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2828\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=2000__original_weight=0.5__overlap=30__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [02:44<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2970\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=2000__original_weight=0.5__overlap=50__window=150\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [02:37<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2987\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=2000__original_weight=0.5__overlap=30__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [03:24<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2875\n",
      "\n",
      "============================================================\n",
      "Experiment: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=2000__original_weight=0.5__overlap=50__window=250\n",
      "Model: AdvancedHybrid\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 50/50 [03:24<00:00,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  MAP: 0.2803\n",
      "\n",
      "============================================================\n",
      "All experiments completed.\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    model_name = exp[\"model_name\"]\n",
    "    model_class = exp[\"model_class\"]\n",
    "    \n",
    "    for params in exp[\"param_grid\"]:\n",
    "        config_key = generate_config_key(model_name, params)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Experiment: {config_key}\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        cached = load_cached_result(config_key)\n",
    "        if cached is not None:\n",
    "            print(\"✓ Loaded from cache\")\n",
    "            result = cached\n",
    "        else:\n",
    "            result = run_experiment(\n",
    "                config_key=config_key,\n",
    "                model_name=model_name,\n",
    "                model_class=model_class,\n",
    "                model_params=params,\n",
    "                queries=train_queries,\n",
    "                qrels=qrels\n",
    "            )\n",
    "            save_experiment_result(result)\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  MAP: {result['map']:.4f}\")\n",
    "        \n",
    "        results.append(result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All experiments completed.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9b7a2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Top 10 Results (sorted by MAP):\n",
      "====================================================================================================\n",
      "#   Model                  MAP Config                                                                \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "1   AdvancedHybrid      0.3018 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=50__window=150\n",
      "2   AdvancedHybrid      0.2987 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=2000__original_weight=0.5__overlap=50__window=150\n",
      "3   AdvancedHybrid      0.2985 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=30__window=150\n",
      "4   AdvancedHybrid      0.2979 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=1000__original_weight=0.5__overlap=50__window=150\n",
      "5   AdvancedHybrid      0.2970 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=2000__original_weight=0.5__overlap=30__window=150\n",
      "6   AdvancedHybrid      0.2947 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=1000__original_weight=0.5__overlap=30__window=150\n",
      "7   AdvancedHybrid      0.2941 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=2000__original_weight=0.5__overlap=30__window=150\n",
      "8   AdvancedHybrid      0.2941 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=250__mu=2000__original_weight=0.5__overlap=50__window=150\n",
      "9   AdvancedHybrid      0.2905 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=30__window=250\n",
      "10  AdvancedHybrid      0.2875 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=2000__original_weight=0.5__overlap=30__window=250\n"
     ]
    }
   ],
   "source": [
    "results_sorted = sorted(results, key=lambda x: x[\"map\"], reverse=True)\n",
    "top_k = results_sorted[:10]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Top 10 Results (sorted by MAP):\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "header = f\"{'#':<3} {'Model':<15} {'MAP':>10} {'Config':<70}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for i, r in enumerate(top_k, start=1):\n",
    "    print(\n",
    "        f\"{i:<3} \"\n",
    "        f\"{r['model']:<15} \"\n",
    "        f\"{r['map']:>10.4f} \"\n",
    "        f\"{r['config_key']:<70}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e509e",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe1916",
   "metadata": {},
   "source": [
    "### 6.1. Best Model per Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ddf8fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration per model:\n",
      "================================================================================\n",
      "\n",
      "AdvancedHybrid:\n",
      "  MAP: 0.3018\n",
      "  Config: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=50__window=150\n",
      "\n",
      "RM3:\n",
      "  MAP: 0.2719\n",
      "  Config: RM3__b=0.4__fb_docs=5__fb_terms=20__k1=0.9__original_weight=0.5\n",
      "\n",
      "BM25:\n",
      "  MAP: 0.2475\n",
      "  Config: BM25__b=0.4__k1=0.6\n"
     ]
    }
   ],
   "source": [
    "# Find best config for each model type\n",
    "best_per_model = {}\n",
    "for r in results_sorted:\n",
    "    model = r[\"model\"]\n",
    "    if model not in best_per_model:\n",
    "        best_per_model[model] = r\n",
    "\n",
    "print(\"Best configuration per model:\")\n",
    "print(\"=\" * 80)\n",
    "for model, r in best_per_model.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"  MAP: {r['map']:.4f}\")\n",
    "    print(f\"  Config: {r['config_key']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b57ea",
   "metadata": {},
   "source": [
    "### 6.2. Training Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "530cee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "TRAINING PERFORMANCE SUMMARY (50 queries)\n",
      "====================================================================================================\n",
      "        Method      MAP                                                                                                                   Config\n",
      "AdvancedHybrid 0.301796 AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=50__window=150\n",
      "           RM3 0.271865                                                          RM3__b=0.4__fb_docs=5__fb_terms=20__k1=0.9__original_weight=0.5\n",
      "          BM25 0.247464                                                                                                      BM25__b=0.4__k1=0.6\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary_data = []\n",
    "for model, r in best_per_model.items():\n",
    "    summary_data.append({\n",
    "        \"Method\": model,\n",
    "        \"MAP\": r[\"map\"],\n",
    "        \"Config\": r[\"config_key\"]\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data).sort_values(\"MAP\", ascending=False)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"TRAINING PERFORMANCE SUMMARY (50 queries)\")\n",
    "print(\"=\" * 100)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2695a66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXE9JREFUeJzt3XlcVdXi///3AZVRBgUZFAWRnIfCRM0pRcFM45Pl0KCgOXVtuJSWlvOYqXFLyyyHLGdT+zaIGkllOdw0s0xKTUVRVBzAERT2749+nNsJUFC2R/P1fDzOI87aa6+91j5Dvs/ee22LYRiGAAAAAABAqXOwdwcAAAAAAPinInQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAPALSY2NlbBwcHXte7o0aNlsVhKt0O3oHPnzumpp56Sv7+/LBaLnn/+eXt3Cbe52+Gzs2zZMlWoUEHnzp2zd1duGWa+bpcvX1ZQUJDefvttU9oHcOcgdANAMVkslmI9kpOT7d1Vu4iNjbXZDx4eHmrYsKGmTZum7OzsUt3WxIkTNX/+fA0aNEgffvihnnzyyVJt/06Um5urefPmqU2bNqpQoYKcnJwUHBysuLg4/fDDD/bu3h0vNzdXo0aN0jPPPCN3d3dreZs2bQr9HoqOji7QRnZ2tl566SUFBgbKxcVFERERWr9+/c0cxm2lbNmyio+P14QJE3Tp0iV7dwfAbcxiGIZh704AwO3go48+snm+YMECrV+/Xh9++KFNefv27eXn53fd27l8+bLy8vLk5ORU4nWvXLmiK1euyNnZ+bq3f71iY2O1ZMkSvf/++5KkM2fO6OOPP1ZycrK6d++uJUuWlNq2mjZtqjJlymjjxo2l1uad7OLFi3r44YeVmJioVq1aqXPnzqpQoYIOHDigZcuW6ffff1dqaqqqVKli766axp6fneJYvXq1Hn74YR06dEiVK1e2lrdp00b79u3TpEmTbOoHBgaqbdu2NmU9e/bUihUr9PzzzyssLEzz58/Xf//7X23YsEEtWrS4KeMobWa/bmfOnJGfn5/eeecd9enTx5RtAPjnI3QDwHUaPHiwZs6cqWt9jV64cEGurq43qVf2ExsbqxUrVtic+pqXl6eIiAj98MMPSktLU2Bg4HW3n5eXp5ycHDk7O6t69eqqU6eOPvvss9Louq5cuaK8vDyVK1euVNq73eS/l994440Cp+rn5ubqjTfeUI8ePf6Rofv8+fNyc3Ozdzeu6aGHHtKpU6f07bff2pS3adNGGRkZ+uWXX666/tatWxUREaHXX39dL774oiTp0qVLqlevnipVqqTvv//etL6b4Wa+bp07d1ZmZqa++eabm7I9AP88nF4OAKWoTZs2qlevnrZt26ZWrVrJ1dVVw4cPlyR98skn6tSpkwIDA+Xk5KTQ0FCNGzdOubm5Nm38/ZruAwcOyGKxaOrUqZo9e7ZCQ0Pl5OSke++9V//9739t1i3s+kaLxaLBgwdr9erVqlevnpycnFS3bl0lJiYW6H9ycrIaN24sZ2dnhYaG6t13372hayYdHBzUpk0b6zikP09xHTVqlGrUqCEnJycFBQVp6NChBU5Bz+/3woULVbduXTk5OSkxMVEWi0X79+/X559/bj2VNr/t48ePq2/fvvLz85Ozs7MaNmyoDz74wKbdv+7PhIQE6/789ddfrWP9/fff9cQTT8jT01O+vr4aMWKEDMPQoUOH9NBDD8nDw0P+/v6aNm2aTds5OTkaOXKkwsPD5enpKTc3N7Vs2VIbNmwosg/Xek0lKSUlRd26dZOvr69cXFxUs2ZNvfLKKzZ10tLS1KdPH/n5+Vlf47lz517zNTp8+LDeffddtW/fvtBr4x0dHfXiiy/aBO4ff/xRHTt2lIeHh9zd3dWuXTtt3rzZZr358+fLYrFo48aNevbZZ+Xr6ysvLy8NGDBAOTk5OnPmjHr16iVvb295e3tr6NChNj9g/XUfvfHGG6pWrZpcXFzUunXrAgFz586dio2NVfXq1eXs7Cx/f3/16dNHJ0+etKmX//r++uuveuyxx+Tt7W09wlvY+3z9+vVq0aKFvLy85O7urpo1a1o/z/lK+p4rzuv9d5cuXVJiYqIiIyOLrHPlypWrXuu9YsUKOTo6qn///tYyZ2dn9e3bV5s2bdKhQ4eu2Y/8vru4uKhJkyb69ttv1aZNG+tnXPrf657/mcyXnJxc6OU3W7ZsUXR0tDw9PeXq6qrWrVvru+++s6lT0tdN+vPMpPDwcLm4uKhChQrq0aNHgTHu2bNHXbt2lb+/v5ydnVWlShX16NFDmZmZNvXat2+vjRs36tSpU9fcRwBQmDL27gAA/NOcPHlSHTt2VI8ePfTEE09YTzWfP3++3N3dFR8fL3d3d3311VcaOXKksrKy9Prrr1+z3UWLFuns2bMaMGCALBaLpkyZoocfflh//PGHypYte9V1N27cqJUrV+rpp59W+fLl9eabb6pr165KTU1VxYoVJf0ZpKKjoxUQEKAxY8YoNzdXY8eOla+v7w3tj3379kmSKlasqLy8PHXp0kUbN25U//79Vbt2bf38889644039Pvvv2v16tU263711VdatmyZBg8eLB8fHwUEBOjDDz/Uv//9b1WpUkUvvPCCJMnX11cXL15UmzZttHfvXg0ePFghISFavny5YmNjdebMGT333HM2bc+bN0+XLl1S//795eTkpAoVKliXde/eXbVr19bkyZP1+eefa/z48apQoYLeffddtW3bVq+99poWLlyoF198Uffee69atWolScrKytL777+vnj17ql+/fjp79qzmzJmjqKgobd26VY0aNbLpQ3Fe0507d6ply5YqW7as+vfvr+DgYO3bt0+ffvqpJkyYIEk6duyYmjZtav2hwtfXV2vWrFHfvn2VlZV11Ynm1qxZoytXrhT7uvhdu3apZcuW8vDw0NChQ1W2bFm9++67atOmjb7++mtFRETY1H/mmWfk7++vMWPGaPPmzZo9e7a8vLz0/fffq2rVqpo4caK++OILvf7666pXr5569epls/6CBQt09uxZ/etf/9KlS5f0n//8R23bttXPP/9s/WytX79ef/zxh+Li4uTv769du3Zp9uzZ2rVrlzZv3lwglD366KMKCwvTxIkTizxTZdeuXXrwwQfVoEEDjR07Vk5OTtq7d69NICzpe+56P8Pbtm1TTk6O7rnnnkKX//7773Jzc1NOTo78/PzUr18/jRw50qbNH3/8UXfddZc8PDxs1m3SpIkkaceOHQoKCiqyD3PmzNGAAQPUvHlzPf/88/rjjz/UpUsXVahQ4arrXc1XX32ljh07Kjw8XKNGjZKDg4PmzZuntm3b6ttvv7X2LV9xXjdJmjBhgkaMGKFu3brpqaee0okTJ/TWW2+pVatW+vHHH+Xl5aWcnBxFRUUpOzvb+h5NS0vTZ599pjNnzsjT09PaXnh4uAzD0Pfff68HH3zwusYK4A5nAACuy7/+9S/j71+jrVu3NiQZs2bNKlD/woULBcoGDBhguLq6GpcuXbKW9e7d26hWrZr1+f79+w1JRsWKFY1Tp05Zyz/55BNDkvHpp59ay0aNGlWgT5KMcuXKGXv37rWW/fTTT4Yk46233rKWde7c2XB1dTXS0tKsZXv27DHKlClToM3C9O7d23BzczNOnDhhnDhxwti7d68xceJEw2KxGA0aNDAMwzA+/PBDw8HBwfj2229t1p01a5Yhyfjuu+9s+u3g4GDs2rWrwLaqVatmdOrUyaYsISHBkGR89NFH1rKcnByjWbNmhru7u5GVlWUYxv/2p4eHh3H8+HGbNvL3X//+/a1lV65cMapUqWJYLBZj8uTJ1vLTp08bLi4uRu/evW3qZmdn27R5+vRpw8/Pz+jTp4+1rCSvaatWrYzy5csbBw8etGk3Ly/P+nffvn2NgIAAIyMjw6ZOjx49DE9Pz0Lfe/n+/e9/G5KMH3/8scg6fxUTE2OUK1fO2Ldvn7XsyJEjRvny5Y1WrVpZy+bNm2dIMqKiomz62qxZM8NisRgDBw60luXv49atW1vL8veRi4uLcfjwYWv5li1bDEnGv//9b2tZYeNbvHixIcn45ptvrGX5r2/Pnj0L1P/7Z+eNN94wJBknTpwocl+U9D1XnNe7MO+//74hyfj5558LLOvTp48xevRo4+OPPzYWLFhgdOnSxZBkdOvWzaZe3bp1jbZt2xZYf9euXUV+Z/11TJUqVTIaNWpk8/6ePXu2Icnmdct/3ffv32/TxoYNGwxJxoYNGwzD+PP9GxYWVuD9ceHCBSMkJMRo3769tawkr9uBAwcMR0dHY8KECTb1fv75Z6NMmTLW8h9//NGQZCxfvrzIcec7cuSIIcl47bXXrlkXAArD6eUAUMqcnJwUFxdXoNzFxcX699mzZ5WRkaGWLVvqwoULSklJuWa73bt3l7e3t/V5y5YtJUl//PHHNdeNjIxUaGio9XmDBg3k4eFhXTc3N1dffvmlYmJibK67rlGjhjp27HjN9vOdP39evr6+8vX1VY0aNTR8+HA1a9ZMq1atkiQtX75ctWvXVq1atZSRkWF95E/49PfTsFu3bq06deoUa9tffPGF/P391bNnT2tZ2bJl9eyzz+rcuXP6+uuvbep37dq1yKP4Tz31lPVvR0dHNW7cWIZhqG/fvtZyLy8v1axZ02b/Ozo6Wq8Lz8vL06lTp3TlyhU1btxY27dvL7Cda72mJ06c0DfffKM+ffqoatWqNuvmH701DEMff/yxOnfuLMMwbPZrVFSUMjMzC912vqysLElS+fLli6yTLzc3V+vWrVNMTIyqV69uLQ8ICNBjjz2mjRs3WtvL17dvX5sjzREREQX2Zf4+Luy9HBMTYzNxWJMmTRQREaEvvvjCWvbXz9alS5eUkZGhpk2bSlKhYx84cOA1x+rl5SXpz8tC8vLyCq1T0vfc9X6G80+T/+u6+ebMmaNRo0bp4Ycf1pNPPqlPPvlE/fr107Jly2xO+b948WKhkzPmT0B28eLFIrf/ww8/6Pjx4xo4cKDNvAexsbE2R4RLYseOHdqzZ48ee+wxnTx50vqePX/+vNq1a6dvvvmmwH4vzuu2cuVK5eXlqVu3bjafBX9/f4WFhVm/Y/L7vXbtWl24cOGqbebv94yMjOsZKgBwejkAlLbKlSsXOiHXrl279Oqrr+qrr74qEEz+fg1hYf4euvL/IXj69OkSr5u/fv66x48f18WLF1WjRo0C9QorK4qzs7M+/fRTSX/++BASEmJzLfCePXu0e/fuIsPu8ePHbZ6HhIQUe9sHDx5UWFiYHBxsf0+uXbu2dXlx2/77/vL09JSzs7N8fHwKlP/9uuEPPvhA06ZNU0pKii5fvnzV7V3rNc0PY/Xq1SuyrydOnNCZM2c0e/ZszZ49u9A6f9+vf5V/uvHZs2eLrPPXbV24cEE1a9YssKx27drKy8vToUOHVLduXWt5YftSUoFTkj09PQt9L4eFhRUou+uuu7Rs2TLr81OnTmnMmDFasmRJgbEW9tkqzvuqe/fuev/99/XUU0/p5ZdfVrt27fTwww/rkUcesb7HSvqeu5HPsKRrTtqY74UXXtB7772nL7/80vrjg4uLS6G37su/FdZff7j4u/xx/P21KFu2rM2PLyWxZ88eSVLv3r2LrJOZmWnzQ0NxXrc9e/bIMIxC3zeSrKfch4SEKD4+XtOnT9fChQvVsmVLdenSxTqXw1/l7/db/T7uAG5dhG4AKGWF/eP1zJkzat26tTw8PDR27FiFhobK2dlZ27dv10svvVTkkbS/cnR0LLS8OP8Qv5F1S8LR0fGqkz3l5eWpfv36mj59eqHL/x7ErhYEbtTV2i5sfxVnH3700UeKjY1VTEyMhgwZokqVKsnR0VGTJk2yXtte0javJf+988QTTxQZYBo0aFDk+rVq1ZIk/fzzzwWuOS8NRY2xsPLrfT9269ZN33//vYYMGaJGjRrJ3d1deXl5io6OLvSzVZz3lYuLi7755htt2LBBn3/+uRITE7V06VK1bdtW69atK3JcV3O9r3f+vAunT58u1gzy+Z+jv078FRAQoLS0tAJ1jx49Kkk3dGeBvyoqmP59wsj81+X1118v8n331/uRS8V73fLy8mSxWLRmzZpC9/df25w2bZpiY2P1ySefaN26dXr22Wc1adIkbd682WY/5/8o8vcf3QCguAjdAHATJCcn6+TJk1q5cqV10i1J2r9/vx179T+VKlWSs7Oz9u7dW2BZYWXXKzQ0VD/99JPatWtX6keNqlWrpp07dyovL8/myGP+qfvVqlUr1e0VZsWKFapevbpWrlxpM75Ro0ZdV3v5RxGvdjsoX19flS9fXrm5uVf9waMoHTt2lKOjoz766KNrTqbm6+srV1dX/fbbbwWWpaSkyMHB4bon1SpK/hHRv/r999+tM/yfPn1aSUlJGjNmjEaOHHnV9UrKwcFB7dq1U7t27TR9+nRNnDhRr7zyijZs2KDIyMib9p7L/2Fk//79ql+//jXr558h8dczSho1aqQNGzYoKyvLZjK1LVu2WJcXJX8ce/bssbn39+XLl7V//341bNjQWpZ/ZPrMmTM2bfz9qH/+5S4eHh7X9b4tSmhoqAzDUEhIiO66665r1q9fv77q16+vV199Vd9//73uu+8+zZo1S+PHj7fWyf+ezj+DAQBKimu6AeAmyD/i8tcjWjk5OXr77bft1SUb+UeoV69erSNHjljL9+7dqzVr1pTadrp166a0tDS99957BZZdvHhR58+fv+62H3jgAaWnp2vp0qXWsitXruitt96Su7u7Wrdufd1tF1dhr/OWLVu0adOm62rP19dXrVq10ty5c5WammqzLH8bjo6O6tq1qz7++ONCw/mJEyeuuo2goCD169dP69at01tvvVVgeV5enqZNm6bDhw/L0dFRHTp00CeffGJzS6hjx45p0aJFatGiRYHZsW/U6tWrbY7Qbt26VVu2bLHONVDYPpekhISEG9puYbeHyg+m+adp36z3XHh4uMqVK6cffvjBpjwrK6vAKeOGYVgDY1RUlLX8kUceUW5urs0lCNnZ2Zo3b54iIiKu+mNJ48aN5evrq1mzZiknJ8daPn/+/ALhOj9M//We1n/fbv6YQkNDNXXq1EJvdXat921RHn74YTk6OmrMmDEF3hOGYVgvB8nKytKVK1dsltevX18ODg4F9um2bdtksVjUrFmz6+oTAHCkGwBugubNm8vb21u9e/fWs88+K4vFog8//LDUT+++EaNHj9a6det03333adCgQcrNzdWMGTNUr1497dixo1S28eSTT2rZsmUaOHCgNmzYoPvuu0+5ublKSUnRsmXLtHbtWjVu3Pi62u7fv7/effddxcbGatu2bQoODtaKFSv03XffKSEhoVgThd2oBx98UCtXrtT//d//qVOnTtq/f79mzZqlOnXqXPUeylfz5ptvqkWLFrrnnnvUv39/hYSE6MCBA/r888+tr8vkyZO1YcMGRUREqF+/fqpTp45OnTql7du368svv7zm/YWnTZumffv26dlnn9XKlSv14IMPytvbW6mpqVq+fLlSUlLUo0cPSdL48eOt969++umnVaZMGb377rvKzs7WlClTrmuMV1OjRg21aNFCgwYNUnZ2thISElSxYkUNHTpU0p9HSlu1aqUpU6bo8uXLqly5statW3fDZ5GMHTtW33zzjTp16qRq1arp+PHjevvtt1WlShXrPaJv1nvO2dlZHTp00JdffqmxY8day7dv366ePXuqZ8+eqlGjhi5evKhVq1bpu+++U//+/W1uMRYREaFHH31Uw4YN0/Hjx1WjRg198MEHOnDggObMmXPV7ZctW1bjx4/XgAED1LZtW3Xv3l379+/XvHnzClzTXbduXTVt2lTDhg3TqVOnVKFCBS1ZsqRAwHVwcND777+vjh07qm7duoqLi1PlypWVlpamDRs2yMPDwzo/REmEhoZq/PjxGjZsmA4cOKCYmBiVL19e+/fv16pVq9S/f3+9+OKL+uqrrzR48GA9+uijuuuuu3TlyhV9+OGH1h+x/mr9+vW67777rKf5A0BJEboB4CaoWLGiPvvsM73wwgt69dVX5e3trSeeeELt2rWzORplT+Hh4VqzZo1efPFFjRgxQkFBQRo7dqx2795drNnVi8PBwUGrV6/WG2+8oQULFmjVqlVydXVV9erV9dxzzxXrdNCiuLi4KDk5WS+//LI++OADZWVlqWbNmpo3b55iY2NLpf/XEhsbq/T0dL377rtau3at6tSpo48++kjLly9XcnLydbXZsGFDbd68WSNGjNA777yjS5cuqVq1aurWrZu1jp+fn7Zu3aqxY8dq5cqVevvtt1WxYkXVrVtXr7322jW34erqqjVr1mj+/Pn64IMPNG7cOF24cEGBgYFq27atFi5caJ1BvG7duvr22281bNgwTZo0SXl5eYqIiNBHH31U4B7dpaFXr15ycHBQQkKCjh8/riZNmmjGjBkKCAiw1lm0aJGeeeYZzZw5U4ZhqEOHDlqzZs0NXafcpUsXHThwQHPnzlVGRoZ8fHzUunVrjRkzxjrR1s18z/Xp00ddu3bVoUOHrEelq1WrppYtW2rVqlVKT0+Xg4ODateurVmzZql///4F2liwYIFGjBihDz/8UKdPn1aDBg302Wef2VzyUpT+/fsrNzdXr7/+uoYMGaL69evr//2//6cRI0YUqLtw4UINGDBAkydPlpeXl/r27av7779f7du3t6nXpk0bbdq0SePGjdOMGTN07tw5+fv7KyIiQgMGDLjOPSW9/PLLuuuuu/TGG29ozJgxkv48o6NDhw7q0qWLpD8/V1FRUfr000+VlpYmV1dXNWzYUGvWrLFOPif9OZnbunXrbpmzkgDcnizGrXSYBQBwy4mJidGuXbtK5RpZoLgOHDigkJAQvf7663rxxRft3R27y83NVZ06ddStWzeNGzfO3t2xatOmjSRd949Kt7qEhARNmTJF+/btM3ViRwD/bFzTDQCw+vu9evfs2aMvvvjC+g9rAPbh6OiosWPHaubMmdd9qQJK5vLly5o+fbpeffVVAjeAG8Lp5QAAq+rVqys2NlbVq1fXwYMH9c4776hcuXLW62cB2E/37t3VvXt3e3fjjlG2bNkCExgCwPUgdAMArKKjo7V48WKlp6fLyclJzZo108SJExUWFmbvrgEAANyWuKYbAAAAAACTcE03AAAAAAAmIXQDAAAAAGASrukuRF5eno4cOaLy5cvLYrHYuzsAAAAAgFuMYRg6e/asAgMD5eBQ9PFsQnchjhw5oqCgIHt3AwAAAABwizt06JCqVKlS5HJCdyHKly8v6c+d5+HhYefeAAAAAABuNVlZWQoKCrLmx6IQuguRf0q5h4cHoRsAAAAAUKRrXZLMRGoAAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3UAJpaSkqH379nJzc5O/v7+GDh2qnJyca673xBNPKCwsTG5ubvL29larVq20bt26AvUyMzPVt29fVahQQeXLl9cjjzyio0eP2tT54YcfFBcXp9q1a8vBwUEPPvhgods8efKkBg4cqKpVq8rNzU316tXTrFmzrm/gAAAAAEqsjL07ANxOTp8+rbZt2yosLEwrV65UWlqa4uPjdeHCBc2YMeOq6+bk5Cg+Pl5hYWG6dOmS5syZowceeEAbNmxQy5YtrfW6d++uXbt2adasWXJ2dtYrr7yijh076ocfflCZMn9+ZL/77jt9++23ioiI0MWLF4vc5qOPPqqUlBRNnDhRVatW1RdffKFBgwbJ0dFR/fr1K52dAgAAAKBIFsMwDHt34laTlZUlT09PZWZmysPDw97dwS1k0qRJmjBhglJTU1WhQgVJ0uzZs/X0008rNTVVgYGBxW4rNzdXISEhio6O1uzZsyVJmzZtUvPmzbV27Vp16NBBkvTbb7+pdu3aWrJkibp16yZJysvLk4PDnyeqtGnTRu7u7vrss89s2k9PT1dAQIDmzZun2NhYa3nr1q1VpkwZJSUlXfd+AAAAAO50xc2NnF4OlMCaNWsUGRlpDdyS1K1bN+Xl5RV6qvjVODo6ysvLy+bU9DVr1sjLy0vt27e3ltWsWVONGjXSF198YS3LD9xXc/nyZUmSp6enTbmnp6f4rQ0AAAC4OQjdQAmkpKSoVq1aNmVeXl4KCAhQSkrKNdc3DENXrlzRyZMnNXXqVO3Zs0cDBgywab9mzZqyWCw269WuXbtY7f9VUFCQOnTooIkTJ+rXX3/V2bNntWzZMq1bt07/+te/StQWAAAAgOvDNd1ACZw+fVpeXl4Fyr29vXXq1Klrrj9nzhzrtdTu7u5aunSpmjVrVmrt/93KlSvVvXt31a1bV9KfR9ffeustde3atcRtAQAAACg5QjdwE8XExKhRo0bKyMjQ8uXL1a1bN61atUodO3Ys9W0ZhqG4uDjt2bNHixYtUkBAgNavX6/nn39e3t7e6tGjR6lvEwAAAIAtQjdQAt7e3srMzCxQfvr0aZvrvIvi4+MjHx8fSVJ0dLROnTqlIUOGWEO3t7e3Dh06dN3t/9Xnn3+u5cuXa+fOnapfv76kPyddO378uF544QVCNwAAAHATcE03UAK1atUqcG11Zmamjh49WuBa7+IIDw/X3r17bdr/7bffCkx0Vti15Nfy66+/ytHRUfXq1bMpv/vuu3XkyBFduHChxP0FAAAAUDKEbqAEOnbsqC+//FJnzpyxli1fvlwODg7WW3yVxMaNG1W9enWb9k+fPm1zO6/ff/9dP/74ox544IEStV2tWjXl5uZq586dNuXbtm1TpUqV5OrqWuL+AgAAACgZTi8HSmDgwIF66623FBMTo+HDhystLU1DhgzRwIEDbe7R3a5dOx08eNB6FPvzzz/XggUL9OCDDyooKEinTp3SokWLtHbtWi1evNi6XrNmzRQVFaU+ffpo2rRpcnZ21iuvvKIGDRro4YcfttY7ceKEvv76a+vf586d04oVKyRJDzzwgFxdXfXAAw+oatWqeuSRRzRq1CgFBARo3bp1mj9/vsaMGXMzdhcAAABwxyN0AyXg7e2tpKQkPfPMM4qJiVH58uX11FNPacKECTb1cnNzdeXKFevz0NBQZWdn6+WXX1ZGRoZ8fHzUoEEDJScnq3Xr1jbrLl26VPHx8erfv7+uXLmiDh066K233lKZMv/7uO7atUuPPvqozXr5z/fv36/g4GCVL19eSUlJeuWVV/TSSy/pzJkzCgkJ0fTp0zV48ODS3jUAAAAACmEx/n7xKJSVlSVPT09lZmbKw8PD3t0BAAAAANxiipsbuaYbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAk9wSoXvmzJkKDg6Ws7OzIiIitHXr1iLrrly5Uo0bN5aXl5fc3NzUqFEjffjhhzZ1DMPQyJEjFRAQIBcXF0VGRmrPnj1mDwMAAAAAABt2D9359yQeNWqUtm/froYNGyoqKkrHjx8vtH6FChX0yiuvaNOmTdq5c6fi4uIUFxentWvXWutMmTJFb775pmbNmqUtW7bIzc1NUVFRunTp0s0aFgAAAAAA9r9Pd0REhO69917NmDFDkpSXl6egoCA988wzevnll4vVxj333KNOnTpp3LhxMgxDgYGBeuGFF/Tiiy9KkjIzM+Xn56f58+erR48e12zvdrlPd2pqqjIyMuzdDQDF5OPjo6pVq9q7GwAAACgFxc2NZW5inwrIycnRtm3bNGzYMGuZg4ODIiMjtWnTpmuubxiGvvrqK/3222967bXXJEn79+9Xenq6IiMjrfU8PT0VERGhTZs2FSt03w5SU1NVs1ZtXbp4wd5dAVBMzi6u+i1lN8EbAADgDmLX0J2RkaHc3Fz5+fnZlPv5+SklJaXI9TIzM1W5cmVlZ2fL0dFRb7/9ttq3by9JSk9Pt7bx9zbzl/1ddna2srOzrc+zsrKuazw3U0ZGhi5dvKCQuKlyDqhh7+4AuIZLR/dq/7wXlZGRQegGAAC4g9g1dF+v8uXLa8eOHTp37pySkpIUHx+v6tWrq02bNtfV3qRJkzRmzJjS7eRN4hxQQ25V69q7GwAAAACAQth1IjUfHx85Ojrq2LFjNuXHjh2Tv79/kes5ODioRo0aatSokV544QU98sgjmjRpkiRZ1ytJm8OGDVNmZqb1cejQoRsZFgAAAAAAkuwcusuVK6fw8HAlJSVZy/Ly8pSUlKRmzZoVu528vDzr6eEhISHy9/e3aTMrK0tbtmwpsk0nJyd5eHjYPAAAAAAAuFF2P708Pj5evXv3VuPGjdWkSRMlJCTo/PnziouLkyT16tVLlStXth7JnjRpkho3bqzQ0FBlZ2friy++0Icffqh33nlHkmSxWPT8889r/PjxCgsLU0hIiEaMGKHAwEDFxMTYa5gAAAAAgDuQ3UN39+7ddeLECY0cOVLp6elq1KiREhMTrROhpaamysHhfwfkz58/r6efflqHDx+Wi4uLatWqpY8++kjdu3e31hk6dKjOnz+v/v3768yZM2rRooUSExPl7Ox808cHAAAAALhz2f0+3bei2+E+3du3b1d4eLhqD1/NRGrAbeB86i7tnhijbdu26Z577rF3dwAAAHCDipsb7XpNNwAAAAAA/2SEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAA/gFSUlLUvn17ubm5yd/fX0OHDlVOTs5V1zl69KiGDh2qRo0aqXz58qpSpYoee+wxHTx40KZebGysLBZLoY/Jkydb661fv16PPfaYQkNDZbFYNHjw4EK3m5aWpu7du8vT01Ply5dXly5dtH///hvfCQAA3ILK2LsDAADgxpw+fVpt27ZVWFiYVq5cqbS0NMXHx+vChQuaMWNGkett27ZNK1euVJ8+fdS0aVNlZGRo3LhxatKkiX755Rf5+vpKkkaMGKGBAwfarLt06VIlJCSoY8eO1rLExET99NNPat26tU6dOlXoNnNzc9WxY0edP39es2fPlpOTk8aMGaO2bdvq559/lru7eynsEQAAbh2EbgAAbnOzZs1SVlaWVq1apQoVKkiSrly5oqefflrDhw9XYGBgoeu1aNFCKSkpKlPmf/8caN68uapWraoFCxbohRdekCSFhoYqNDTUZt2XX35ZderUUcOGDa1lr7/+uqZNmyZJ+uqrrwrd5vLly/Xzzz/rp59+UoMGDSRJ9957r0JDQ/Xee+/p3//+93XuBQAAbk2cXg4AwG1uzZo1ioyMtAZuSerWrZvy8vK0bt26Itfz8vKyCdySVKVKFfn6+urIkSNFrpeWlqZvv/1Wjz/+uE25g8O1/1nx448/yt/f3xq4Jaly5cqqV6+ePv3002uuDwDA7YbQDQDAbS4lJUW1atWyKfPy8lJAQIBSUlJK1Nbvv/+u48ePq3bt2kXWWbx4sfLy8tSzZ88S9/XSpUtycnIqUO7k5KTdu3eXuD0AAG51hG4AAG5zp0+flpeXV4Fyb2/vIq+tLoxhGHr22WcVGBh41UC9aNEiNWvWTCEhISXua1hYmA4fPmxzJP3cuXPatWtXifoKAMDtgtANAAAkSaNHj1ZSUpIWLFggNze3QuukpKToxx9/1GOPPXZd23jsscdUvnx5xcXF6Y8//tDhw4f11FNP6dy5c7JYLDfSfQAAbkmEbgAAbnPe3t7KzMwsUH769Gmb67yv5r333tPYsWP17rvvql27dkXWW7hwocqUKaPu3btfV18rVKigJUuW6JdfflFoaKiCgoJ09OhR9e7dWwEBAdfVJgAAtzJmLwcA4DZXq1atAtduZ2Zm6ujRowWu9S7MqlWrNGjQII0dO1Z9+vS5at3FixcrMjLSejux6xEVFaXU1FT9/vvvcnZ2VkhIiDp16qSmTZted5sAANyqONINAMBtrmPHjvryyy915swZa9ny5cvl4OCgDh06XHXd5ORk9ezZU/369dOIESOuWnfLli3at2/fdZ9a/leOjo6qXbu2QkJClJKSoi+//FL9+vW74XYBALjVcKQbAIDb3MCBA/XWW28pJiZGw4cPV1pamoYMGaKBAwfa3KO7Xbt2OnjwoPbu3StJ2r17t2JiYhQWFqYnn3xSmzdvttb19fUtcG/uRYsWycXFRf/3f/9XaD8OHjyo//73v5KkCxcuaN++fVqxYoUk6ZFHHrHWe+mll9S0aVN5enrqp59+0vjx49WrVy+1bdu2dHYIAAC3EEI3AAC3OW9vbyUlJemZZ55RTEyMypcvr6eeekoTJkywqZebm6srV65Yn2/ZskWZmZnKzMzUfffdZ1O3d+/emj9/vs26y5YtU+fOneXu7l5oPzZs2KC4uDjr88TERCUmJkr6c2b0fIcPH9agQYN0+vRphYSE6JVXXtFzzz133eMHAOBWZjH++n9BSJKysrLk6empzMxMeXh42Ls7hdq+fbvCw8NVe/hquVWta+/uALiG86m7tHtijLZt26Z77rnH3t0BAADADSpubuSabgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATFLG3h0AAPzzpKamKiMjw97dAFAMPj4+qlq1qr27AQD/WIRuAECpSk1NVc3atXTpwkV7dwVAMTi7uui33SkEbwAwCaEbAFCqMjIydOnCRQWNi5ZTSAV7dwfAVWTvP6VDIxKVkZFB6AYAkxC6AQCmcAqpINdafvbuBgAAgF0xkRoAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAA06SkpKh9+/Zyc3OTv7+/hg4dqpycnKuuc/ToUQ0dOlSNGjVS+fLlVaVKFT322GM6ePBgkevk5eUpPDxcFotFK1assFlmsViKfBw9evSq9fz9/W9sB+COx326AQAAAJji9OnTatu2rcLCwrRy5UqlpaUpPj5eFy5c0IwZM4pcb9u2bVq5cqX69Omjpk2bKiMjQ+PGjVOTJk30yy+/yNfXt8A67777rtLS0gptb9OmTQXKevXqJTc3NwUEBNiUP/PMM3rsscesz8uVK1fc4QKFInQDAAAAMMWsWbOUlZWlVatWqUKFCpKkK1eu6Omnn9bw4cMVGBhY6HotWrRQSkqKypT5X1xp3ry5qlatqgULFuiFF16wqZ+RkaFXX31VU6dOVZ8+fQq017RpU5vnBw4c0J49ezRlypQCdatWrVqgPnAjOL0cAAAAgCnWrFmjyMhIa+CWpG7duikvL0/r1q0rcj0vLy+bwC1JVapUka+vr44cOVKg/rBhw3T//ffr/vvvL1a/Fi1aJIvFop49exZzJMD1I3QDAAAAMEVKSopq1aplU+bl5aWAgAClpKSUqK3ff/9dx48fV+3atW3Kt27dqkWLFmnq1KnFbmvx4sVq1aqVqlSpUmDZpEmTVLZsWXl5eal79+5KTU0tUT+BvyN0AwAAADDF6dOn5eXlVaDc29tbp06dKnY7hmHo2WefVWBgoM3R6by8PP3rX//SCy+8oODg4GK1tXPnTv3yyy82123n69Wrl2bNmqWkpCRNnDhR33zzjVq0aKHTp08Xu6/A33FNNwAAAIBb2ujRo5WUlKTExES5ublZy99//32lp6fr5ZdfLnZbCxcuVNmyZfXII48UWPbBBx9Y/27VqpVatGihe+65R++9956GDh16Y4PAHYvQDQAAAMAU3t7eyszMLFB++vRpm+u8r+a9997T2LFjNWfOHLVr185afu7cOQ0fPlwTJkxQTk6OcnJylJWVJUm6cOGCsrKy5OHhYdOWYRhasmSJOnbsWKztN2jQQDVr1tS2bduK1VegMJxeDgAAAMAUtWrVKnDtdmZmpo4ePVrgWu/CrFq1SoMGDdLYsWMLzEqekZGhkydPauDAgfL29pa3t7caNmwoSerdu7fuuuuuAu1t3LhRqamphZ5aDpiFI90AAAAATNGxY0dNnDhRZ86csV7bvXz5cjk4OKhDhw5XXTc5OVk9e/ZUv379NGLEiALL/f39tWHDBpuy9PR09ezZU6NHj1b79u0LrLNo0SK5u7urS5cuxer/jh079NtvvykuLq5Y9YHCELoBAAAAmGLgwIF66623FBMTo+HDhystLU1DhgzRwIEDbe7R3a5dOx08eFB79+6VJO3evVsxMTEKCwvTk08+qc2bN1vr+vr6KjQ0VM7OzmrTpo3N9g4cOCBJqlu3rpo3b26z7MqVK1qxYoViYmLk4uJSoK9Tp07Vvn371KZNG1WqVEm//PKLJkyYoKCgID311FOltEdwJyJ0AwAAADCFt7e3kpKS9MwzzygmJkbly5fXU089pQkTJtjUy83N1ZUrV6zPt2zZoszMTGVmZuq+++6zqdu7d2/Nnz+/xH1Zu3atMjIyijy1vGbNmvr444+1dOlSnT17Vr6+vurUqZPGjx9f6AzsQHERugEAAACYpnbt2vryyy+vWic5OdnmeWxsrGJjY0u8reDgYBmGUeiyTp06FblMkjp37qzOnTuXeJvAtdwSE6nNnDlTwcHBcnZ2VkREhLZu3Vpk3ffee08tW7a0TpYQGRlZoH5sbKwsFovNIzo62uxhAAAAAABgw+6he+nSpYqPj9eoUaO0fft2NWzYUFFRUTp+/Hih9fMnVNiwYYM2bdqkoKAgdejQQWlpaTb1oqOjdfToUetj8eLFN2M4AAAAAABY2T10T58+Xf369VNcXJzq1KmjWbNmydXVVXPnzi20/sKFC/X000+rUaNGqlWrlt5//33l5eUpKSnJpp6Tk5P8/f2tD29v75sxHAAAAAAArOwaunNycrRt2zZFRkZayxwcHBQZGalNmzYVq40LFy7o8uXLBW5un5ycrEqVKqlmzZoaNGiQTp48Wap9BwAAAADgWuw6kVpGRoZyc3Pl5+dnU+7n56eUlJRitfHSSy8pMDDQJrhHR0fr4YcfVkhIiPbt26fhw4erY8eO2rRpkxwdHQu0kZ2drezsbOvzrKys6xwRAAAAAAD/c1vPXj558mQtWbJEycnJcnZ2tpb36NHD+nf9+vXVoEEDhYaGKjk5We3atSvQzqRJkzRmzJib0mcAAAAAwJ3DrqeX+/j4yNHRUceOHbMpP3bsmPz9/a+67tSpUzV58mStW7dODRo0uGrd6tWry8fHR3v37i10+bBhw6z3AczMzNShQ4dKNhAAAAAAAAph1yPd5cqVU3h4uJKSkhQTEyNJ1knRBg8eXOR6U6ZM0YQJE7R27Vo1btz4mts5fPiwTp48qYCAgEKXOzk5ycnJ6brGAAAAgNtDamqqMjIy7N0NAMXk4+OjqlWr2rsbN8zup5fHx8erd+/eaty4sZo0aaKEhASdP39ecXFxkqRevXqpcuXKmjRpkiTptdde08iRI7Vo0SIFBwcrPT1dkuTu7i53d3edO3dOY8aMUdeuXeXv7699+/Zp6NChqlGjhqKiouw2TgAAANhPamqqatesqQuXLtm7KwCKydXZWbt/++22D952D93du3fXiRMnNHLkSKWnp6tRo0ZKTEy0Tq6WmpoqB4f/nQX/zjvvKCcnR4888ohNO6NGjdLo0aPl6OionTt36oMPPtCZM2cUGBioDh06aNy4cRzNBgAAuENlZGTowqVLmtHoLoWVd7V3dwBcw56zFzR4x+/KyMggdJeGwYMHF3k6eXJyss3zAwcOXLUtFxcXrV27tpR6BgAAgH+SsPKuauDpbu9uALiD2HUiNQAAAAAA/skI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmOSWCN0zZ85UcHCwnJ2dFRERoa1btxZZ97333lPLli3l7e0tb29vRUZGFqhvGIZGjhypgIAAubi4KDIyUnv27DF7GAAAAAAA2LB76F66dKni4+M1atQobd++XQ0bNlRUVJSOHz9eaP3k5GT17NlTGzZs0KZNmxQUFKQOHTooLS3NWmfKlCl68803NWvWLG3ZskVubm6KiorSpUuXbtawAAAAAACwf+iePn26+vXrp7i4ONWpU0ezZs2Sq6ur5s6dW2j9hQsX6umnn1ajRo1Uq1Ytvf/++8rLy1NSUpKkP49yJyQk6NVXX9VDDz2kBg0aaMGCBTpy5IhWr159E0cGAAAAALjT2TV05+TkaNu2bYqMjLSWOTg4KDIyUps2bSpWGxcuXNDly5dVoUIFSdL+/fuVnp5u06anp6ciIiKK3SYAAAAAAKWhjD03npGRodzcXPn5+dmU+/n5KSUlpVhtvPTSSwoMDLSG7PT0dGsbf28zf9nfZWdnKzs72/o8Kyur2GMAAAAAAKAodj+9/EZMnjxZS5Ys0apVq+Ts7Hzd7UyaNEmenp7WR1BQUCn2EgAAAABwp7Jr6Pbx8ZGjo6OOHTtmU37s2DH5+/tfdd2pU6dq8uTJWrdunRo0aGAtz1+vJG0OGzZMmZmZ1sehQ4euZzgAAAAAANiwa+guV66cwsPDrZOgSbJOitasWbMi15syZYrGjRunxMRENW7c2GZZSEiI/P39bdrMysrSli1bimzTyclJHh4eNg8AAAAAAG6UXa/plqT4+Hj17t1bjRs3VpMmTZSQkKDz588rLi5OktSrVy9VrlxZkyZNkiS99tprGjlypBYtWqTg4GDrddru7u5yd3eXxWLR888/r/HjxyssLEwhISEaMWKEAgMDFRMTY69hAgAAAADuQHYP3d27d9eJEyc0cuRIpaenq1GjRkpMTLROhJaamioHh/8dkH/nnXeUk5OjRx55xKadUaNGafTo0ZKkoUOH6vz58+rfv7/OnDmjFi1aKDEx8Yau+wYAAAAAoKTsHrolafDgwRo8eHChy5KTk22eHzhw4JrtWSwWjR07VmPHji2F3gEAAAAAcH1u69nLAQAAAAC4lRG6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwSZmSrpCVlaUtW7YoJydHTZo0ka+vrxn9AgAAAADgtlei0L1jxw498MADOnbsmAzDUPny5bVs2TJFRUWZ1T8AAAAAAG5bJTq9/KWXXlJISIg2btyobdu2qV27dho8eLBZfQMAAAAA4LZWoiPd27Zt07p163TPPfdIkubOnasKFSooKytLHh4epnQQAAAAAIDbVYmOdJ86dUpVqlSxPvfy8pKbm5tOnjxZ6h0DAAAAAOB2V+KJ1H799Velp6dbnxuGod27d+vs2bPWsgYNGpRO7wAAAAAAuI2VOHS3a9dOhmHYlD344IOyWCwyDEMWi0W5ubml1kEAAAAAAG5XJQrd+/fvN6sfAAAAAAD845QodFerVu2adX755Zfr7gwAAAAAAP8kJZpIrShnz57V7Nmz1aRJEzVs2LA0mgQAAAAA4LZ3Q6H7m2++Ue/evRUQEKCpU6eqbdu22rx5c2n1DQAAAACA21qJJ1JLT0/X/PnzNWfOHGVlZalbt27Kzs7W6tWrVadOHTP6CAAAAADAbalER7o7d+6smjVraufOnUpISNCRI0f01ltvmdU3AAAAAABuayU60r1mzRo9++yzGjRokMLCwszqEwAAAAAA/wglOtK9ceNGnT17VuHh4YqIiNCMGTOUkZFhVt8AAAAAALitlSh0N23aVO+9956OHj2qAQMGaMmSJQoMDFReXp7Wr1+vs2fPmtVPAAAAAABuO9c1e7mbm5v69OmjjRs36ueff9YLL7ygyZMnq1KlSurSpUtp9xEAAAAAgNvSDd+nu2bNmpoyZYoOHz6sJUuWyGKxlEa/AAAAAAC47ZVoIrU+ffpcs07FihWvuzMAAAAAAPyTlCh0z58/X9WqVdPdd98twzAKrcORbgAAAAAA/lSi0D1o0CAtXrxY+/fvV1xcnJ544glVqFDBrL4BAAAAAHBbK9E13TNnztTRo0c1dOhQffrppwoKClK3bt20du3aIo98AwAAAABwpyrxRGpOTk7q2bOn1q9fr19//VV169bV008/reDgYJ07d86MPgIAAAAAcFu6odnLHRwcZLFYZBiGcnNzS6tPAAAAAAD8I5Q4dGdnZ2vx4sVq37697rrrLv3888+aMWOGUlNT5e7ubkYfAQAAAAC4LZVoIrWnn35aS5YsUVBQkPr06aPFixfLx8fHrL4BAAAAAHBbK1HonjVrlqpWrarq1avr66+/1tdff11ovZUrV5ZK5wAAAAAAuJ2VKHT36tWL+3ADAAAAAFBMJQrd8+fPN6kbAAAAAAD889zQ7OUAAAAAAKBohG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExi99A9c+ZMBQcHy9nZWREREdq6dWuRdXft2qWuXbsqODhYFotFCQkJBeqMHj1aFovF5lGrVi0TRwAAAAAAQOHsGrqXLl2q+Ph4jRo1Stu3b1fDhg0VFRWl48ePF1r/woULql69uiZPnix/f/8i261bt66OHj1qfWzcuNGsIQAAAAAAUCS7hu7p06erX79+iouLU506dTRr1iy5urpq7ty5hda/99579frrr6tHjx5ycnIqst0yZcrI39/f+vDx8TFrCAAAAAAAFMluoTsnJ0fbtm1TZGTk/zrj4KDIyEht2rTphtres2ePAgMDVb16dT3++ONKTU29av3s7GxlZWXZPAAAAAAAuFF2C90ZGRnKzc2Vn5+fTbmfn5/S09Ovu92IiAjNnz9fiYmJeuedd7R//361bNlSZ8+eLXKdSZMmydPT0/oICgq67u0DAAAAAJDP7hOplbaOHTvq0UcfVYMGDRQVFaUvvvhCZ86c0bJly4pcZ9iwYcrMzLQ+Dh06dBN7DAAAAAD4pypjrw37+PjI0dFRx44dsyk/duzYVSdJKykvLy/ddddd2rt3b5F1nJycrnqNOAAAAAAA18NuR7rLlSun8PBwJSUlWcvy8vKUlJSkZs2aldp2zp07p3379ikgIKDU2gQAAAAAoDjsdqRbkuLj49W7d281btxYTZo0UUJCgs6fP6+4uDhJUq9evVS5cmVNmjRJ0p+Tr/3666/Wv9PS0rRjxw65u7urRo0akqQXX3xRnTt3VrVq1XTkyBGNGjVKjo6O6tmzp30GCQAAAAC4Y9k1dHfv3l0nTpzQyJEjlZ6erkaNGikxMdE6uVpqaqocHP53MP7IkSO6++67rc+nTp2qqVOnqnXr1kpOTpYkHT58WD179tTJkyfl6+urFi1aaPPmzfL19b2pYwMAAAAAwK6hW5IGDx6swYMHF7osP0jnCw4OlmEYV21vyZIlpdU1AAAAAABuyD9u9nIAAAAAAG4VhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExi99A9c+ZMBQcHy9nZWREREdq6dWuRdXft2qWuXbsqODhYFotFCQkJN9wmAAAAAABmsWvoXrp0qeLj4zVq1Cht375dDRs2VFRUlI4fP15o/QsXLqh69eqaPHmy/P39S6VNAAAAAADMYtfQPX36dPXr109xcXGqU6eOZs2aJVdXV82dO7fQ+vfee69ef/119ejRQ05OTqXSJgAAAAAAZrFb6M7JydG2bdsUGRn5v844OCgyMlKbNm26qW1mZ2crKyvL5gEAAAAAwI2yW+jOyMhQbm6u/Pz8bMr9/PyUnp5+U9ucNGmSPD09rY+goKDr2j4AAAAAAH9l94nUbgXDhg1TZmam9XHo0CF7dwkAAAAA8A9Qxl4b9vHxkaOjo44dO2ZTfuzYsSInSTOrTScnpyKvEQcAAAAA4HrZ7Uh3uXLlFB4erqSkJGtZXl6ekpKS1KxZs1umTQAAAAAArpfdjnRLUnx8vHr37q3GjRurSZMmSkhI0Pnz5xUXFydJ6tWrlypXrqxJkyZJ+nOitF9//dX6d1pamnbs2CF3d3fVqFGjWG0CAAAAAHCz2DV0d+/eXSdOnNDIkSOVnp6uRo0aKTEx0ToRWmpqqhwc/ncw/siRI7r77rutz6dOnaqpU6eqdevWSk5OLlabAAAAAADcLHYN3ZI0ePBgDR48uNBl+UE6X3BwsAzDuKE2AQAAAAC4WZi9HAAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwyS0RumfOnKng4GA5OzsrIiJCW7duvWr95cuXq1atWnJ2dlb9+vX1xRdf2CyPjY2VxWKxeURHR5s5BAAAAAAACrB76F66dKni4+M1atQobd++XQ0bNlRUVJSOHz9eaP3vv/9ePXv2VN++ffXjjz8qJiZGMTEx+uWXX2zqRUdH6+jRo9bH4sWLb8ZwAAAAAACwsnvonj59uvr166e4uDjVqVNHs2bNkqurq+bOnVto/f/85z+Kjo7WkCFDVLt2bY0bN0733HOPZsyYYVPPyclJ/v7+1oe3t/fNGA4AAAAAAFZ2Dd05OTnatm2bIiMjrWUODg6KjIzUpk2bCl1n06ZNNvUlKSoqqkD95ORkVapUSTVr1tSgQYN08uTJIvuRnZ2trKwsmwcAAAAAADfKrqE7IyNDubm58vPzsyn38/NTenp6oeukp6dfs350dLQWLFigpKQkvfbaa/r666/VsWNH5ebmFtrmpEmT5OnpaX0EBQXd4MgAAAAAAJDK2LsDZujRo4f17/r166tBgwYKDQ1VcnKy2rVrV6D+sGHDFB8fb32elZVF8AYAAAAA3DC7Hun28fGRo6Ojjh07ZlN+7Ngx+fv7F7qOv79/iepLUvXq1eXj46O9e/cWutzJyUkeHh42DwAAAAAAbpRdQ3e5cuUUHh6upKQka1leXp6SkpLUrFmzQtdp1qyZTX1JWr9+fZH1Jenw4cM6efKkAgICSqfjAAAAAAAUg91nL4+Pj9d7772nDz74QLt379agQYN0/vx5xcXFSZJ69eqlYcOGWes/99xzSkxM1LRp05SSkqLRo0frhx9+0ODBgyVJ586d05AhQ7R582YdOHBASUlJeuihh1SjRg1FRUXZZYwAAAAAgDuT3a/p7t69u06cOKGRI0cqPT1djRo1UmJionWytNTUVDk4/O+3gebNm2vRokV69dVXNXz4cIWFhWn16tWqV6+eJMnR0VE7d+7UBx98oDNnzigwMFAdOnTQuHHj5OTkZJcxAgAAAADuTHYP3ZI0ePBg65Hqv0tOTi5Q9uijj+rRRx8ttL6Li4vWrl1bmt0DAAAAAOC62P30cgAAAAAA/qkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmOSWCN0zZ85UcHCwnJ2dFRERoa1bt161/vLly1WrVi05Ozurfv36+uKLL2yWG4ahkSNHKiAgQC4uLoqMjNSePXvMHAIAAAAAAAXYPXQvXbpU8fHxGjVqlLZv366GDRsqKipKx48fL7T+999/r549e6pv37768ccfFRMTo5iYGP3yyy/WOlOmTNGbb76pWbNmacuWLXJzc1NUVJQuXbp0s4YFAAAAAID9Q/f06dPVr18/xcXFqU6dOpo1a5ZcXV01d+7cQuv/5z//UXR0tIYMGaLatWtr3LhxuueeezRjxgxJfx7lTkhI0KuvvqqHHnpIDRo00IIFC3TkyBGtXr36Jo4MAAAAAHCnK2PPjefk5Gjbtm0aNmyYtczBwUGRkZHatGlToets2rRJ8fHxNmVRUVHWQL1//36lp6crMjLSutzT01MRERHatGmTevToUaDN7OxsZWdnW59nZmZKkrKysq57bGY7d+6cJOnCwV+Um33Bzr0BcC3Z6X9I+vOzeyt/t5SG/O+ni7uPK+/CZTv3BsDVZB88LenO+m7aeeaszl/JtXNvAFzLvnN/Zpxb+fspv1+GYVy1nl1Dd0ZGhnJzc+Xn52dT7ufnp5SUlELXSU9PL7R+enq6dXl+WVF1/m7SpEkaM2ZMgfKgoKDiDcSODi581d5dAFACrVu3tncXbpq0CV/auwsAiulO+m4a8vM+e3cBQAncDt9PZ8+elaenZ5HL7Rq6bxXDhg2zOXqel5enU6dOqWLFirJYLHbsGe5EWVlZCgoK0qFDh+Th4WHv7gCAJL6bANya+G6CPRmGobNnzyowMPCq9ewaun18fOTo6Khjx47ZlB87dkz+/v6FruPv73/V+vn/PXbsmAICAmzqNGrUqNA2nZyc5OTkZFPm5eVVkqEApc7Dw4P/eQC45fDdBOBWxHcT7OVqR7jz2XUitXLlyik8PFxJSUnWsry8PCUlJalZs2aFrtOsWTOb+pK0fv16a/2QkBD5+/vb1MnKytKWLVuKbBMAAAAAADPY/fTy+Ph49e7dW40bN1aTJk2UkJCg8+fPKy4uTpLUq1cvVa5cWZMmTZIkPffcc2rdurWmTZumTp06acmSJfrhhx80e/ZsSZLFYtHzzz+v8ePHKywsTCEhIRoxYoQCAwMVExNjr2ECAAAAAO5Adg/d3bt314kTJzRy5Eilp6erUaNGSkxMtE6ElpqaKgeH/x2Qb968uRYtWqRXX31Vw4cPV1hYmFavXq169epZ6wwdOlTnz59X//79debMGbVo0UKJiYlydna+6eMDSsrJyUmjRo0qcMkDANgT300AbkV8N+F2YDGuNb85AAAAAAC4Lna9phsAAAAAgH8yQjcAAAAAACYhdAMAAAAAYBJCN+4Io0ePLvI+7beb4OBgJSQklHq78+fPv+7707dp00bPP//8VeuY1W8AAADgVkboxm1r06ZNcnR0VKdOnezdFbsqKszezB8aVq5cqXHjxt2UbQG4cbGxsbJYLLJYLCpbtqxCQkI0dOhQXbp0yVonf/nmzZtt1s3OzlbFihVlsViUnJxsLe/SpYuqVq0qZ2dnBQQE6Mknn9SRI0du1pAA3Ib++l1ksVhUsWJFRUdHa+fOndY6JfkuOnDggPr27auQkBC5uLgoNDRUo0aNUk5OjnW9AwcO2GyzqPaB0kToxm1rzpw5euaZZ/TNN9/wDzs7yf+fWIUKFVS+fHk79wZASURHR+vo0aP6448/9MYbb+jdd9/VqFGjbOoEBQVp3rx5NmWrVq2Su7t7gfbuv/9+LVu2TL/99ps+/vhj7du3T4888oipYwBw+8v/Ljp69KiSkpJUpkwZPfjggzZ1ivtdlJKSory8PL377rvatWuX3njjDc2aNUvDhw8vsN0vv/zSut2jR48qPDy89AcH/P8I3bgtnTt3TkuXLtWgQYPUqVMnzZ8/32b55MmT5efnp/Lly6tv3742R2/WrVsnZ2dnnTlzxmad5557Tm3btpUknTx5Uj179lTlypXl6uqq+vXra/HixTb127Rpo2effVZDhw5VhQoV5O/vr9GjR9vUOXPmjAYMGCA/Pz85OzurXr16+uyzz6zLN27cqJYtW8rFxUVBQUF69tlndf78eevy48ePq3PnznJxcVFISIgWLlx4Xfvrm2++UdmyZZWenm5T/vzzz6tly5Y2ZatXr1ZYWJicnZ0VFRWlQ4cOWZflHz1///33FRISImdnZ+u++Ovp5aXVbwDmcXJykr+/v4KCghQTE6PIyEitX7/epk7v3r21ZMkSXbx40Vo2d+5c9e7du0B7//73v9W0aVNVq1ZNzZs318svv6zNmzfr8uXLpo8FwO0r/7vI399fjRo10ssvv6xDhw7pxIkT1jrF/S6Kjo7WvHnz1KFDB1WvXl1dunTRiy++qJUrVxbYbsWKFa3b9ff3V9myZc0bJO54hG7clpYtW6ZatWqpZs2aeuKJJzR37lzl33J+2bJlGj16tCZOnKgffvhBAQEBevvtt63rtmvXTl5eXvr444+tZbm5uVq6dKkef/xxSdKlS5cUHh6uzz//XL/88ov69++vJ598Ulu3brXpxwcffCA3Nzdt2bJFU6ZM0dixY63/aM3Ly1PHjh313Xff6aOPPtKvv/6qyZMny9HRUZK0b98+RUdHq2vXrtq5c6eWLl2qjRs3avDgwdb2Y2NjdejQIW3YsEErVqzQ22+/rePHj5d4f7Vq1UrVq1fXhx9+aC27fPmyFi5cqD59+ljLLly4oAkTJmjBggX67rvvdObMGfXo0cOmrb179+rjjz/WypUrtWPHjkK3V1r9BnBz/PLLL/r+++9Vrlw5m/Lw8HAFBwdbvy9TU1P1zTff6Mknn7xqe6dOndLChQvVvHlz/iELoNjOnTunjz76SDVq1FDFihWt5df7XSRJmZmZqlChQoHyLl26qFKlSmrRooX+3//7f6U3CKAwBnAbat68uZGQkGAYhmFcvnzZ8PHxMTZs2GAYhmE0a9bMePrpp23qR0REGA0bNrQ+f+6554y2bdtan69du9ZwcnIyTp8+XeQ2O3XqZLzwwgvW561btzZatGhhU+fee+81XnrpJWubDg4Oxm+//VZoe3379jX69+9vU/btt98aDg4OxsWLF43ffvvNkGRs3brVunz37t2GJOONN96wllWrVs0oV66c4ebmZvMoW7aszZhfe+01o3bt2tbnH3/8seHu7m6cO3fOMAzDmDdvniHJ2Lx5c4HtbdmyxTAMwxg1apRRtmxZ4/jx4zb9bt26tfHcc88ZhmEUu98A7Kd3796Go6Oj4ebmZjg5ORmSDAcHB2PFihXWOpKMVatWGQkJCcb9999vGIZhjBkzxvi///s/4/Tp04Yk6/duvqFDhxqurq6GJKNp06ZGRkbGzRwWgNvMX7+L3NzcDElGQECAsW3bNmud6/kuyrdnzx7Dw8PDmD17trXsxIkTxrRp04zNmzcbW7duNV566SXDYrEYn3zyialjxZ2NI9247fz222/aunWrevbsKUkqU6aMunfvrjlz5kiSdu/erYiICJt1mjVrZvP88ccfV3JysvVa8IULF6pTp07W2btzc3M1btw41a9fXxUqVJC7u7vWrl2r1NRUm3YaNGhg8zwgIMB6RHfHjh2qUqWK7rrrrkLH8dNPP2n+/Plyd3e3PqKiopSXl6f9+/dr9+7dKlOmjM01RrVq1Sp0hvEhQ4Zox44dNo+BAwfa1ImNjdXevXutE4XMnz9f3bp1k5ubm7VOmTJldO+99xbY3u7du61l1apVk6+vb6FjklSifgOwn/vvv187duzQli1b1Lt3b8XFxalr164F6j3xxBPatGmT/vjjD82fP9/m7Ji/GzJkiH788UetW7dOjo6O6tWrl/UsJAAoTP530Y4dO7R161ZFRUWpY8eOOnjwoE29knwXSVJaWpqio6P16KOPql+/ftZyHx8fxcfHKyIiQvfee68mT56sJ554Qq+//rop4wMkqYy9OwCU1Jw5c3TlyhUFBgZaywzDkJOTk2bMmFGsNu69916FhoZqyZIlGjRokFatWmVzXfjrr7+u//znP0pISFD9+vXl5uam559/3mb2S0kFTpu0WCzKy8uTJLm4uFy1D+fOndOAAQP07LPPFlhWtWpV/f7778Uai/Tn/0Bq1KhhU/b3U6kqVaqkzp07a968eQoJCdGaNWtsZh4urr+GdAC3Lzc3N+v3xty5c9WwYUPNmTNHffv2talXsWJFPfjgg9b5MTp27KizZ88W2qaPj498fHx01113qXbt2goKCtLmzZsL/PAJAPn++l0kSe+//748PT313nvvafz48dbyknwXHTlyRPfff7+aN2+u2bNnX7MPERERBea0AEoTR7pxW7ly5YoWLFigadOm2RzV/emnnxQYGKjFixerdu3a2rJli816hd0G4vHHH9fChQv16aefysHBwebWY999950eeughPfHEE2rYsKGqV69eohAs/XkU/PDhw0Wud8899+jXX39VjRo1CjzKlSunWrVq6cqVK9q2bZt1nd9++63ABHAl8dRTT2np0qWaPXu2QkNDdd9999ksv3Llin744YcC26tdu3axt2FGvwGYy8HBQcOHD9err75qM1FRvj59+ig5OVm9evWyzktxLfk/QGZnZ5dqXwH8s1ksFjk4OFz3d1FaWpratGmj8PBwzZs3Tw4O1447O3bsUEBAwA33HSgKR7pxW/nss890+vRp9e3bV56enjbLunbtqjlz5ujFF19UbGysGjdurPvuu08LFy7Url27VL16dZv6jz/+uEaPHq0JEybokUcekZOTk3VZWFiYVqxYoe+//17e3t6aPn26jh07pjp16hS7r61bt1arVq3UtWtXTZ8+XTVq1FBKSoosFouio6P10ksvqWnTpho8eLCeeuopubm56ddff9X69es1Y8YM1axZU9HR0RowYIDeeecdlSlTRs8///w1j6BfTVRUlDw8PDR+/HiNHTu2wPKyZcvqmWee0ZtvvqkyZcpo8ODBatq0qZo0aVLsbZjRbwDme/TRRzVkyBDNnDlTL774os2y6OhonThxQh4eHoWuu2XLFv33v/9VixYt5O3trX379mnEiBEKDQ3lKDeAq8rOzrbeXeX06dOaMWOGzp07p86dOxeoe63vovzAXa1aNU2dOtVmBnR/f39Jf06CW65cOd19992SpJUrV2ru3Ll6//33S3togBVHunFbmTNnjiIjIwsEbunP0P3DDz+odu3aGjFihIYOHarw8HAdPHhQgwYNKlC/Ro0aatKkiXbu3GmdtTzfq6++qnvuuUdRUVFq06aN/P39FRMTU+L+fvzxx7r33nvVs2dP1alTR0OHDlVubq6kP4+Ef/311/r999/VsmVL3X333Ro5cqTNafPz5s1TYGCgWrdurYcfflj9+/dXpUqVStyPfA4ODoqNjVVubq569epVYLmrq6teeuklPfbYY7rvvvvk7u6upUuXlng7pd1vAObL/6FtypQpNrculP488uTj41NgdvN8rq6uWrlypdq1a6eaNWuqb9++1u+4v/6gCQB/l5iYqICAAAUEBCgiIkL//e9/tXz5crVp06ZA3Wt9F61fv1579+5VUlKSqlSpYm3370exx40bp/DwcEVEROiTTz7R0qVLFRcXZ8bwAEmSxWCGE+CO0rdvX504cYLbYwAAAAA3AaeXA3eIzMxM/fzzz1q0aBGBGwAAALhJCN3AHeKhhx7S1q1bNXDgQLVv397e3QEAAADuCJxeDgAAAACASZhIDQAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACT/H8x8zh5AzVgVgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "methods = summary_df[\"Method\"].tolist()\n",
    "maps = summary_df[\"MAP\"].tolist()\n",
    "colors = [\"#3498db\", \"#2ecc71\", \"#e74c3c\"]\n",
    "\n",
    "bars = ax.bar(methods, maps, color=colors[:len(methods)], edgecolor=\"black\")\n",
    "ax.set_ylabel(\"MAP\")\n",
    "ax.set_title(\"Training Performance Comparison (50 queries)\")\n",
    "ax.set_ylim(0, max(maps) * 1.15)\n",
    "\n",
    "for bar, m in zip(bars, maps):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "            f\"{m:.4f}\", ha=\"center\", va=\"bottom\", fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e5ffea",
   "metadata": {},
   "source": [
    "## 7. Final Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7390690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from all experiments:\n",
      "  Model: AdvancedHybrid\n",
      "  MAP: 0.3018\n",
      "  Config: AdvancedHybrid__b=0.4__fb_docs=10__fb_terms=10__k1=0.9__k_docs=500__mu=1000__original_weight=0.5__overlap=50__window=150\n",
      "\n",
      "✓ Best model identified: AdvancedHybrid\n",
      "  Parameters: {'k1': 0.9, 'b': 0.4, 'mu': 1000, 'fb_terms': 10, 'fb_docs': 10, 'original_weight': 0.5, 'k_docs': 500, 'window': 150, 'overlap': 50}\n"
     ]
    }
   ],
   "source": [
    "# Select best overall model\n",
    "best_result = results_sorted[0]\n",
    "\n",
    "print(\"Best model from all experiments:\")\n",
    "print(f\"  Model: {best_result['model']}\")\n",
    "print(f\"  MAP: {best_result['map']:.4f}\")\n",
    "print(f\"  Config: {best_result['config_key']}\")\n",
    "\n",
    "# Find matching experiment configuration\n",
    "best_model_name = best_result[\"model\"]\n",
    "best_config_key = best_result[\"config_key\"]\n",
    "\n",
    "matched_config = None\n",
    "matched_model_class = None\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    if exp[\"model_name\"] == best_model_name:\n",
    "        matched_model_class = exp[\"model_class\"]\n",
    "        for params in exp[\"param_grid\"]:\n",
    "            config_key = generate_config_key(exp[\"model_name\"], params)\n",
    "            if config_key == best_config_key:\n",
    "                matched_config = params.copy()\n",
    "                break\n",
    "        if matched_config:\n",
    "            break\n",
    "\n",
    "if matched_config is None:\n",
    "    raise ValueError(f\"Could not find matching config for {best_config_key}\")\n",
    "\n",
    "print(f\"\\n✓ Best model identified: {best_model_name}\")\n",
    "print(f\"  Parameters: {matched_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78526c82",
   "metadata": {},
   "source": [
    "## 8. Generate Submission Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43c924",
   "metadata": {},
   "source": [
    "### 8.1. Initialize Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1cfbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model configurations:\n",
      "  BM25: {'k1': 0.6, 'b': 0.4}\n",
      "  RM3: {'k1': 0.9, 'b': 0.4, 'fb_terms': 20, 'fb_docs': 5, 'original_weight': 0.5}\n",
      "  AdvancedHybrid: {'k1': 0.9, 'b': 0.4, 'mu': 1000, 'fb_terms': 10, 'fb_docs': 10, 'original_weight': 0.5, 'k_docs': 500, 'window': 150, 'overlap': 50}\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters for each method\n",
    "best_bm25_params = None\n",
    "best_rm3_params = None\n",
    "best_advanced_params = None\n",
    "\n",
    "for model_name, r in best_per_model.items():\n",
    "    for exp in EXPERIMENTS:\n",
    "        if exp[\"model_name\"] == model_name:\n",
    "            for params in exp[\"param_grid\"]:\n",
    "                if generate_config_key(model_name, params) == r[\"config_key\"]:\n",
    "                    if model_name == \"BM25\":\n",
    "                        best_bm25_params = params\n",
    "                    elif model_name == \"RM3\":\n",
    "                        best_rm3_params = params\n",
    "                    elif model_name == \"AdvancedHybrid\":\n",
    "                        best_advanced_params = params\n",
    "                    break\n",
    "\n",
    "print(\"Final model configurations:\")\n",
    "print(f\"  BM25: {best_bm25_params}\")\n",
    "print(f\"  RM3: {best_rm3_params}\")\n",
    "print(f\"  AdvancedHybrid: {best_advanced_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9f6e9",
   "metadata": {},
   "source": [
    "### 8.2. Run Inference on Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f411f11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on 199 test queries...\n",
      "\n",
      "Method 1: BM25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BM25 Search: 100%|██████████| 199/199 [00:11<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ 199 queries processed\n",
      "\n",
      "Method 2: BM25 + RM3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RM3 Search: 100%|██████████| 199/199 [00:11<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ 199 queries processed\n",
      "\n",
      "Method 3: Advanced Hybrid (BM25+RM3, QLD+RM3, Passages, RRF)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced Hybrid Search: 100%|██████████| 199/199 [09:58<00:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ 199 queries processed\n",
      "\n",
      "✓ All test queries processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running inference on {len(test_queries)} test queries...\\n\")\n",
    "\n",
    "# Method 1: BM25\n",
    "print(\"Method 1: BM25\")\n",
    "model_1 = BM25Retriever(**best_bm25_params)\n",
    "run_1 = model_1.search(test_queries, k=1000)\n",
    "print(f\"  ✓ {len(run_1)} queries processed\")\n",
    "\n",
    "# Method 2: RM3\n",
    "print(\"\\nMethod 2: BM25 + RM3\")\n",
    "model_2 = RM3Retriever(**best_rm3_params)\n",
    "run_2 = model_2.search(test_queries, k=1000)\n",
    "print(f\"  ✓ {len(run_2)} queries processed\")\n",
    "\n",
    "# Method 3: Advanced Hybrid (BM25+RM3, QLD+RM3, Passages, RRF)\n",
    "print(\"\\nMethod 3: Advanced Hybrid (BM25+RM3, QLD+RM3, Passages, RRF)\")\n",
    "model_3 = AdvancedHybridRetriever(**best_advanced_params)\n",
    "run_3 = model_3.search(test_queries, k=1000)\n",
    "print(f\"  ✓ {len(run_3)} queries processed\")\n",
    "\n",
    "print(\"\\n✓ All test queries processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30683d4",
   "metadata": {},
   "source": [
    "### 8.3. Export TREC Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "683f4e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission files...\n",
      "\n",
      "✓ Written: run_1.res\n",
      "✓ Written: run_2.res\n",
      "✓ Written: run_3.res\n",
      "\n",
      "✓ All submission files written\n"
     ]
    }
   ],
   "source": [
    "def write_trec_run(\n",
    "    run: Dict[str, List[Tuple[str, float]]],\n",
    "    filepath: str,\n",
    "    run_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Write run to TREC format.\n",
    "    Format: topic_id Q0 doc_id rank score run_name\n",
    "    \"\"\"\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for qid in sorted(run.keys(), key=lambda x: int(x)):\n",
    "            results = run[qid]\n",
    "            sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "            for rank, (docid, score) in enumerate(sorted_results[:1000], start=1):\n",
    "                f.write(f\"{qid} Q0 {docid} {rank} {score:.6f} {run_name}\\n\")\n",
    "    \n",
    "    print(f\"✓ Written: {filepath}\")\n",
    "\n",
    "\n",
    "print(\"Writing submission files...\\n\")\n",
    "\n",
    "write_trec_run(run_1, \"run_1.res\", \"run_1\")\n",
    "write_trec_run(run_2, \"run_2.res\", \"run_2\")\n",
    "write_trec_run(run_3, \"run_3.res\", \"run_3\")\n",
    "\n",
    "print(\"\\n✓ All submission files written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731a362",
   "metadata": {},
   "source": [
    "### 8.4. Validate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38b4900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating submission files...\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Query 364: expected 1000 docs, got 123",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(query_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m queries × \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocs_per_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m docs, scores non-increasing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidating submission files...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mvalidate_run_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_1.res\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m validate_run_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_2.res\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m validate_run_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_3.res\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 14\u001b[0m, in \u001b[0;36mvalidate_run_file\u001b[0;34m(filepath, expected_queries, docs_per_query)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_docs) \u001b[38;5;241m==\u001b[39m expected_queries, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_queries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m queries, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(query_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m qid, docs \u001b[38;5;129;01min\u001b[39;00m query_docs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(docs) \u001b[38;5;241m==\u001b[39m docs_per_query, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocs_per_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m docs, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     scores \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m _, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(docs, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m scores \u001b[38;5;241m==\u001b[39m \u001b[38;5;28msorted\u001b[39m(scores, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: scores not in decreasing order\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Query 364: expected 1000 docs, got 123"
     ]
    }
   ],
   "source": [
    "def validate_run_file(filepath: str, expected_queries: int = 199, docs_per_query: int = 1000):\n",
    "    \"\"\"Validate TREC run file format and contents.\"\"\"\n",
    "    query_docs = defaultdict(list)\n",
    "    \n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            qid, _, docid, rank, score, _ = parts\n",
    "            query_docs[qid].append((int(rank), float(score)))\n",
    "    \n",
    "    assert len(query_docs) == expected_queries, f\"Expected {expected_queries} queries, got {len(query_docs)}\"\n",
    "    \n",
    "    for qid, docs in query_docs.items():\n",
    "        assert len(docs) == docs_per_query, f\"Query {qid}: expected {docs_per_query} docs, got {len(docs)}\"\n",
    "        scores = [s for _, s in sorted(docs, key=lambda x: x[0])]\n",
    "        assert scores == sorted(scores, reverse=True), f\"Query {qid}: scores not in decreasing order\"\n",
    "    \n",
    "    print(f\"✓ {filepath}: {len(query_docs)} queries × {docs_per_query} docs, scores non-increasing\")\n",
    "\n",
    "\n",
    "print(\"Validating submission files...\\n\")\n",
    "\n",
    "validate_run_file(\"run_1.res\")\n",
    "validate_run_file(\"run_2.res\")\n",
    "validate_run_file(\"run_3.res\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUBMISSION FILES READY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Files: run_1.res, run_2.res, run_3.res\")\n",
    "print(\"Format: TREC 6-column\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
